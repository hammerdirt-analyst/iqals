{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys, file and nav packages:\n",
    "import os\n",
    "import datetime as dt\n",
    "import csv\n",
    "\n",
    "# math packages:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "import datetime as dt \n",
    "from scipy.stats import kendalltau, pearsonr, spearmanr\n",
    "import math\n",
    "from scipy.stats import gamma\n",
    "from scipy.stats import beta\n",
    "from scipy.stats import binom\n",
    "from scipy.stats import bernoulli\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.gofplots import qqplot_2samples\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "# charting:\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib import ticker\n",
    "import matplotlib.ticker as mtick\n",
    "import seaborn as sns\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from IPython.display import display, Markdown, Latex, HTML\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap, Colormap\n",
    "\n",
    "# mapping\n",
    "import geopandas as gpd\n",
    "\n",
    "# home brew utitilties\n",
    "import utilities.utility_functions as ut\n",
    "import utilities.abundance_classes as ac\n",
    "\n",
    "# documenting\n",
    "from IPython.display import Markdown as md\n",
    "\n",
    "\n",
    "# returns the p_value for each test\n",
    "def kendall_pval(x,y):\n",
    "    return kendalltau(x,y)[1]\n",
    "\n",
    "def pearsonr_pval(x,y):\n",
    "    return pearsonr(x,y)[1]\n",
    "\n",
    "def spearmanr_pval(x,y):\n",
    "    return spearmanr(x,y)[1]\n",
    "\n",
    "# table kwargs\n",
    "table_k = dict(loc=\"top left\", bbox=(0,0,1,1), colWidths=[.5, .5], cellLoc='center')\n",
    "tablecenter_k = dict(loc=\"top left\", bbox=(0,0,1,1), cellLoc='center')\n",
    "tabtickp_k = dict(axis='both', which='both', bottom=False, top=False, left=False, right=False, labelleft=False, labelbottom=False)\n",
    "\n",
    "# chart kwargs\n",
    "title_k = {'loc':'left', 'pad':14, 'linespacing':1.5, 'fontsize':12}\n",
    "title_k14 = {'loc':'left', 'pad':16, 'linespacing':1.5, 'fontsize':14}\n",
    "xlab_k = {'labelpad':10, 'fontsize':12}\n",
    "ylab_k = {'labelpad':14, 'fontsize':14}\n",
    "\n",
    "\n",
    "# # use these to format date axis in charts\n",
    "# weeks = mdates.WeekdayLocator(byweekday=1, interval=4)\n",
    "# # onedayweek = mdates.DayLocator(bymonthday=1, interval=1)\n",
    "# # everytwoweeks = mdates.WeekdayLocator(byweekday=1, interval=4)\n",
    "\n",
    "# months = mdates.MonthLocator(bymonth=[3,6,9,12])\n",
    "# bimonthly = mdates.MonthLocator(bymonth=[1,3,5,7,9,11])\n",
    "# allmonths = mdates.MonthLocator()\n",
    "# wks_fmt = mdates.DateFormatter('%d')\n",
    "# mths_fmt = mdates.DateFormatter('%b')\n",
    "\n",
    "# map marker size:\n",
    "markerSize = 100\n",
    "survey_data, location_data, code_defs, stat_ent, geo_data, output = ut.make_local_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set some parameters:\n",
    "start_date = '2020-04-01'\n",
    "end_date = dt.datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "startyearmonth = '{}/{}'.format(start_date[5:7], start_date[:4])\n",
    "endyearmonth = '{}/{}'.format(end_date[5:7], end_date[:4]) \n",
    "\n",
    "# decide which data to use\n",
    "aggregated = False\n",
    "\n",
    "\n",
    "# collect the names:\n",
    "# group_names = list(these_groups.keys())\n",
    "\n",
    "# choose a lake:\n",
    "# lake = 'Lac Léman'\n",
    "coi = 'Neuchâtel'\n",
    "bassin_label = 'Aare'\n",
    "bassin = ['Aare', 'Aare|Nidau-Büren-Kanal','Schüss', 'Neuenburgersee', 'Thunersee','Bielersee', 'Brienzersee','La Thièle']\n",
    "bassin_lmn = ['Rhône', 'Lac Léman']\n",
    "samples_all = 'All samples'\n",
    "# lavey_locs= ['lavey-les-bains-2','lavey-les-bains', 'lavey-la-source']\n",
    "\n",
    "\n",
    "# define a significant event:\n",
    "sig = .9\n",
    "one_minus_sig = (1-sig)\n",
    "\n",
    "# define explanatory variables:\n",
    "expv = ['population','streets','buildings','rivs']\n",
    "\n",
    "# name the folder:\n",
    "name_of_project = 'bielsummary'\n",
    "save_output = False\n",
    "\n",
    "# use this to store things:\n",
    "project_directory = ut.make_project_folder(output, name_of_project)\n",
    "\n",
    "# get the data\n",
    "# aggregated survey data\n",
    "# dfAgg = pd.read_csv(F\"{survey_data}/results_with_zeroes_aggregated_parent.csv\")\n",
    "\n",
    "# keep track of output\n",
    "files_generated = []\n",
    "figure_num = 1\n",
    "data_num = 1\n",
    "\n",
    "def add_output(**kwargs):\n",
    "    files_generated.append({'tag':kwargs['tag'], 'number':kwargs['figure_num'], 'file':kwargs['file'],'type':kwargs['a_type']})\n",
    "    if kwargs['a_type'] == 'data':\n",
    "        kwargs['data'].to_csv(F\"{kwargs['file']}.csv\", index=False)\n",
    "    else:\n",
    "        plt.savefig(F\"{kwargs['file']}.jpeg\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non aggregated survey data\n",
    "# Zero values are assigned for all codes not identified at a survey, for each survey\n",
    "dfSurveys = pd.read_csv(F\"{survey_data}/results_with_zeroes.csv\")\n",
    "\n",
    "# house keeping\n",
    "dfSurveys = dfSurveys[(dfSurveys.date >= start_date)&(dfSurveys.date <= end_date)]\n",
    "dfSurveys['date'] = pd.to_datetime(dfSurveys['date'], format=\"%Y-%m-%d\")\n",
    "\n",
    "# allow for groups\n",
    "dfSurveys['groupname'] = 'nogroup'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survey_key</th>\n",
       "      <th>date</th>\n",
       "      <th>length</th>\n",
       "      <th>area</th>\n",
       "      <th>mac_plast_w</th>\n",
       "      <th>mic_plas_w</th>\n",
       "      <th>total_w</th>\n",
       "      <th>est_weight</th>\n",
       "      <th>num_parts_staff</th>\n",
       "      <th>num_parts_other</th>\n",
       "      <th>time_minutes</th>\n",
       "      <th>participants</th>\n",
       "      <th>project</th>\n",
       "      <th>is_2020</th>\n",
       "      <th>location</th>\n",
       "      <th>loc_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aabach2020-10-2230</td>\n",
       "      <td>2020-10-22</td>\n",
       "      <td>30</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>[\"HD\"]</td>\n",
       "      <td>2020</td>\n",
       "      <td>True</td>\n",
       "      <td>aabach</td>\n",
       "      <td>('aabach', '2020-10-22')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aare-limmatspitz2020-07-13120</td>\n",
       "      <td>2020-07-13</td>\n",
       "      <td>120</td>\n",
       "      <td>253.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>[\"HD\"]</td>\n",
       "      <td>2020</td>\n",
       "      <td>True</td>\n",
       "      <td>aare-limmatspitz</td>\n",
       "      <td>('aare-limmatspitz', '2020-07-13')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aare-solothurn-lido-strand2020-09-0511</td>\n",
       "      <td>2020-09-05</td>\n",
       "      <td>11</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>[\"HD\"]</td>\n",
       "      <td>2020</td>\n",
       "      <td>True</td>\n",
       "      <td>aare-solothurn-lido-strand</td>\n",
       "      <td>('aare-solothurn-lido-strand', '2020-09-05')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aare_bern_gerberm2020-09-2337</td>\n",
       "      <td>2020-09-23</td>\n",
       "      <td>37</td>\n",
       "      <td>148.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>[\"HD\"]</td>\n",
       "      <td>2020</td>\n",
       "      <td>True</td>\n",
       "      <td>aare_bern_gerberm</td>\n",
       "      <td>('aare_bern_gerberm', '2020-09-23')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aare_bern_scheurerk2020-05-1332</td>\n",
       "      <td>2020-05-13</td>\n",
       "      <td>32</td>\n",
       "      <td>96.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>[\"HD\"]</td>\n",
       "      <td>2020</td>\n",
       "      <td>True</td>\n",
       "      <td>aare_bern_scheurerk</td>\n",
       "      <td>('aare_bern_scheurerk', '2020-05-13')</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               survey_key        date  length   area  \\\n",
       "0                      aabach2020-10-2230  2020-10-22      30   75.0   \n",
       "1           aare-limmatspitz2020-07-13120  2020-07-13     120  253.0   \n",
       "2  aare-solothurn-lido-strand2020-09-0511  2020-09-05      11   38.0   \n",
       "3           aare_bern_gerberm2020-09-2337  2020-09-23      37  148.0   \n",
       "4         aare_bern_scheurerk2020-05-1332  2020-05-13      32   96.0   \n",
       "\n",
       "   mac_plast_w  mic_plas_w  total_w  est_weight  num_parts_staff  \\\n",
       "0         75.0       0.145    0.080         0.0                1   \n",
       "1        155.0       0.033    0.155         0.0                1   \n",
       "2          1.0       0.000    0.001         0.0                1   \n",
       "3       3800.0       0.000    5.300         0.0                1   \n",
       "4        100.0       0.000    0.140         0.0                1   \n",
       "\n",
       "   num_parts_other  time_minutes participants  project  is_2020  \\\n",
       "0                0            90       [\"HD\"]     2020     True   \n",
       "1                0            90       [\"HD\"]     2020     True   \n",
       "2                0            80       [\"HD\"]     2020     True   \n",
       "3                1           150       [\"HD\"]     2020     True   \n",
       "4                0           120       [\"HD\"]     2020     True   \n",
       "\n",
       "                     location                                      loc_date  \n",
       "0                      aabach                      ('aabach', '2020-10-22')  \n",
       "1            aare-limmatspitz            ('aare-limmatspitz', '2020-07-13')  \n",
       "2  aare-solothurn-lido-strand  ('aare-solothurn-lido-strand', '2020-09-05')  \n",
       "3           aare_bern_gerberm           ('aare_bern_gerberm', '2020-09-23')  \n",
       "4         aare_bern_scheurerk         ('aare_bern_scheurerk', '2020-05-13')  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# beach data\n",
    "dfBeaches = pd.read_csv(F\"{location_data}/beaches_with_ranks.csv\")\n",
    "dfBeaches.set_index('slug', inplace=True)\n",
    "dfBeaches.rename(columns={\"NUMPOINTS\":\"intersects\"}, inplace=True)\n",
    "\n",
    "# code definitions\n",
    "dfCodes = pd.read_csv(F\"{code_defs}/mlw_codes.csv\", index_col='code')\n",
    "\n",
    "# dimensional data\n",
    "\n",
    "dfDims = pd.read_csv(F\"{survey_data}/dims_data.csv\")\n",
    "dfDims.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names_locations = {\n",
    "    \"waste water\": \"wastewater.json\" ,\n",
    "    \"less than 5mm\":\"codeListMicros.json\",\n",
    "    \"construction\":\"construction.json\",\n",
    "    \"food\":\"foodstuff.json\",\n",
    "    \"agg-con-trans\":\"cat.json\",\n",
    "    \"agriculture\":\"ag.json\",\n",
    "    \"tobacco\":\"tobac.json\",\n",
    "    \"recreation\":\"recreation.json\",    \n",
    "    \"packaging\":\"packaging.json\",\n",
    "    \"personal items\":\"pi.json\",    \n",
    "}\n",
    "\n",
    "\n",
    "frag_plas = {\"fragmented plastics\":[\"G79\", \"G78\", \"G75\"]}\n",
    "levels={'muni':coi, 'catchment':bassin_label}\n",
    "\n",
    "these_cols = ['loc_date', 'location', 'water_name','type', 'date']\n",
    "catchment_cols = ['region','water_name','type','city','loc_date', 'location', 'date']\n",
    "foams={'G82':['G82', 'G912'], 'G81':['G81', 'G911'], 'G74':['G74', 'G910', 'G909']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dfSurveys.copy()\n",
    "lakes = dfBeaches[dfBeaches.water == 'l'].water_name.unique()\n",
    "rivers = dfBeaches[dfBeaches.water == 'r'].water_name.unique()\n",
    "bssn = dfBeaches.water_name.isin(bassin)\n",
    "# data.set_index('location', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['type'] = 't'\n",
    "for a_place in data.water_name.unique():\n",
    "    data.loc[data.water_name.isin(lakes), 'type'] = 'l'\n",
    "    data.loc[data.water_name.isin(rivers), 'type'] = 'r'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>code</th>\n",
       "      <th>pcs_m</th>\n",
       "      <th>quantity</th>\n",
       "      <th>location</th>\n",
       "      <th>loc_date</th>\n",
       "      <th>water_name</th>\n",
       "      <th>groupname</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [date, code, pcs_m, quantity, location, loc_date, water_name, groupname, type]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['type']=='t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code maps done\n",
      "agg foams complet\n",
      "added exp vs\n"
     ]
    }
   ],
   "source": [
    "data.reset_index(inplace=True)\n",
    "a = ac.PreprocessData(data, dfBeaches,these_cols=these_cols, foams=foams, start_date=start_date, end_date=end_date)\n",
    "\n",
    "clas_kwargs = dict(\n",
    "    code_group_data=group_names_locations,\n",
    "    new_code_group=frag_plas,\n",
    "    levels=levels,\n",
    "    catchment_features=bassin,\n",
    "    end_date=end_date,\n",
    "    start_date=start_date,\n",
    "    code_group_loc=output,\n",
    "    catchment_cols=catchment_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "made code groups\n",
      "making group map\n",
      "assigned results to code groups\n",
      "assigned regional labels\n",
      "assigned results to code groups\n",
      "assigned regional labels\n",
      "made code totals\n",
      "made code totals\n"
     ]
    }
   ],
   "source": [
    "b = ac.CatchmentArea(a.processed, dfBeaches, **clas_kwargs)\n",
    "\n",
    "lakes = dfBeaches.water == 'l'\n",
    "rivers = dfBeaches.water == 'r'\n",
    "bssn = dfBeaches.water_name.isin(bassin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'code', 'pcs_m', 'quantity', 'location', 'loc_date',\n",
      "       'water_name', 'groupname', 'type', 'population', 'string_date',\n",
      "       'region', 'city', 'fail'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "som_bassin_data = b.bassin_data.copy()\n",
    "\n",
    "# mark all the records that have quantity > 0\n",
    "som_bassin_data['fail'] = som_bassin_data.quantity > 0\n",
    "som_bassin_data = som_bassin_data[som_bassin_data.columns[1:]]\n",
    "print(som_bassin_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather the dimensional data for this river basin\n",
    "som_dims = dfDims.copy()\n",
    "som_dims['new_loc_date'] = list(zip(som_dims.location, som_dims.date))\n",
    "som_dims = som_dims.loc[som_dims.new_loc_date.isin(som_bassin_data.loc_date.unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_wname_key = dfBeaches[['water_name']]\n",
    "som_dims['water_name'] = som_dims.location.map(lambda x: location_wname_key.loc[x][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time in minutes, cumulative meters survyed, cumulative m² survyed, and the total weight of objects removed:\n",
      "\n",
      "                        time_minutes  length     area  total_w\n",
      "water_name                                                    \n",
      "Aare                             917     545   2477.0   12.036\n",
      "Aare|Nidau-Büren-Kanal           160     106    565.0    1.965\n",
      "Bielersee                       4284    1083   5515.0   11.425\n",
      "Brienzersee                      650     230   1143.0    2.270\n",
      "La Thièle                         65      19     13.0    0.001\n",
      "Neuenburgersee                  5145    3016  14328.0  275.397\n",
      "Schüss                           185      92    381.0  160.200\n",
      "Thunersee                       3320    1939   8755.8  488.224\n"
     ]
    }
   ],
   "source": [
    "# dims data summary stats:\n",
    "\n",
    "dims_summary_stats = som_dims.groupby('water_name').agg({'time_minutes':'sum', 'length':'sum', 'area':'sum', 'total_w':'sum'})\n",
    "\n",
    "print(F\"The time in minutes, cumulative meters survyed, cumulative m² survyed, and the total weight of objects removed:\\n\\n{dims_summary_stats}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get sample rates at the code level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map number of samples per location and sample total of all objects to each record\n",
    "\n",
    "def add_attribute(x, a_map={}):\n",
    "    try:\n",
    "        num_samps = a_map[x]\n",
    "    except:\n",
    "        num_samps = 0\n",
    "    return num_samps\n",
    "\n",
    "# conut the number of samples per location\n",
    "num_samp_location = b.bassin_pcsm_day.groupby('location').loc_date.count()\n",
    "\n",
    "# retrieve the total quantity per sample\n",
    "qty_sample = b.bassin_pcsm_day.groupby('loc_date').quantity.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map values to bassin data\n",
    "\n",
    "# the number of samples at a location\n",
    "for beach in som_bassin_data.location.unique():\n",
    "    som_bassin_data.loc[som_bassin_data.location==beach, 'nsamps'] = add_attribute(beach, a_map=num_samp_location)\n",
    "\n",
    "# the number of samples at a location divided by the total number of samples\n",
    "# som_bassin_data['l_weight'] = som_bassin_data.nsamps/len(som_bassin_data.loc_date.unique())\n",
    "\n",
    "# the survey total for the corresponding loc_date variable\n",
    "for loc_date in som_bassin_data.loc_date.unique():\n",
    "    som_bassin_data.loc[som_bassin_data.loc_date==loc_date, 'samp_total'] = qty_sample[[loc_date]][0]\n",
    "\n",
    "# the % of total for that object for the survey defined by loc_date\n",
    "som_bassin_data['sample_% _of_total'] = som_bassin_data.quantity/som_bassin_data.samp_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12364\n"
     ]
    }
   ],
   "source": [
    "def save_describe(x):\n",
    "    data=x.describe()\n",
    "    return data.values\n",
    "\n",
    "# save the key values from the original data:\n",
    "q_before = save_describe(som_bassin_data.quantity)\n",
    "pc_befor = save_describe(som_bassin_data.pcs_m)\n",
    "print(som_bassin_data.quantity.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True False  True  True  True  True  True]\n",
      "12364\n",
      "[ True  True  True  True  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "# rank the quantity found of each code in each survey for all locations\n",
    "ranked = []\n",
    "\n",
    "# the loc_date values to aggregate:\n",
    "locs = som_bassin_data.loc_date.unique()\n",
    "\n",
    "# for each value in loc_date:\n",
    "sbd = som_bassin_data.copy()\n",
    "for a_samp in locs:\n",
    "    # sort the values for each survey by \n",
    "    sbdl = sbd[sbd.loc_date == a_samp].sort_values(by='quantity', ascending=False)\n",
    "    sbdl = sbdl.set_index(np.arange(1, len(sbdl)+1), drop=True)\n",
    "    sbdl['sample_rank'] = sbdl.index\n",
    "    ranked.append(sbdl)\n",
    "    \n",
    "# new data with amplitude rankings for each record\n",
    "sbd = pd.concat(ranked, ignore_index=True)\n",
    "\n",
    "# check the key values before and after:\n",
    "print(q_before == sbd.quantity.describe().values)\n",
    "print(sbd.quantity.sum())\n",
    "print(pc_befor == sbd.pcs_m.describe().values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'code', 'pcs_m', 'quantity', 'location', 'loc_date',\n",
       "       'water_name', 'groupname', 'type', 'population', 'string_date',\n",
       "       'region', 'city', 'fail', 'nsamps', 'samp_total', 'sample_% _of_total',\n",
       "       'sample_rank'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " objects grouped by code and sorted by quantity found: \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "code\n",
       "G27     2302\n",
       "G78      953\n",
       "G79      815\n",
       "G30      804\n",
       "G67      750\n",
       "G200     636\n",
       "G81      538\n",
       "G941     366\n",
       "G117     278\n",
       "G74      259\n",
       "Name: quantity, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n objects grouped by code and sorted by quantity found: \\n\\n\")\n",
    "sbd[sbd.quantity > 0].groupby(['code']).quantity.sum().sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " objects grouped by code and sorted by median pcs-m: \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "code\n",
       "G122    0.580\n",
       "G144    0.235\n",
       "G27     0.180\n",
       "G78     0.150\n",
       "G119    0.135\n",
       "G79     0.100\n",
       "G67     0.090\n",
       "G5      0.090\n",
       "G200    0.090\n",
       "G30     0.090\n",
       "Name: pcs_m, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n objects grouped by code and sorted by median pcs-m: \\n\\n\")\n",
    "sbd[sbd.quantity > 0].groupby(['code']).pcs_m.median().sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " objects grouped by code and sorted by quantity found: \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "code\n",
       "G27     2302\n",
       "G78      953\n",
       "G79      815\n",
       "G30      804\n",
       "G67      750\n",
       "G200     636\n",
       "G81      538\n",
       "G941     366\n",
       "G117     278\n",
       "G74      259\n",
       "Name: quantity, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n objects grouped by code and sorted by quantity found: \\n\\n\")\n",
    "sbd[sbd.quantity > 0].groupby(['code']).quantity.sum().sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " objects grouped by code and sorted by number of times at least one was found: \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "code\n",
       "G27     105\n",
       "G79     104\n",
       "G30     102\n",
       "G67      94\n",
       "G78      93\n",
       "G200     85\n",
       "G81      69\n",
       "G82      65\n",
       "G89      62\n",
       "G177     62\n",
       "Name: fail, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n objects grouped by code and sorted by number of times at least one was found: \\n\\n\")\n",
    "sbd[sbd.quantity > 0].groupby(['code']).fail.sum().sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample rank: how much of the sample total was taken up by this object analogous to % of sample total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " objects grouped by water feature and code, sorted by frequency of sample ranking: \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>water_name</th>\n",
       "      <th>code</th>\n",
       "      <th>sample_rank</th>\n",
       "      <th>loc_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1328</th>\n",
       "      <td>Neuenburgersee</td>\n",
       "      <td>G27</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>Neuenburgersee</td>\n",
       "      <td>G79</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>Thunersee</td>\n",
       "      <td>G27</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>Neuenburgersee</td>\n",
       "      <td>G78</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>Bielersee</td>\n",
       "      <td>G27</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>Bielersee</td>\n",
       "      <td>G941</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>Bielersee</td>\n",
       "      <td>G940</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>Bielersee</td>\n",
       "      <td>G940</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>Bielersee</td>\n",
       "      <td>G940</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2269</th>\n",
       "      <td>Thunersee</td>\n",
       "      <td>G98</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2270 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          water_name  code  sample_rank  loc_date\n",
       "1328  Neuenburgersee   G27            1        22\n",
       "1517  Neuenburgersee   G79            3        12\n",
       "1985       Thunersee   G27            1        11\n",
       "1503  Neuenburgersee   G78            2         8\n",
       "444        Bielersee   G27            1         8\n",
       "...              ...   ...          ...       ...\n",
       "825        Bielersee  G941            8         1\n",
       "819        Bielersee  G940           26         1\n",
       "818        Bielersee  G940           13         1\n",
       "817        Bielersee  G940           12         1\n",
       "2269       Thunersee   G98           34         1\n",
       "\n",
       "[2270 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n objects grouped by water feature and code, sorted by frequency of sample ranking: \\n\\n\")\n",
    "sbd[sbd.quantity > 0].groupby(['water_name','code', 'sample_rank'], as_index=False).loc_date.nunique().sort_values(by='loc_date', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " objects grouped by water feature and code, sorted by quantity found: \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>water_name</th>\n",
       "      <th>code</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>Neuenburgersee</td>\n",
       "      <td>G27</td>\n",
       "      <td>898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Bielersee</td>\n",
       "      <td>G27</td>\n",
       "      <td>669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>Thunersee</td>\n",
       "      <td>G27</td>\n",
       "      <td>553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Bielersee</td>\n",
       "      <td>G78</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>Bielersee</td>\n",
       "      <td>G79</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>Neuenburgersee</td>\n",
       "      <td>G103</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>Neuenburgersee</td>\n",
       "      <td>G107</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>Neuenburgersee</td>\n",
       "      <td>G111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>Neuenburgersee</td>\n",
       "      <td>G119</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>La Thièle</td>\n",
       "      <td>G82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>590 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         water_name  code  quantity\n",
       "364  Neuenburgersee   G27       898\n",
       "142       Bielersee   G27       669\n",
       "524       Thunersee   G27       553\n",
       "175       Bielersee   G78       362\n",
       "176       Bielersee   G79       322\n",
       "..              ...   ...       ...\n",
       "300  Neuenburgersee  G103         1\n",
       "303  Neuenburgersee  G107         1\n",
       "305  Neuenburgersee  G111         1\n",
       "309  Neuenburgersee  G119         1\n",
       "295       La Thièle   G82         1\n",
       "\n",
       "[590 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n objects grouped by water feature and code, sorted by quantity found: \\n\\n\")\n",
    "sbd[sbd.quantity > 0].groupby(['water_name','code'], as_index=False).quantity.sum().sort_values(by='quantity', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " objects grouped by water feature and code, sorted by median pcs_m: \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>water_name</th>\n",
       "      <th>code</th>\n",
       "      <th>pcs_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>Brienzersee</td>\n",
       "      <td>G27</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Aare</td>\n",
       "      <td>G98</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>Brienzersee</td>\n",
       "      <td>G78</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Bielersee</td>\n",
       "      <td>G204</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Bielersee</td>\n",
       "      <td>G122</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>Neuenburgersee</td>\n",
       "      <td>G84</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>Neuenburgersee</td>\n",
       "      <td>G13</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Aare|Nidau-Büren-Kanal</td>\n",
       "      <td>G30</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>Thunersee</td>\n",
       "      <td>G159</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>Thunersee</td>\n",
       "      <td>G98</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>590 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 water_name  code  pcs_m\n",
       "246             Brienzersee   G27   1.00\n",
       "54                     Aare   G98   0.97\n",
       "265             Brienzersee   G78   0.61\n",
       "131               Bielersee  G204   0.59\n",
       "86                Bielersee  G122   0.58\n",
       "..                      ...   ...    ...\n",
       "398          Neuenburgersee   G84   0.01\n",
       "313          Neuenburgersee   G13   0.01\n",
       "64   Aare|Nidau-Büren-Kanal   G30   0.01\n",
       "491               Thunersee  G159   0.01\n",
       "589               Thunersee   G98   0.01\n",
       "\n",
       "[590 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n objects grouped by water feature and code, sorted by median pcs_m: \\n\\n\")\n",
    "sbd[sbd.quantity > 0].groupby(['water_name','code'], as_index=False).pcs_m.median().sort_values(by='pcs_m', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get sample rates at the group level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fail(x):\n",
    "    a_q = x.sum()\n",
    "    if a_q > 0:\n",
    "        data = True\n",
    "    else:\n",
    "        data = False\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>water_name</th>\n",
       "      <th>type</th>\n",
       "      <th>loc_date</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>groupname</th>\n",
       "      <th>nsamps</th>\n",
       "      <th>samp_total</th>\n",
       "      <th>quantity</th>\n",
       "      <th>pcs_m</th>\n",
       "      <th>fail</th>\n",
       "      <th>sample_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bielersee</td>\n",
       "      <td>l</td>\n",
       "      <td>(bielersee_vinelz_fankhausers, 2021-03-25)</td>\n",
       "      <td>2021-03-25</td>\n",
       "      <td>bielersee_vinelz_fankhausers</td>\n",
       "      <td>fragmented plastics</td>\n",
       "      <td>12.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>19</td>\n",
       "      <td>1.11</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bielersee</td>\n",
       "      <td>l</td>\n",
       "      <td>(bielersee_vinelz_fankhausers, 2021-03-25)</td>\n",
       "      <td>2021-03-25</td>\n",
       "      <td>bielersee_vinelz_fankhausers</td>\n",
       "      <td>food</td>\n",
       "      <td>12.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.53</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bielersee</td>\n",
       "      <td>l</td>\n",
       "      <td>(bielersee_vinelz_fankhausers, 2021-03-25)</td>\n",
       "      <td>2021-03-25</td>\n",
       "      <td>bielersee_vinelz_fankhausers</td>\n",
       "      <td>construction</td>\n",
       "      <td>12.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.36</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bielersee</td>\n",
       "      <td>l</td>\n",
       "      <td>(bielersee_vinelz_fankhausers, 2021-03-25)</td>\n",
       "      <td>2021-03-25</td>\n",
       "      <td>bielersee_vinelz_fankhausers</td>\n",
       "      <td>waste water</td>\n",
       "      <td>12.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.24</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bielersee</td>\n",
       "      <td>l</td>\n",
       "      <td>(bielersee_vinelz_fankhausers, 2021-03-25)</td>\n",
       "      <td>2021-03-25</td>\n",
       "      <td>bielersee_vinelz_fankhausers</td>\n",
       "      <td>agg-con-trans</td>\n",
       "      <td>12.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.18</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  water_name type                                    loc_date       date  \\\n",
       "0  Bielersee    l  (bielersee_vinelz_fankhausers, 2021-03-25) 2021-03-25   \n",
       "1  Bielersee    l  (bielersee_vinelz_fankhausers, 2021-03-25) 2021-03-25   \n",
       "2  Bielersee    l  (bielersee_vinelz_fankhausers, 2021-03-25) 2021-03-25   \n",
       "3  Bielersee    l  (bielersee_vinelz_fankhausers, 2021-03-25) 2021-03-25   \n",
       "4  Bielersee    l  (bielersee_vinelz_fankhausers, 2021-03-25) 2021-03-25   \n",
       "\n",
       "                       location            groupname  nsamps  samp_total  \\\n",
       "0  bielersee_vinelz_fankhausers  fragmented plastics    12.0        53.0   \n",
       "1  bielersee_vinelz_fankhausers                 food    12.0        53.0   \n",
       "2  bielersee_vinelz_fankhausers         construction    12.0        53.0   \n",
       "3  bielersee_vinelz_fankhausers          waste water    12.0        53.0   \n",
       "4  bielersee_vinelz_fankhausers        agg-con-trans    12.0        53.0   \n",
       "\n",
       "   quantity  pcs_m  fail  sample_rank  \n",
       "0        19   1.11  True            1  \n",
       "1         9   0.53  True            2  \n",
       "2         6   0.36  True            3  \n",
       "3         4   0.24  True            4  \n",
       "4         3   0.18  True            5  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbd_g = sbd.groupby(['water_name', 'type', 'loc_date', 'date', 'location', 'groupname', 'nsamps', 'samp_total'], as_index=False).agg({'quantity':'sum', 'pcs_m':'sum', 'fail':calculate_fail})\n",
    "\n",
    "sbd_g_ranked = []\n",
    "for a_samp in locs:\n",
    "    # sort the values for each survey by \n",
    "    sbdl = sbd_g.loc[sbd_g.loc_date==a_samp].sort_values(by='quantity', ascending=False)\n",
    "    sbdl = sbdl.set_index(np.arange(1, len(sbdl)+1), drop=True)\n",
    "    sbdl['sample_rank'] = sbdl.index\n",
    "    sbd_g_ranked.append(sbdl)\n",
    "sbd_g_ranked[0]\n",
    "sbd_gr = pd.concat(sbd_g_ranked, ignore_index=True)\n",
    "sbd_gr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "groupname\n",
      "agg-con-trans           1\n",
      "construction            1\n",
      "food                   13\n",
      "fragmented plastics    11\n",
      "less than 5mm           1\n",
      "recreation              1\n",
      "tobacco                 8\n",
      "Name: sample_rank, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "fd = sbd_gr[(sbd_gr.water_name=='Bielersee')&(sbd_gr.sample_rank==1)].groupby('groupname').sample_rank.sum()\n",
    "fd.sum()\n",
    "print(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "water_name  groupname          \n",
       "Aare        agg-con-trans           6\n",
       "            agriculture             5\n",
       "            construction            6\n",
       "            food                    5\n",
       "            fragmented plastics     8\n",
       "                                   ..\n",
       "Thunersee   personal items          8\n",
       "            recreation             10\n",
       "            the rest               10\n",
       "            tobacco                 9\n",
       "            waste water             7\n",
       "Name: sample_rank, Length: 96, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbd_gr.groupby(['water_name','groupname']).sample_rank.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (<ipython-input-31-6aaf1f276005>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-31-6aaf1f276005>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by code and location. keep the columns that are specific to the location\n",
    "# agg results: pieces per meter and quantity. count the number of samples for this code and location\n",
    "sbd_ranked = som_bassin_data.groupby(['code','rank','location', 'population', 'groupname','l_weight','type'], as_index=False).agg({'pcs_m':'median', 'loc_date':'count', 'quantity':'sum'})\n",
    "\n",
    "# recalculate the % of total for the group levels\n",
    "# the sum of this col should equal one\n",
    "sbd_ranked['% of total'] = sbd_ranked.quantity/sbd_ranked.quantity.sum()\n",
    "\n",
    "# house keeping\n",
    "# the number of surveys is equal to the number of unique loc_values\n",
    "sbd_ranked.rename(columns={'loc_date':'n_times'}, inplace=True)\n",
    "\n",
    "# calculate the weight of the sample in reference to all other samples\n",
    "# the sum of rank_weight should equal one\n",
    "sbd_ranked['n_weight'] = sbd_ranked.n_times/len(locs)\n",
    "\n",
    "print(F\"Check the n_weight sum:{sbd_ranked.n_weight.sum()}\\n\\nCheck the % of total column: {sbd_ranked['% of total'].sum()}\\n\")\n",
    "\n",
    "print(F\"The number of times that G27 is ranked one: {len(som_bassin_data[(som_bassin_data.code == 'G27')&(som_bassin_data['rank'] == 1)])}\\n\")\n",
    "\n",
    "# aggregate and check:\n",
    "rank_and_code = sbd_ranked.groupby(['rank','code','location'], as_index=False).n_times.sum()\n",
    "print(F\"The aggregated values should be the same: {rank_and_code[(rank_and_code.code == 'G27')&(rank_and_code['rank'] == 1)].n_times.sum()}\\n\")\n",
    "\n",
    "print(F\"The locations where G27 was number one at least once: \\n\\n{rank_and_code[(rank_and_code.code == 'G27')&(rank_and_code['rank'] == 1)].location.unique()}\")\n",
    "print(F\"\\nG27 has been the number one at least once at {np.round((len(rank_and_code[(rank_and_code.code == 'G27')&(rank_and_code['rank'] == 1)].location.unique())/len(som_bassin_data.location.unique())*100),0)}% of the locations sampled\")\n",
    "\n",
    "print(F\"\\nG27 has been the number one object at a survey {np.round((len(som_bassin_data[(som_bassin_data.code == 'G27')&(som_bassin_data['rank'] == 1)])/len(som_bassin_data.loc_date.unique()))*100, 0)}% of the time\\n\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_number_one_ranks = rank_and_code[rank_and_code['rank'] == 1].groupby(['code','location'], as_index=False).n_times.sum()\n",
    "print(F\"Codes and the number of times that they have been the number one item at a survey\\n{other_number_one_ranks.groupby('code').n_times.sum().sort_values(ascending=False)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project directory is 'output/bielsummary'\n",
    "sbd_ranked.to_csv(F\"{project_directory}/aare_codes_ranked.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "these_codes = ['G27', 'G30','G25', 'G81', 'G95', 'G67','G82']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped by survey and code group\n",
    "sbd_ranked_gs = som_bassin_data.groupby(['loc_date','groupname','location', 'population'], as_index=False).agg({'pcs_m':'sum', 'quantity':'sum'})\n",
    "\n",
    "sbd_ranked_gs['% of total'] = sbd_ranked_gs.apply(lambda x: x.quantity/qty_sample[x.loc_date], axis=1)\n",
    "# save the key values from the original data:\n",
    "q_before = save_describe(sbd_ranked_gs.quantity)\n",
    "pc_befor = save_describe(sbd_ranked_gs.pcs_m)\n",
    "print(sbd_ranked_gs.quantity.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked = []\n",
    "for a_samp in locs:\n",
    "    sbdl = sbd_ranked_gs[sbd_ranked_gs.loc_date == a_samp].sort_values(by='% of total', ascending=False)\n",
    "    sbdl = sbdl.set_index(np.arange(1, len(sbdl)+1), drop=True)\n",
    "    sbdl['rank'] = sbdl.index\n",
    "    ranked.append(sbdl)\n",
    "    \n",
    "sbd_ranked_gs = pd.concat(ranked, ignore_index=True)\n",
    "\n",
    "# check the key values before and after:\n",
    "print(\"Check that the survey values have not been altered:\\n\")\n",
    "print(q_before == sbd_ranked_gs.quantity.describe().values)\n",
    "print(pc_befor == sbd_ranked_gs.pcs_m.describe().values)\n",
    "\n",
    "# check the % of total\n",
    "print(F\"\\nCheck % of total: {sbd_ranked_gs.groupby('loc_date')['% of total'].sum().sum()}\\n\")\n",
    "print(F\"The number of SURVEYS where ALL TOBACCO items combined are rank one: {sbd_ranked_gs[(sbd_ranked_gs.groupname == 'tobacco')&(sbd_ranked_gs['rank'] == 1)].loc_date.nunique()}\\n\")\n",
    "\n",
    "print(F\"All TOBACCO items combined were number one in {np.round((sbd_ranked_gs[(sbd_ranked_gs.groupname == 'tobacco')&(sbd_ranked_gs['rank'] == 1)].loc_date.nunique()/sbd_ranked_gs.loc_date.nunique())*100,0)}% of the surveys.\")\n",
    "print(F\"\\nThe number of locations that tobaco is rank one: {sbd_ranked_gs[(sbd_ranked_gs.groupname == 'tobacco')&(sbd_ranked_gs['rank'] == 1)].location.nunique()}\\n\")\n",
    "print(F\"The objects labeled tobacco:\\n{sbd_ranked[sbd_ranked.groupname == 'tobacco'].code.unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = sbd_ranked_gs.groupby(['rank','groupname','location'], as_index=False).loc_date.nunique()\n",
    "fx = f[f['rank'] == 1].groupby('groupname').loc_date.sum()\n",
    "print(F\"\\nThe number of samples: {fx.sum()}\\n\")\n",
    "print(F\"Other groups and the number of times they have been the most prevalent item:\\n{fx.sort_values(ascending=False)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the pass fail rate for each water feature\n",
    "\n",
    "# the total number of tries:\n",
    "tries_t = som_bassin_data.groupby(['water_name', 'code']).loc_date.nunique()\n",
    "\n",
    "# the total number of times that the object was found for a particular water feature\n",
    "fails_b = som_bassin_data.groupby(['water_name','code']).fail.sum()\n",
    "\n",
    "# the total number of samples:\n",
    "n_samps_b = som_bassin_data.groupby(['water_name']).loc_date.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all values greater than zero for each code and LOCATION\n",
    "grtr_than_zero = som_bassin_data[(som_bassin_data.quantity > 0)].groupby(['code', 'location'], as_index=False).loc_date.count()\n",
    "\n",
    "# weight the result by the sum of the loc_date column\n",
    "grtr_than_zero['weight'] = grtr_than_zero.loc_date/grtr_than_zero.loc_date.sum()\n",
    "\n",
    "# housekeeping\n",
    "som_data = som_bassin_data.copy()\n",
    "\n",
    "# get a list of the codes that were found at least once\n",
    "codes_in_use = grtr_than_zero.code.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the tries and fails dfs for each water feature\n",
    "tries_fails_b = pd.concat([tries_t, fails_b], axis=1)\n",
    "tries_fails_b.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tries_fails_b.iloc[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the ratio of total tries per code and location to total number of samples for that feature\n",
    "for a_b in tries_fails_b.water_name.unique():\n",
    "    tries_fails_b.loc[tries_fails_b.water_name==a_b, 'rate'] = tries_fails_b.fail/n_samps_b.loc[a_b]\n",
    "\n",
    "tries_fails_b.iloc[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the minimum rate is 1/ the current sample number + 1\n",
    "# we are assuming that if the object has never been found before there\n",
    "# is always a chance that we may find it on the next sample\n",
    "# the longer we go without finding it the less likely it is to find in the river basin\n",
    "# which means that once it has been identified this should be considered a significant event.\n",
    "rate_min = 1/(len(a.processed.loc_date.unique())+1)\n",
    "rate_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tries_fails_b.loc[tries_fails_b.fail==0, 'min_rate'] = rate_min\n",
    "tries_fails_b.loc[tries_fails_b.fail>0, 'min_rate'] = tries_fails_b.rate\n",
    "tries_fails_b.iloc[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the ratio samples-per-location/number-samples-catchment-area\n",
    "weights = tries_fails_b[['water_name', 'loc_date']].drop_duplicates().set_index('water_name', drop=True)\n",
    "weights['location_weight'] = weights.loc_date/len(locs)\n",
    "nsamps = weights.loc['Aare', :]\n",
    "\n",
    "# now the number of samples and the weight is available\n",
    "nsamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull some samples from one river basin feature\n",
    "feature = 'Aare'\n",
    "n = weights.loc['Aare', 'loc_date']\n",
    "rates = tries_fails_b.loc[tries_fails_b.water_name == 'Aare'][['code','min_rate']].set_index('code')\n",
    "\n",
    "# store the samples here\n",
    "theta_samples_feature = pd.DataFrame(index=codes_in_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rates.loc['G27'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine wehter or not an object was found at a survey\n",
    "# use the rates for the parameter of a bernouli trial for each code\n",
    "\n",
    "k=0\n",
    "for j in np.arange(n):\n",
    "    k+=1\n",
    "    col_name = F\"s_{int(k)}\"\n",
    "    for a_code in codes_in_use:\n",
    "        theta_samples_feature.loc[a_code, col_name ] = bernoulli.rvs(rates.loc[a_code], size=1)\n",
    "\n",
    "\n",
    "found_feature = theta_samples_feature > 0\n",
    "codes_found_feature = [found_feature[found_feature[s_one] == True][s_one].index for s_one in found_feature.columns]\n",
    "codes_found_len_feature = [len(x) for x in codes_found_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_samps_aare = b.bassin_data[(b.bassin_data.quantity>0)&(b.bassin_data.water_name == \"Aare\")][['loc_date', 'code']].groupby('loc_date').code.unique().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of times each code was found\n",
    "def count_occurences(an_array):\n",
    "    wiw = {}\n",
    "    for a_list in an_array:\n",
    "        for code in a_list:\n",
    "            if code in wiw.keys():\n",
    "                wiw[code] += 1\n",
    "            else:\n",
    "                wiw[code] = 1\n",
    "    return [{'code':k, 'inst':v} for k,v in wiw.items()]\n",
    "theta_codes_count = count_occurences(codes_found_feature)\n",
    "dsamp_aare_count = pd.DataFrame(count_occurences(d_samps_aare)).set_index('code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsamp_aare_count.loc['G7', 'inst']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the counts in to one dataframe and compare results\n",
    "\n",
    "def combine_code_counts(x):\n",
    "    try:\n",
    "        data = dsamp_aare_count.loc[x, 'inst']\n",
    "    except:\n",
    "        data = 0\n",
    "    return data\n",
    "        \n",
    "theta_codes = pd.DataFrame(theta_codes_count)\n",
    "theta_codes['s_inst'] = theta_codes.code.map(lambda x: combine_code_counts(x))\n",
    "theta_codes['inst_dif'] = theta_codes.inst - theta_codes.s_inst\n",
    "\n",
    "# check the diffference between the two sets\n",
    "print(theta_codes['s_inst'].sum())\n",
    "print(theta_codes['inst'].sum())\n",
    "print(theta_codes.inst_dif.sum())\n",
    "print(len(theta_codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_codes[theta_codes.code.isin([x for x in theta_codes.code.unique() if x not in dsamp_aare_count.index])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,1, figsize=(12,8))\n",
    "sns.barplot(data=theta_codes.sort_values(by='s_inst', ascending=False), x='code', y='s_inst', ax=axs[0])\n",
    "sns.barplot(data=theta_codes.sort_values(by='inst', ascending=False), x='code', y='inst', ax=axs[1])\n",
    "axs[0].tick_params(axis='x', labelrotation=90, labelsize=8)\n",
    "axs[1].tick_params(axis='x', labelrotation=90, labelsize=8)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_samples_all = pd.DataFrame(index=codes_in_use)\n",
    "tries = som_bassin_data.groupby(['code']).loc_date.nunique()\n",
    "fails = som_bassin_data.groupby('code').fail.sum()\n",
    "# tries_fails by water body\n",
    "\n",
    "# for one body of water\n",
    "#fails_b = som_bassin_data.groupby(['water_name','code']).fail.sum()\n",
    "\n",
    "tries_fails = pd.concat([tries, fails], axis=1)\n",
    "tries_fails['rate'] = tries_fails.fail/tries_fails.loc_date\n",
    "\n",
    "code_weights = grtr_than_zero.groupby('code').weight.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "for body in weights.index:\n",
    "#     print(body)\n",
    "#     print(tries_fails_b.loc[body].min_rate.sum())\n",
    "    these_rates =tries_fails_b.loc[tries_fails_b.water_name == body][['code','min_rate']].set_index('code')\n",
    "    \n",
    "\n",
    "    for j in np.arange(weights.loc[body]['loc_date']):\n",
    "        k+=1\n",
    "        #print(j, k)\n",
    "        col_name = F\"s_{int(k)} {body}\"\n",
    "        for a_code in codes_in_use:\n",
    "            theta_samples_all.loc[a_code, col_name ] = bernoulli.rvs(these_rates.loc[a_code], size=1)\n",
    "#             theta_samples_all.loc[a_code, col_name ] = binom.rvs(1,these_rates.loc[a_code], size=1)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found = theta_samples_all > 0\n",
    "codes_found = [found[found[s_one] == True][s_one].index for s_one in found.columns]\n",
    "codes_found_len = [len(x) for x in codes_found]\n",
    "\n",
    "print(len(codes_found[0]))\n",
    "print(codes_found_len[0])\n",
    "print(len(codes_found))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tries_fails.iloc[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of unique codes per sample in the project data:\n",
    "d_samps = b.bassin_data[b.bassin_data.quantity>0][['loc_date', 'code']].groupby('loc_date').code.nunique()\n",
    "\n",
    "# the list of codes found at each survey in the project data:\n",
    "d_samps_c = b.bassin_data[b.bassin_data.quantity>0][['loc_date', 'code']].groupby('loc_date').code.unique().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_occurences(an_array):\n",
    "    wiw = {}\n",
    "    for a_list in an_array:\n",
    "        for code in a_list:\n",
    "            if code in wiw.keys():\n",
    "                wiw[code] += 1\n",
    "            else:\n",
    "                wiw[code] = 1\n",
    "    return [{'code':k, 'inst':v} for k,v in wiw.items()]\n",
    "samp_codes = pd.DataFrame(count_occurences(d_samps_c)).set_index('code')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_list_o_list = [value for k, value in samples.items()]\n",
    "# the_list_o_list = [*a_list_o_list]\n",
    "theta_codes = pd.DataFrame(count_occurences(codes_found))\n",
    "theta_codes['s_inst'] = theta_codes.code.map(lambda x: samp_codes.loc[x, 'inst'])\n",
    "theta_codes['inst_dif'] = theta_codes.inst - theta_codes.s_inst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(theta_codes['inst_dif'].sum())\n",
    "print(len(theta_codes))\n",
    "print(theta_codes.inst.sum(), theta_codes.s_inst.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(18,8))\n",
    "sns.barplot(data=theta_codes[theta_codes.inst >=20].sort_values(by='s_inst', ascending=False), x='code', y='s_inst', color='red', alpha=.6, ax=axs)\n",
    "sns.barplot(data=theta_codes[theta_codes.inst >=20].sort_values(by='inst', ascending=False), x='code', y='inst', color='blue',alpha=.6, ax=axs)\n",
    "axs.tick_params(axis='x', labelrotation=90, labelsize=10)\n",
    "# axs[1].tick_params(axis='x', labelrotation=90, labelsize=8)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axs = plt.subplots(1,2)\n",
    "sns.histplot(codes_found_len, ax=axs[0], binwidth=3)\n",
    "sns.histplot(d_samps.values, ax=axs[1], binwidth=3)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# found.rename(columns={x:x.split(\" \")[-1] for x in found.columns}, inplace=True)\n",
    "codes_found = [{'label':s_one.split(\" \")[-1] , 'codes':found[found[s_one] == True][s_one].index.to_numpy()} for s_one in found.columns]\n",
    "# codes_found_len = [len(x) for x in codes_found_feature]\n",
    "a_label = codes_found[1]['label']\n",
    "a_code = codes_found[1]['codes'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_weight = som_bassin_data.groupby('water_name', as_index=False).l_weight.median()\n",
    "location_weight.loc[4, 'water_name'] = \"Thièle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_results_feature = som_bassin_data[som_bassin_data.pcs_m > 0].groupby(['water_name','code']).agg({'pcs_m':['mean', 'min', 'median', 'max']})\n",
    "agg_results_feature.columns = agg_results_feature.columns.get_level_values(1)\n",
    "agg_results_bassin = som_bassin_data[som_bassin_data.pcs_m > 0].groupby(['code']).agg({'pcs_m':['mean', 'min', 'median', 'max']})\n",
    "agg_results_bassin.columns = agg_results_bassin.columns.get_level_values(1)\n",
    "# get the parameters for one code at one sample:\n",
    "this_data = agg_results_feature.loc[a_label,codes_found[1]['codes'][0]]\n",
    "print(this_data['mean'])\n",
    "print(codes_found[1]['codes'][0])\n",
    "print(a_label)\n",
    "loc = this_data['mean']\n",
    "alpha=this_data['min']\n",
    "beta = 1/alpha\n",
    "print(\"\\n the parameters \\n\")\n",
    "print(loc, alpha, beta)\n",
    "\n",
    "print(\"\\nthe predicted result \\n\")\n",
    "print(gamma.rvs(alpha, loc=loc, scale=beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_results_feature.loc['Aare','G101']['min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hmm = pd.DataFrame(codes_found).explode('codes').copy()\n",
    "# hmm.drop_duplicates(inplace=True)\n",
    "# print(hmm.isnull().values.any())\n",
    "# hmm.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_params(a_label, a_code, a_param, params):\n",
    "    default_params = agg_results_bassin\n",
    "    try:\n",
    "        this_param = params.loc[a_label,a_code][a_param]\n",
    "    except:\n",
    "        this_param = default_params.loc[a_code][a_param]\n",
    "    return this_param\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_samps_d = b.bassin_pcsm_day[['water_name', 'pcs_m']].sort_values(by='pcs_m')\n",
    "o_samps_d.reset_index(inplace=True, drop=True)\n",
    "o_samps_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_weight.set_index('water_name', drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_surveys = []\n",
    "for i,sample in enumerate(codes_found):\n",
    "    a_label = sample['label']\n",
    "    som_codes = sample['codes']\n",
    "    loc_weight = location_weight.loc[a_label]\n",
    "    for a_code in som_codes:\n",
    "        alpha = assign_params(a_label, a_code, 'median', agg_results_feature)\n",
    "        loc = assign_params(a_label, a_code, 'min', agg_results_feature)\n",
    "        scale = assign_params(a_label, a_code, 'max', agg_results_feature)+(5*alpha)       \n",
    "        pcs_m = gamma.rvs(alpha+(loc_weight*alpha), loc=loc, scale=scale)\n",
    "        sim_surveys.append({'code':a_code, 'label':a_label, 'survey':i, 'pcs_m':pcs_m})\n",
    "    \n",
    "new_surveys = pd.DataFrame(sim_surveys)\n",
    "new_surveys_d = new_surveys.groupby(['survey','label'], as_index=False).pcs_m.sum().copy()\n",
    "\n",
    "new_surveys_d.sort_values(by='pcs_m', inplace=True)\n",
    "ns_d = new_surveys_d[['label', 'pcs_m']].reset_index(drop=True).copy()\n",
    "ns_d.rename(columns={'label':'water_name'}, inplace=True)\n",
    "ns_d['label'] = 'sim'\n",
    "o_samps_d['label'] = 'odata'\n",
    "o_samps_d['survey'] = o_samps_d.index\n",
    "ns_d['survey'] =ns_d.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_samps_d['label'] = 'odata'\n",
    "\n",
    "combined = pd.concat([ns_d, o_samps_d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(14,8))\n",
    "sns.scatterplot(data=combined, x='survey', y='pcs_m', style='label', hue='water_name', palette='husl', s=40, ax=axs)\n",
    "# sns.scatterplot(data=o_samps_d, x=o_samps_d.index, y=o_samps_d.pcs_m, hue=o_samps_d.water_name, palette='viridis', ax=axs)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the values for one survey:\n",
    "fig, axs = plt.subplots(figsize=(14,8))\n",
    "sns.boxplot(data=combined, x='water_name', y='pcs_m', hue='label', palette='flare', ax=axs, dodge=True)\n",
    "sns.stripplot(data=combined, x='water_name', y='pcs_m', hue='label', palette='husl', ax=axs)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "these_params = []\n",
    "\n",
    "# get some paramaters from the data.\n",
    "print(\"The codes and the number of samples that the parameters are being drawn from\\n\")\n",
    "for code in samples[0]:\n",
    "    samp_data = som_params[som_params.code == code].pcs_m\n",
    "    # check how many samples there are for this region/district\n",
    "    # if less than minsamps grab the results from the next highest level\n",
    "    minsamps = 65\n",
    "    if len(samp_data) < minsamps:\n",
    "        samp_data = a.processed[(a.processed.code == code)&(a.processed.quantity > 0)].pcs_m\n",
    "        loc = samp_data.min()\n",
    "        alpha = samp_data.mean()\n",
    "        scale = 1/alpha\n",
    "    else:\n",
    "        loc = samp_data.min()\n",
    "        alpha = samp_data.mean()\n",
    "        scale = 1/alpha\n",
    "    print(code, len(samp_data))\n",
    "    these_params.append(dict(code=code, loc=loc, alpha=alpha, scale=scale, data=samp_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "these_params[2]['data'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hopefully that just worked for you\n",
    "\n",
    "if not contact analyst@hammerdirt.ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
