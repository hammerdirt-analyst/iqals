{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Code groups: assessing regional litter survey results. Support text for presentation </span>\n",
    "\n",
    "### <span style=\"color:#008891\">Methods</span>\n",
    "1. data collection\n",
    "2. scope\n",
    "\n",
    "### <span style=\"color:#008891\">Summary data</span>\n",
    "#### <span style=\"color:#008891\">All surveys</span>\n",
    "\n",
    "1. all data\n",
    "2. project lakes\n",
    "\n",
    "### <span style=\"color:#008891\">Code groups</span>\n",
    "\n",
    "1. summary data\n",
    "2. components\n",
    "3. survey results\n",
    "4. monthly median and change\n",
    "5. key values by lake\n",
    "\n",
    "#### <span style=\"color:#008891\">Code groups: Significant events</span>\n",
    "\n",
    "1. definition\n",
    "2. significant events per lake\n",
    "3. frequency of ocurrence per group and lake\n",
    "\n",
    "#### <span style=\"color:#008891\">Regional assessment tools</span>\n",
    "\n",
    "Find the locations on one lake that may be hotspots for litter accumulation. Identify the ones that may be interesting to monitor in the future. Use the provided graphic and map to make your decision.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys, file and nav packages:\n",
    "import os\n",
    "import datetime as dt\n",
    "import csv\n",
    "\n",
    "# math packages:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import datetime as dt \n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "from scipy.stats import kendalltau, pearsonr, spearmanr\n",
    "import math\n",
    "\n",
    "# charting:\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib import ticker\n",
    "import matplotlib.ticker as mtick\n",
    "import seaborn as sns\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from IPython.display import display, Markdown, Latex, HTML\n",
    "\n",
    "# mapping\n",
    "import geopandas as gpd\n",
    "\n",
    "# home brew utitilties\n",
    "import utilities.utility_functions as ut\n",
    "\n",
    "# documenting\n",
    "from IPython.display import Markdown as md\n",
    "\n",
    "\n",
    "# returns the p_value for each test\n",
    "def kendall_pval(x,y):\n",
    "    return kendalltau(x,y)[1]\n",
    "\n",
    "def pearsonr_pval(x,y):\n",
    "    return pearsonr(x,y)[1]\n",
    "\n",
    "def spearmanr_pval(x,y):\n",
    "    return spearmanr(x,y)[1]\n",
    "\n",
    "# convenience functions for tables\n",
    "def make_table_grids(anax):\n",
    "    anax.grid(False)\n",
    "    anax.spines[\"top\"].set_visible(False)\n",
    "    anax.spines[\"right\"].set_visible(False)\n",
    "    anax.spines[\"bottom\"].set_visible(False)\n",
    "    anax.spines[\"left\"].set_visible(False)\n",
    "    return(anax)\n",
    "\n",
    "def table_fonts(a_table, size=12):\n",
    "    a_table.auto_set_font_size(False)\n",
    "    a_table.set_fontsize(size)\n",
    "# variables/arrays that are frequently used:\n",
    "# project lakes\n",
    "\n",
    "the_lakes = [\n",
    "    \"Bielersee\",\n",
    "    \"Walensee\",\n",
    "    \"Lac LÃ©man\",\n",
    "    \"Zurichsee\",\n",
    "    \"Neuenburgersee\",\n",
    "    \"Thunersee\",\n",
    "    \"Lago Maggiore\",\n",
    "    \"Brienzersee\",\n",
    "]\n",
    "\n",
    "# standard formats already in use for charts, these will gradually\n",
    "# define the chart style or output format for the app\n",
    "# you can just apply these as kwargs to different elements...\n",
    "# table kwargs\n",
    "table_k = dict(loc=\"top left\", bbox=(0,0,1,1), colWidths=[.5, .5], cellLoc='center')\n",
    "tablecenter_k = dict(loc=\"top left\", bbox=(0,0,1,1), cellLoc='center')\n",
    "tabtickp_k = dict(axis='both', which='both', bottom=False, top=False, left=False, right=False, labelleft=False, labelbottom=False)\n",
    "\n",
    "# chart kwargs\n",
    "title_k = {'loc':'left', 'pad':12, 'linespacing':1.5, 'fontsize':12}\n",
    "title_k14 = {'loc':'left', 'pad':12, 'linespacing':1.5, 'fontsize':14}\n",
    "title_k20 = {'loc':'left', 'pad':10, 'linespacing':1.5, 'fontsize':12, 'color':'dodgerblue'}\n",
    "title_k17 = {'loc':'left', 'pad':10, 'linespacing':1.5, 'fontsize':12, 'color':'salmon'}\n",
    "titler_k20 = {'loc':'right', 'pad':10, 'linespacing':1.5, 'fontsize':12, 'color':'dodgerblue'}\n",
    "titler_k17 = {'loc':'right', 'pad':10, 'linespacing':1.5, 'fontsize':12, 'color':'salmon'}\n",
    "xlab_k = {'labelpad':10, 'fontsize':12}\n",
    "ylab_k = {'labelpad':14, 'fontsize':14}\n",
    "titler_k = {'loc':'right', 'pad':10, 'linespacing':1.5, 'fontsize':12}\n",
    "label45r = {'rotation':45, 'ha':'right'}\n",
    "label45c = {'rotation':45, 'ha':'center'}\n",
    "\n",
    "# use these to format date axis in charts\n",
    "weeks = mdates.WeekdayLocator(byweekday=1, interval=4)\n",
    "onedayweek = mdates.DayLocator(bymonthday=1, interval=1)\n",
    "everytwoweeks = mdates.WeekdayLocator(byweekday=1, interval=4)\n",
    "\n",
    "months = mdates.MonthLocator(bymonth=[3,6,9,12])\n",
    "bimonthly = mdates.MonthLocator(bymonth=[1,3,5,7,9,11])\n",
    "allmonths = mdates.MonthLocator()\n",
    "wks_fmt = mdates.DateFormatter('%d')\n",
    "mths_fmt = mdates.DateFormatter('%b')\n",
    "\n",
    "# map marker size:\n",
    "markerSize = 100\n",
    "survey_data, location_data, code_defs, stat_ent, geo_data, output = ut.make_local_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "som_names = {\n",
    "    \"waste water\": \"wastewater.json\" ,\n",
    "    \"less than 5mm\":\"codeListMicros.json\",\n",
    "    \"construction\":\"construction.json\",\n",
    "    \"food\":\"foodstuff.json\",\n",
    "    \"agg-con-trans\":\"cat.json\",\n",
    "    \"agriculture\":\"ag.json\",\n",
    "    \"tobacco\":\"tobac.json\",\n",
    "    \"recreation\":\"recreation.json\",    \n",
    "    \"packaging\":\"packaging.json\",\n",
    "    \"personal items\":\"pi.json\",    \n",
    "}\n",
    "def make_group_map(a_dict_of_lists):\n",
    "    wiw = {}\n",
    "    for group in a_dict_of_lists:\n",
    "        keys = a_dict_of_lists[group]\n",
    "        a_dict = {x:group for x in keys}\n",
    "        wiw.update(**a_dict)\n",
    "    return wiw\n",
    "\n",
    "these_groups ={k:ut.json_file_get(F\"{output}/code_groups/{v}\") for k,v in som_names.items()}\n",
    "these_groups.update({\"fragmented plastics\":[\"G79\", \"G78\", \"G75\"]})\n",
    "group_names = list(these_groups.keys())\n",
    "\n",
    "# collect the codes\n",
    "accounted = [v for k,v in these_groups.items()]\n",
    "accounted = [item for a_list in accounted for item in a_list]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'water_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-1a9b600f0159>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;31m# restrict to lakes only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;31m# aggregated to the parent code, which is an MLW code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m \u001b[0mdfS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwater_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthe_lakes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0mdfS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loc_date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdfS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/refactor_process/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5138\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'water_name'"
     ]
    }
   ],
   "source": [
    "# the local file structure. The resources are located in the corresponding directory.\n",
    "\n",
    "\n",
    "# set some parameters:\n",
    "start_date = '2020-04-01'\n",
    "end_date = dt.datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "startyearmonth = '{}/{}'.format(start_date[5:7], start_date[:4])\n",
    "endyearmonth = '{}/{}'.format(end_date[5:7], end_date[:4]) \n",
    "\n",
    "# decide which data to use\n",
    "aggregated = False\n",
    "\n",
    "french_names = {\n",
    "    \"waste water\":\"traitement d'eau\",\n",
    "    \"less than 5mm\":\"moins que 5mm\",\n",
    "    \"construction\":\"construction\",\n",
    "    \"food\":\"alimentation\",\n",
    "    \"agg-con-trans\":\"const-trans-ag\",\n",
    "    \"agriculture\":\"agriculture\",\n",
    "    \"the rest\":\"le rest\",\n",
    "    \"tobacco\":\"tabac\",\n",
    "    \"recreation\": \"recreation\",\n",
    "    \"fragmented plastics\":\"plastiques fragmentÃ©s\",\n",
    "    \"packaging\":\"emballages\",\n",
    "    \"personal items\":\"affaires personnelles\",\n",
    "    \"survey total\":\"total du jour\"\n",
    "}\n",
    "\n",
    "\n",
    "# collect the names:\n",
    "group_names = list(these_groups.keys())\n",
    "\n",
    "# choose a lake:\n",
    "lake = 'Lac LÃ©man'\n",
    "\n",
    "# define a significant event:\n",
    "sig = .9\n",
    "one_minus_sig = (1-sig)\n",
    "\n",
    "# define explanatory variables:\n",
    "expv = ['population','streets','buildings','rivs']\n",
    "\n",
    "# name the folder:\n",
    "name_of_project = 'codegroupsummaryMarch2020'\n",
    "\n",
    "# use this to store things:\n",
    "project_directory = ut.make_project_folder(output, name_of_project)\n",
    "\n",
    "# get the data\n",
    "# aggregated survey data\n",
    "dfAgg = pd.read_csv(F\"{survey_data}/results_with_zeroes_aggregated_parent.csv\")\n",
    "dfAgg['date'] = pd.to_datetime(dfAgg['date'])\n",
    "dfAgg = dfAgg[dfAgg.date >= start_date]\n",
    "dfAgg = dfAgg[dfAgg.location != 'pfafikon-bad']\n",
    "dfAgg['groupname'] = 'nogroup'\n",
    "\n",
    "# non aggregated survey data\n",
    "dfSurveys = pd.read_csv(F\"{survey_data}/results_with_zeroes.csv\")\n",
    "dfSurveys['date'] = pd.to_datetime(dfSurveys['date'])\n",
    "dfSurveys = dfSurveys[dfSurveys.date >= start_date]\n",
    "dfSurveys = dfSurveys[dfSurveys.location != 'pfafikon-bad']\n",
    "dfSurveys['groupname'] = 'nogroup'\n",
    "\n",
    "# beach data\n",
    "dfBeaches = pd.read_csv(F\"{location_data}/beaches_with_ranks.csv\")\n",
    "dfBeaches.set_index('slug', inplace=True)\n",
    "dfBeaches.rename(columns={\"NUMPOINTS\":\"intersects\"}, inplace=True)\n",
    "\n",
    "# code definitions\n",
    "dfCodes = pd.read_csv(F\"{code_defs}/mlw_codes.csv\", index_col='code')\n",
    "\n",
    "cols_to_keep = ['loc_date',\n",
    "                'location',\n",
    "                'water_name',\n",
    "                'date',\n",
    "                'population',\n",
    "               ]\n",
    "\n",
    "# geo data: explantory variables, index by slug and make a map:\n",
    "# dfStreets = pd.read_csv(F\"{geo_data}/exp_variables/strasse_1000.csv\", index_col='slug')['length']\n",
    "# dfBlds = pd.read_csv(F\"{geo_data}/exp_variables/builds_500.csv\", index_col='slug')['surface']\n",
    "# dfRivs = pd.read_csv(F\"{geo_data}/exp_variables/riparian_intersects.csv\", index_col='slug')['NUMPOINTS']\n",
    "\n",
    "# restrict to lakes only\n",
    "# aggregated to the parent code, which is an MLW code\n",
    "dfS = dfAgg.loc[(dfAgg.water_name.isin(the_lakes))].copy()\n",
    "dfS['loc_date'] = zip(dfS.location,dfS.date)\n",
    "\n",
    "# these values are not aggregated:\n",
    "dfNag = dfSurveys.copy()\n",
    "thesecols = ['loc_date',\n",
    "             'location',\n",
    "             'water_name',\n",
    "             'date']\n",
    "\n",
    "# there are somecodes that allways need to be aggregated:\n",
    "dfNagl = dfNag.copy()\n",
    "mapG82 = dfNagl[dfNagl.code.isin(['G82', 'G912'])].groupby(thesecols, as_index=False).agg({'pcs_m':'sum', 'quantity':'sum'})\n",
    "mapG82['code'] = 'G82'\n",
    "mapG81 = dfNagl[dfNagl.code.isin(['G81', 'G911'])].groupby(thesecols, as_index=False).agg({'pcs_m':'sum', 'quantity':'sum'})\n",
    "mapG81['code'] = 'G81'\n",
    "mapG74 = dfNagl[dfNagl.code.isin(['G74', 'G910', 'G909'])].groupby(thesecols, as_index=False).agg({'pcs_m':'sum', 'quantity':'sum'})\n",
    "mapG74['code'] = 'G74'\n",
    "dfnofoam = dfNag.loc[~dfNag.code.isin(['G82', 'G912','G81', 'G911','G74', 'G910', 'G909'])]\n",
    "newdf = pd.concat([dfnofoam,mapG74,mapG81,mapG82])\n",
    "newdfx = newdf.copy()\n",
    "\n",
    "newdf = newdf.loc[(newdf.water_name.isin(the_lakes))&(newdf.date >= start_date)]\n",
    "\n",
    "dfS['population']=dfS.location.map(lambda x: dfBeaches.loc[x]['population'])\n",
    "\n",
    "# these need to be moved to context:\n",
    "# map geo values to aggregated survey results:\n",
    "# dfS['streets'] = dfS.location.map(lambda x: dfStreets.loc[x])\n",
    "# dfS['buildings'] = dfS.location.map(lambda x: dfBlds.loc[x])\n",
    "# dfS['rivs'] = dfS.location.map(lambda x: dfRivs.loc[x])\n",
    "# dfS['pop_streets'] = dfS.population + dfS.streets\n",
    "# dfS['pop_builds'] = dfS.population + dfS.buildings\n",
    "# dfS['streets_builds'] = dfS.streets + dfS.rivs\n",
    "\n",
    "newdf['population']=newdf.location.map(lambda x: dfBeaches.loc[x]['population'])\n",
    "\n",
    "# these need to be moved to context\n",
    "# map geo values to non aggregated survey results:\n",
    "# newdf['streets'] = newdf.location.map(lambda x: dfStreets.loc[x])\n",
    "# newdf['buildings'] = newdf.location.map(lambda x: dfBlds.loc[x])\n",
    "# newdf['rivs'] = newdf.location.map(lambda x: dfRivs.loc[x])\n",
    "# newdf['pop_streets'] = newdf.population + newdf.streets\n",
    "# newdf['pop_builds'] = newdf.population + newdf.buildings\n",
    "# newdf['streets_builds'] = newdf.streets + newdf.buildings\n",
    "\n",
    "if aggregated:\n",
    "    print(\"Using aggregated data\")\n",
    "    useThis = dfS.copy()\n",
    "else:\n",
    "    print(\"Using non aggregated data\")\n",
    "    useThis = newdf.copy()\n",
    "    \n",
    "codes_in_use = useThis.code.unique()\n",
    "\n",
    "# make a code group of the unaccounted for codes:\n",
    "the_rest = [x for x in codes_in_use if x not in accounted]\n",
    "these_groups.update({'the rest':the_rest})\n",
    "group_names = list(these_groups.keys())\n",
    "\n",
    "# map code to group in the survey results\n",
    "a_group_map = make_group_map(these_groups)\n",
    "useThis['groupname'] = useThis.code.map(lambda x: a_group_map[x])\n",
    "\n",
    "# make sure to have acces to this column throughout\n",
    "cols_to_keep.append('groupname')\n",
    "\n",
    "# keep track of the files you are exporting:\n",
    "files_generated = []\n",
    "\n",
    "# method to save\n",
    "def add_output(a_name, a_tag, atype=\"table\", fignum=0, a_list=files_generated):\n",
    "    tableonefile = F\"{project_directory}/{a_name}\"\n",
    "    files_generated.append({'tag':a_tag, 'number':fignum, 'file':tableonefile,'type':atype})\n",
    "    plt.savefig(tableonefile, dpi=300)\n",
    "\n",
    "# save files\n",
    "survey_csv = F\"{project_directory}/survey_data.csv\"\n",
    "files_generated.append(survey_csv)\n",
    "useThis.to_csv(survey_csv, index=False)\n",
    "\n",
    "beaches_csv = F\"{project_directory}/beach_data.csv\"\n",
    "files_generated.append(beaches_csv)\n",
    "dfBeaches.to_csv(beaches_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geo output\n",
    "locs = newdf.location.unique()\n",
    "these_beaches = dfBeaches[dfBeaches.index.isin(locs)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_totals = useThis.groupby(['loc_date','location','water_name', 'date','population'], as_index=False).agg({\"pcs_m\":\"sum\", \"quantity\":\"sum\"})\n",
    "survey_totals.set_index('loc_date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# place to store the summaries\n",
    "regional_summaries = []\n",
    "\n",
    "# creating a summary for each df in groupdfs\n",
    "\n",
    "def account_for_no_vals(x, a_df):\n",
    "    if x in a_df.index:\n",
    "        data = a_df.loc[x].location\n",
    "    else:\n",
    "        data = 0\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_agg = {'location':'nunique', 'loc_date':'nunique', 'pcs_m':'mean', 'quantity':'sum'}\n",
    "agrouper = useThis.groupby(['water_name', 'groupname'])\n",
    "regional_summary = agrouper.agg(this_agg)\n",
    "\n",
    "regions = list(regional_summary.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_defs_codes = {\n",
    "    'G95': 'Coton-tige',\n",
    "    'G100': 'MÃ©dical conteneurs/tubes/ emballages',\n",
    "    'G98': 'Couches - lingettes',\n",
    "    'G96': 'Serviettes hygiÃ©niques / protÃ¨ge-slips / tampons et ...',\n",
    "    'G91': 'Porte-biomasse',\n",
    "    'G133':'PrÃ©servatifs, y compris emballage',\n",
    "    'G144':'Tampons',\n",
    "    'G97': 'RafraÃ®chisseurs de toilettes',\n",
    "    \"G112\":\"Pellets industriels (GPI)\",\n",
    "    \"G117\":\"polystyrÃ¨ne < 5mm\",\n",
    "    \"G106\":\"Fragments de plastique angulaires <5mm\",\n",
    "    \"G103\":\"fragments de plastique arrondis <5mm\",\n",
    "    \"G115\":\"Mousse de plastique <5mm\",\n",
    "    \"G105\":\"fragments de plastique subangulaires <5mm\",\n",
    "    \"G114\":\"Films <5mm\",\n",
    "    \"G118\":\"Petites sphÃ¨res industrielles <5mm\",\n",
    "    \"G123\":\"GranulÃ©s de polyurÃ©thane < 5mm\",\n",
    "    \"G113\":\"Filaments <5mm\",\n",
    "    \"G119\":\"Plastique utilisateur en feuille (>1mm)\",\n",
    "    \"G122\":\"Fragments de plastique ( >1mm)\",\n",
    "    \"G107\":\"Boulettes cylindriques < 5mm\",\n",
    "    \"G108\":\"pastilles de disque <5mm\",\n",
    "    \"G109\":\"Pellets plats <5mm\",\n",
    "    \"G111\":\"GranulÃ©s sphÃ©roÃ¯des < 5mm\",\n",
    "    \"G104\":\"fragments de plastique sous-arrondis <5mm\",\n",
    "    \"G81\":\"Morceaux de polystyrÃ¨ne expansÃ© 0,5cm - 2,5cm\",\n",
    "    \"G82\":\"Mousse de polystyrÃ¨ne ; perles/billes expansÃ©es 2,5 cm\",\n",
    "    \"G74\":\"Mousse de plastique pour l'isolation thermique ou ...\",\n",
    "    \"G89\":\"DÃ©chets de construction en plastique\",\n",
    "    \"G73\":\"Articles et piÃ¨ces en mousse (sans emballage ou... liÃ©s)\",\n",
    "    \"G22\":\"Couvercles pour produits chimiques, dÃ©tergents (non alimentaires)\",\n",
    "    \"G66\":\"sangles/bandes ; fermeture de paquet en plastique dur\",\n",
    "    \"G921\":\"Carreaux et piÃ¨ces de cÃ©ramique\",\n",
    "    \"G908\": \"Ruban ; Ã©lectrique, isolant\",\n",
    "    \"G186\":\"DÃ©bris industriels\",\n",
    "    \"G93\": \"Colson, zip-ties\",\n",
    "    \"G87\": \"Ruban adhÃ©sif, masquage/conduit/emballage\",\n",
    "    \"G194\":\"CÃ¢bles, fil(s) mÃ©tallique(s) souvent Ã  l'intÃ©rieur du caoutchouc ou...\",\n",
    "    \"G931\":\"Ruban adhÃ©sif pour barriÃ¨re, police, construction\",\n",
    "    \"G68\":\"Fragments de fibre de verre\",\n",
    "    \"G83\":\"PiÃ¨ces en polystyrÃ¨ne > 50cm\",\n",
    "    \"G17\":\"Cartouche pour pistolet d'injection\",\n",
    "    \"G174\":\"Bombes aÃ©rosols\",\n",
    "    \"G190\":\"Bidons de peinture\",\n",
    "    \"G188\":\"Autres bidons < 4 L\",\n",
    "    \"G27\": \"MÃ©gots et filtres Ã  cigarettes\", \n",
    "    \"G30\": \"Emballages alimentaires ; emballages de bonbons, de snacks\", \n",
    "    \"G21\": \"Couvercles de bouteilles\", \n",
    "    \"G25\": \"Tabac ; emballages en plastique, conteneurs\", \n",
    "    \"G24\" :\"Couvercle/anneaux de fermeture de bouteilles/rÃ©cipients en plastique\", \n",
    "    \"G35\": \"Pailles et agitateurs\", \n",
    "    \"G31\": \"BÃ¢tonnets de sucette\", \n",
    "    \"G32\": \"Jouets et faveurs de fÃªte\", \n",
    "    \"G33\": \"Gobelets, couvercles, mousse Ã  usage unique et plastique dur\", \n",
    "    \"G34\": \"Couverts, assiettes et plateaux palstique\",\n",
    "    \"G67\":\"BÃ¢che plastique industrielle\",\n",
    "    \"G38\":\"Couvertures ; emballages en plastique gros calibre\",\n",
    "    \"G204\" :\"MatÃ©riaux de construction ; briques, tuyaux, ciment\",\n",
    "    \"G191\" :\"Fils et grillages\",\n",
    "    \"G170\" :\"Bois (transformÃ©)\",\n",
    "    \"G161\" :\"Bois transformÃ©\",\n",
    "    \"G919\" :\"Clous, vis, boulons, etc.\",\n",
    "    \"G171\" :\"Autre bois < 50cm\",\n",
    "    \"G13\":\"Bouteilles, conteneurs, fÃ»ts pour le transport, le stockage\",\n",
    "    \"G14\": \"Bouteilles d'huile moteur\",\n",
    "    \"G172\":\"Autres bois > 50cm\",\n",
    "    \"G41\":\"Gant industriel/professionnel\",\n",
    "    \"G936\":\"Film sur les serres\",\n",
    "    \"G937\":\"AppÃ¢ts Ã  phÃ©romones pour les vignobles\",\n",
    "    \"G943\":\"ClÃ´turer l'agriculture, plastique\",\n",
    "    \"G36\":\"Sacs/sacs en plastique rÃ©sistant pour 25 kg ou plus\",\n",
    "    \"G81\":\"Morceaux de polystyrÃ¨ne expansÃ© 0,5cm - 2,5cm\",\n",
    "    \"G30\":\"Emballages alimentaires ; emballages de bonbons, de snacks\",\n",
    "    \"G67\":\"Feuilles industrielles\",\n",
    "    \"G82\":\"Mousse de polystyrÃ¨ne; perles/billes expansÃ©es > 2,5 cm -\",\n",
    "    \"G74\":\"Mousse de plastique pour l'isolation thermique ou ...\",\n",
    "    \"G117\": \"PolystyrÃ¨ne expansÃ©e < 5mm\",\n",
    "    \"G89\":\"DÃ©chets de construction en plastique\",\n",
    "    \"G21\":\"Couvercles de boissons\",\n",
    "    \"G24\":\"Couvercle/anneaux de fermeture de bouteilles/rÃ©cipients en plastique\",\n",
    "    \"G23\":\"Couvercles non identifiÃ©s\",\n",
    "    \"G73\":\"Articles et piÃ¨ces en mousse (sans emballage ou... liÃ©s)\",\n",
    "    \"G22\":\"Couvercles pour produits chimiques, dÃ©tergents (non alimentaires)\",\n",
    "    \"G78\":\"Plastiques fragmentÃ©s .5mm < x < 25mm\",\n",
    "    \"G79\":\"Plastiques fragmentÃ©s x > 25mm\",\n",
    "    \"G200\":\"verre brisÃ© \",\n",
    "    \"G10\":\"Emballage fast food\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a table for key statistics:\n",
    "somdata = survey_totals\n",
    "a_sum = pd.DataFrame(somdata.pcs_m.describe()[1:].round(2)).T\n",
    "a_sum_table = [[x] for x in a_sum.values[0]]\n",
    "rowLabels = [x for x in list(a_sum.columns)]\n",
    "\n",
    "\n",
    "def map_to_group_type(x):\n",
    "    if x in ['diffusion','less than 5mm']:\n",
    "        thistype = 'phys'\n",
    "    else:\n",
    "        thistype = 'econ'\n",
    "    return thistype\n",
    "limit=50\n",
    "def count_k(a_string, limit):\n",
    "    split = a_string.split(\" \")\n",
    "    total = 0\n",
    "    new_words = []\n",
    "    for i,word in enumerate(split):\n",
    "        if (total + len(word))+1 >= limit:\n",
    "            thisnewword = F\"{split[i-1]}...\"\n",
    "            if (len(thisnewword) + total) <= limit:\n",
    "                del new_words[-1]\n",
    "                new_words.append(thisnewword)\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            total += len(word)+1\n",
    "            new_words.append(word)\n",
    "\n",
    "    return \" \".join(new_words)\n",
    "\n",
    "colors = ['dodgerblue', 'salmon', 'teal', 'red','maroon','goldenrod', 'mediumspringgreen', 'slategray','olive','yellowgreen', 'purple', 'orange', 'cyan']\n",
    "grouppalette = {x:colors[i] for i,x in enumerate(group_names)}\n",
    "\n",
    "\n",
    "is_french = False\n",
    "is_german = False\n",
    "is_italian = False\n",
    "\n",
    "french_sum_names = {\"survey total\":\"total de l'enquÃªte\", **french_names}\n",
    "thing = 'objets'\n",
    "parent = \"de l'ensemble\"\n",
    "french_pcm = \"piÃ¨ces par mÃ¨tre\"\n",
    "french_srs = \"rÃ©sultats des recensements\"\n",
    "french_pcg = \"par groupe de codes\"\n",
    "french_pct = \"pourcentage du total\"\n",
    "french_med = \"mÃ©dian\"\n",
    "french_mm = \"mÃ©diane mensuelle\"\n",
    "french_change = 'changement'\n",
    "french_bg = \"par groupe\"\n",
    "french_nooutliers = \"les valeurs extrÃªmes ne sont pas indiquÃ©es\"\n",
    "french_columns = {'code':'code','description': 'description', 'material':'matÃ©riel', 'quantity':'quantitÃ©', '% of total':'% du total', 'group':'groupe'}\n",
    "of_prep= 'de'\n",
    "frname = [v for k,v in french_names.items()]\n",
    "frpalette = {french_names[x]:grouppalette[x] for x in grouppalette}\n",
    "summary_row_fr = ['moy', 'et', 'min', '25%', '50%', '75%', 'max']\n",
    "french_key_values = \"valeurs clÃ©s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_french:    \n",
    "    sommarkdown = \"\"\"### <span style='color:#1e90ff'>MÃ©thodes</span>\\n#### <span style='color:#008891'>Source des donnÃ©es, calendrier, portÃ©e gÃ©ographique et mÃ©thodes de collecte</span>\\n\n",
    "    Les donnÃ©es utilisÃ©es pour cette analyse sont les rÃ©sultats d'enquÃªtes sur les dÃ©chets de plage menÃ©es en Suisse. Toutes les enquÃªtes qui ont Ã©tÃ© menÃ©es sur le lac de Bienne, le lac de NeuchÃ¢tel, le lac de Thoune, le lac Walensee, le lac de Zurich, le lac LÃ©man, le lac Brienze et le lac Magiore ont Ã©tÃ© prises en compte.\\n\n",
    "    Les donnÃ©es ont Ã©tÃ© collectÃ©es selon le protocole dÃ©crit ici https://www.plagespropres.ch/. En bref, toutes les dÃ©chets visibles sont collectÃ©es le long d'une plage Ã  une distance mesurÃ©e du bord de l'eau. La largeur de la zone d'Ã©tude dÃ©pend du terrain et du niveau de l'eau. La ligne de rive visible ou la structure physique la plus proche dÃ©finit la largeur d'une enquÃªte (figure 1).\\n\n",
    "    Des enquÃªtes ont Ã©tÃ© menÃ©es par:\\n\n",
    "    1. hammerdirt\n",
    "    2. Association pour le Sauvegarde du leman\n",
    "    3. Solid Waste Management Ecole Polytechnique Federal\n",
    "    4. Ecole International de Geneve\n",
    "    5. Precious plastic leman\n",
    "    6. Why isn't your association here?\\n\n",
    "    Cette analyse est un document open source. Le cahier de notes de travail est disponible dans le dÃ©pÃ´t situÃ© ici: https://github.com/hammerdirt-analyst/iqals.\\n\n",
    "    \n",
    "    \"\"\"\n",
    "else:\n",
    "    sommarkdown = \"\"\"### <span style=\"color:#1e90ff\">Methods</span>\\n#### <span style=\"color:#008891\">Data source, time frame, geographic scope and collection methods </span>\\n\n",
    "    The data for this analysis is the results from beach-litter surveys conducted in Switzerland.\\n\n",
    "    All surveys that were conducted on Bielersee, Neuenburgersee, Thunersee, Walensee, Zurichsee, Lac LÃ©man, Brienzersee and Lago Magiore were considered.\\n \n",
    "    The data was collected according to the protocol described here https://www.plagespropres.ch/. In brief all visible data is collected along a beach within a measured distance from the waters edge. The width of the survey area depends on the terrain and the water level. The visible strand line or the nearest physical structure defines the width of a survey (figure 1).\\n\n",
    "    Surveys were conducted by the following organizations:\\n\n",
    "    1. hammerdirt\n",
    "    2. Association pour le Sauvegarde du leman\n",
    "    3. Solid Waste Management Ecole Polytechnique Federal\n",
    "    4. Ecole International de Geneve\n",
    "    5. Precious plastic leman\n",
    "    6. Why isn't your association here?\\n\n",
    "    This analysis is an open source document. The working note book is available in the repository located here https://github.com/hammerdirt-analyst/iqals.\\n\n",
    "\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(sommarkdown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "figure_num = 1\n",
    "map_num = 1\n",
    "\n",
    "plt.axvspan(xmin=0, xmax=1, fc='antiquewhite', label='littoral')\n",
    "plt.axvspan(xmin=0.6, xmax=1, fc='dodgerblue', label='lac/riviÃ¨re')\n",
    "# plt.axvspan(xmin=0.2, xmax=0.5, fc='None', label='debris field')\n",
    "plt.axvspan(xmin=0.2, xmax=0.6, fc='None', ec='tan', hatch=\"x\", label=\"zone d'intÃ©rÃªt\")\n",
    "plt.axvspan(xmin=0.19, xmax=0.6, ymin=0.2, ymax=0.8, fc='salmon', alpha=0.4, ec='black', linewidth=8, label='zone de recensement')\n",
    "plt.axvline(x=0.2, linestyle=\":\",  c='tan', linewidth=8, label =\"plus haut ligne de rive\" )\n",
    "plt.axvline(x=0.19, linestyle=\":\",  c='tan', linewidth=8 )\n",
    "ax.annotate(\"zone de recensement\", xy=(0.4, 0.5), xycoords=\"data\",\n",
    "                  va=\"center\", ha=\"center\", size=20,\n",
    "                  bbox=dict(boxstyle=\"round\", fc=\"w\"))\n",
    "\n",
    "make_table_grids(ax)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.suptitle(F\"Figure {figure_num}: schÃ©ma d'un recensement\", x=0.16, fontsize=18, y=0.92,ha='left')\n",
    "plt.legend(fontsize=(14), framealpha=1, bbox_to_anchor=(0.6, .9), loc='upper left')\n",
    "\n",
    "figname = F\"figure{figure_num}.jpg\"\n",
    "atype = \"figure\"\n",
    "add_output(figname,  'schematic of a survey', fignum=figure_num, atype=atype)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_french:\n",
    "    sommarkdown = \"\"\"#### <span style=\"color:#008891\">Scope of surveys</span>\\n\n",
    "    Le champ d'application des enquÃªtes comprend toutes les berges accessibles sur les lacs mentionnÃ©s prÃ©cÃ©demment dans les conditions suivantes:\\n\n",
    "    \n",
    "    1. Les transports publics sont Ã  moins d'une demi-heure de marche\n",
    "    2. Le lieu est un bien public\n",
    "    3. La zone d'enquÃªte est sÃ»re\n",
    "    4. Il n'y a pas de contre-indications Ã  la rÃ©alisation d'un recensement\\n    \n",
    "    \"\"\"\n",
    "else:\n",
    "    sommarkdown = \"\"\"#### <span style=\"color:#008891\">Scope of surveys</span>\\n\n",
    "    The scope of the surveys includes all accessible shoreline on the previously mentioned lakes given the following conditions:\\n\n",
    "    \n",
    "    1. Public transport is 1/2 hour away on foot\n",
    "    2. The land is open to the public\n",
    "    3. The location is safe\n",
    "    4. There is no reason to not do the survey\\n    \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(sommarkdown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_french:\n",
    "    sommarkdown = \"\"\"### <span style=\"color:#1e90ff\"> DonnÃ©es de synthÃ¨se: toutes les enquÃªtes</span>\\n    \n",
    "    Depuis le 14 avril 2020, 301 Ã©chantillons ont Ã©tÃ© enregistrÃ©s, 266 provenant des lacs et 35 de riviÃ¨res (graphique 1, tableau 1).\\n    \n",
    "    Le nombre d'Ã©chantillons dÃ©passe Ã  la fois nos attentes personnelles et les exigences du contrat. Cependant, il reste encore trois mois d'Ã©chantillonnage.\\n    \n",
    "    Nous remercions les personnes suivantes pour leur participation:\\n\n",
    "    1. Helen Kurukulasuriya\n",
    "    2. Martin Brenvasser\n",
    "    3. Adrien Bonny\n",
    "    4. Debora Camaro\n",
    "    5. Geatan Busser\n",
    "    6. Marie-France Labelle\n",
    "    7. Andreas Gauer\n",
    "    \n",
    "    \"\"\"\n",
    "else:\n",
    "    sommarkdown = \"\"\"### <span style=\"color:#1e90ff\"> Summary data: all surveys</span>\\n    \n",
    "    Since april 14, 2020 301 samples have been recorded, 266 from lakes and 35 from rivers (figure 1, table 1).\\n \n",
    "    The number of samples exceeds both our personal expectations and the contract requirements. However there are still three more months of sampling.\\n \n",
    "    Thanks to the following individuals for their participation:\\n \n",
    "    1. Helen Kurukulasuriya\n",
    "    2. Martin Brenvasser\n",
    "    3. Adrien Bonny\n",
    "    4. Debora Camaro\n",
    "    5. Geatan Busser\n",
    "    6. Marie-France Labelle\n",
    "    7. Andreas Gauer\n",
    "    8. Gaetan Buser\\n\n",
    "    \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(sommarkdown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep track of the figures you produce\n",
    "\n",
    "# use all the surveys un aggregated\n",
    "allsurveys =  newdfx[newdfx.date >= '2020-04-01'].groupby(['loc_date', 'location', 'date', 'water_name'], as_index=False).pcs_m.sum()\n",
    "\n",
    "# identify lakes v/s rivers\n",
    "allsurveys['type'] = allsurveys.location.map(lambda x: dfBeaches[dfBeaches.index == x]['water'].values[0])\n",
    "\n",
    "# count the number of rivers and lakes\n",
    "v_counts = allsurveys['type'].value_counts()\n",
    "rivercount = int(v_counts['r'])\n",
    "lakecount = int(v_counts['l'])\n",
    "\n",
    "# make a table for key statistics:\n",
    "a_sum = pd.DataFrame(allsurveys.pcs_m.describe()[1:].round(2)).T\n",
    "a_sum_table = [[x] for x in a_sum.values[0]]\n",
    "rowLabels = [x for x in list(a_sum.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust table kwargs\n",
    "tablecenter_k = dict(loc=\"center\", bbox=(0,0,1,1), cellLoc='center')\n",
    "\n",
    "fig = plt.figure(constrained_layout = False, figsize=(12,6))\n",
    "figure_num += 1\n",
    "\n",
    "# declare a grid\n",
    "gs = GridSpec(1, 5, figure=fig)\n",
    "\n",
    "# put an ax on it\n",
    "ax1 = fig.add_subplot(gs[4:])\n",
    "\n",
    "# the context matters for the row and column labels\n",
    "if is_french:\n",
    "    rowLabels = summary_row_fr\n",
    "    col_label = [french_pcm]\n",
    "else:\n",
    "    col_label = ['pieces per meter']\n",
    "\n",
    "# define the table\n",
    "a_table = mpl.table.table(\n",
    "    cellText=a_sum_table,\n",
    "    rowLabels=rowLabels,\n",
    "    rowColours=['antiquewhite' for i in rowLabels],\n",
    "    colLabels=['pieces per meter'],\n",
    "    colColours=['antiquewhite' for col in np.arange(1)],\n",
    "    \n",
    "    ax=ax1,\n",
    "    **tablecenter_k)\n",
    "\n",
    "def table_format(a_table, ax, size=12):\n",
    "    table_fonts(a_table, size=size)\n",
    "    make_table_grids(ax)\n",
    "    ax.tick_params(**tabtickp_k)\n",
    "\n",
    "table_format(a_table, ax1) \n",
    "\n",
    "# add table to ax\n",
    "ax1.add_table(a_table )\n",
    "\n",
    "# scatter plot\n",
    "ax2 = fig.add_subplot(gs[0:4])\n",
    "sns.scatterplot(data=allsurveys, x='date',  y='pcs_m', alpha=1, linewidth=1,s=80, ax=ax2)\n",
    "\n",
    "# format scatter\n",
    "ax2.xaxis.set_major_formatter(mths_fmt)\n",
    "ax2.xaxis.set_major_locator(allmonths)\n",
    "ax2.set_xlabel(\"\")\n",
    "\n",
    "# context\n",
    "if is_french:\n",
    "    ax1.set_title(F\"{french_key_values}\", loc='left', pad=10)\n",
    "    ax2.set_title(F\"Figure {figure_num}: {french_srs} {startyearmonth} - {endyearmonth}, Ã©chantillons={len(allsurveys)}, lacs={lakecount}, riviÃ¨res={rivercount}.\", loc='left', pad=10)\n",
    "    ax2.set_ylabel(F\"{french_pcm}\", **ylab_k)\n",
    "else:\n",
    "    ax1.set_title(F\"key values\", loc='left', pad=10)\n",
    "    ax2.set_ylabel(\"Pieces per meter\", **ylab_k)\n",
    "    ax2.set_title(F\"Figure {figure_num}: survey totals {startyearmonth} - {endyearmonth}, all codes all locations. Samples={len(allsurveys)}, lakes={lakecount}, rivers={rivercount}\", loc='left', pad=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# tag the output:\n",
    "figname = F\"figure{figure_num}.jpg\"\n",
    "atype = \"figure\"\n",
    "tag =  'all surveys: scatter plot, key values table'\n",
    "add_output(figname, tag, fignum=figure_num, atype=atype)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_french:\n",
    "    sommarkdown = \"\"\"#### <span style=\"color:#008891\"> Les objets les plus communs: toutes les enquÃªtes </span>\\n    \n",
    "    \"\"\"\n",
    "else:\n",
    "    sommarkdown = \"\"\"#### <span style=\"color:#008891\">Most common objects: all surveys</span>\\n    \n",
    "     \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(sommarkdown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the total quantity for each code\n",
    "allcodevals = pd.DataFrame(newdfx[newdfx.date >= '2020-04-01'].groupby('code').quantity.sum())\n",
    "\n",
    "# add description and material from the codes df\n",
    "allcodevals['description'] = allcodevals.index.map(lambda x: dfCodes.loc[x].description)\n",
    "allcodevals['material'] = allcodevals.index.map(lambda x: dfCodes.loc[x].material)\n",
    "allcodevals['group'] = allcodevals.index.map(lambda x: a_group_map[x])\n",
    "\n",
    "# get the total number of objects and the percent of total\n",
    "allcodevalst= allcodevals.quantity.sum()\n",
    "allcodevals['p_total'] = allcodevals.quantity/allcodevalst*100\n",
    "allcodevals['p_total'] = allcodevals['p_total'].round(2)\n",
    "\n",
    "# sort the values \n",
    "allcodevals = allcodevals.sort_values(by='quantity',ascending=False)\n",
    "\n",
    "# do some housekeeping\n",
    "allcodevals.rename(columns={'p_total':'% of total'}, inplace=True)\n",
    "allcodevals = allcodevals[['description', 'material', 'quantity', '% of total', 'group']]\n",
    "\n",
    "# format for charting\n",
    "allcodevals.reset_index(inplace=True)\n",
    "allcodevals['quantity'] = allcodevals.quantity.apply(lambda x: \"{:,}\".format(x))\n",
    "\n",
    "# define the most common objects:\n",
    "tabledata = allcodevals[allcodevals['% of total'] >= 2]\n",
    "\n",
    "# sum the % of total of the most common objects\n",
    "ptotal = tabledata['% of total'].sum()\n",
    "# is_french = True\n",
    "if is_french:\n",
    "    tabledatacopy = tabledata.copy()\n",
    "    tabledatacopy['description'] = tabledatacopy.code.map(lambda x: count_k(fr_defs_codes[x], limit))\n",
    "    tabledatacopy['group'] = tabledatacopy.group.map(lambda x: count_k(french_names[x], limit))\n",
    "    tabledatacopy.rename(columns=french_columns, inplace=True)\n",
    "    tabledata = tabledatacopy\n",
    "\n",
    "# make adjustments to table kwargs:\n",
    "tablecenter_k = dict(loc=\"center\", bbox=(0,0,1,1), colWidths=[10,46, 10, 10, 10,14], cellLoc='center')\n",
    "\n",
    "# plot the table:\n",
    "fig, ax = plt.subplots(figsize=(15, len(tabledata)*.75))\n",
    "figure_num += 1\n",
    "ax = make_table_grids(ax)\n",
    "a_table = mpl.table.table(\n",
    "    cellText=tabledata.values,\n",
    "    colLabels=tabledata.columns,\n",
    "    colColours=['antiquewhite' for col in list(tabledata.columns)],    \n",
    "    ax=ax,\n",
    "    **tablecenter_k)\n",
    "\n",
    "# set parameters\n",
    "table_fonts(a_table, size=12)\n",
    "ax.tick_params(**tabtickp_k)\n",
    "\n",
    "# add the table\n",
    "ax.add_table(a_table)\n",
    "\n",
    "\n",
    "if is_french:\n",
    "    ax.set_title(F\"Figure {figure_num}: top {len(tabledata)} codes, {np.round(ptotal, 2)}% de {'{:,}'.format(allcodevalst)} objets\", **title_k14)\n",
    "else:\n",
    "    ax.set_title(F\"Figure {figure_num}: top {len(tabledata)} codes, {np.round(ptotal, 2)}% of {'{:,}'.format(allcodevalst)} objects\", **title_k14)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "figname = F\"figure{figure_num}.jpg\"\n",
    "tag = 'all surveys: most common objects table'\n",
    "add_output(figname, tag, fignum=figure_num)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_french:\n",
    "    sommarkdown = \"\"\"### <span style=\"color:#1e90ff\"> DonnÃ©es de synthÃ¨se sur les lacs du projet </span>\\n\n",
    "    \n",
    "    Il y a 8 lacs concernÃ©s par le projet:\\n\n",
    "\n",
    "    1. Zurichsee\n",
    "    2. Lago Maggiore\n",
    "    3. Thunersee\n",
    "    4. Lac LÃ©man\n",
    "    5. Bielersee\n",
    "    6. Lac de NeuchÃ¢tel\n",
    "    7. Walensee\n",
    "    8. Brienzersee\\n\n",
    "\n",
    "    Le lac de Brienze a Ã©tÃ© ajoutÃ© Ã  la liste des lacs Ã©tudiÃ©s, en raison de sa position dans le bassin versant de l'Aare (graphique 2, tableau 3).\n",
    "    \n",
    "    \"\"\"\n",
    "else:\n",
    "    sommarkdown = \"\"\"### <span style=\"color:#1e90ff\"> Project lakes summary data </span>\\n\n",
    "    \n",
    "    There are eight project lakes:\\n\n",
    "\n",
    "    1. Zurichsee\n",
    "    2. Lago Maggiore\n",
    "    3. Thunersee\n",
    "    4. Lac LÃ©man\n",
    "    5. Bielersee\n",
    "    6. Neuenburgersee\n",
    "    7. Walensee\n",
    "    8. Brienzersee\\n\n",
    "\n",
    "    Brienzersee was added to the surveys beacuase of it's position in the catchment area of the Aare (figure 2, table 3).\n",
    "    \n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(sommarkdown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tablecenter_k = dict(loc=\"center\", bbox=(0,0,1,1), cellLoc='center')\n",
    "\n",
    "fig = plt.figure(constrained_layout = False, figsize=(12,6))\n",
    "figure_num += 1\n",
    "\n",
    "ax1 = fig.add_subplot(gs[4:])\n",
    "\n",
    "if is_french:\n",
    "    rowLabels = summary_row_fr\n",
    "    col_label = [french_pcm]\n",
    "else:\n",
    "    col_label = ['pieces per meter']\n",
    "\n",
    "a_table = mpl.table.table(\n",
    "    cellText=a_sum_table,\n",
    "    rowLabels=rowLabels,\n",
    "    rowColours=['antiquewhite' for i in rowLabels],\n",
    "    colLabels=col_label,\n",
    "    colColours=['antiquewhite' for col in np.arange(1)],\n",
    "    \n",
    "    ax=ax1,\n",
    "    **tablecenter_k)\n",
    "\n",
    "\n",
    "table_format(a_table, ax1) \n",
    "ax1.add_table(a_table )\n",
    "\n",
    "if is_french:\n",
    "    ax1.set_title(F\"{french_key_values}\", loc='left', pad=10)\n",
    "else:\n",
    "    ax1.set_title(F\"key values\", loc='left', pad=10)\n",
    "    \n",
    "\n",
    "ax2 = fig.add_subplot(gs[0:4])\n",
    "sns.scatterplot(data=somdata, x='date',  y='pcs_m', hue='water_name', palette='husl', alpha=1, linewidth=1,s=80, ax=ax2)\n",
    "ax2.xaxis.set_major_formatter(mths_fmt)\n",
    "ax2.xaxis.set_major_locator(allmonths)\n",
    "ax2.set_ylabel(\"Pieces per meter\", **ylab_k)\n",
    "\n",
    "if is_french:\n",
    "    ax2.set_title(F\"Figure {figure_num}: {french_srs} {startyearmonth} - {endyearmonth}, Ã©chantillons={len(somdata)}.\", loc='left', pad=10)\n",
    "    ax2.set_ylabel(F\"{french_pcm}\", **ylab_k)\n",
    "    \n",
    "else:\n",
    "    ax2.set_title(F\"Figure {figure_num}: lakes survey totals {startyearmonth} - {endyearmonth}, samples={len(somdata)}.\", loc='left', pad=10)\n",
    "ax2.set_xlabel(\"\")\n",
    "ax2.legend(title=\"Lakes\")\n",
    "\n",
    "\n",
    "\n",
    "fignum = figure_num\n",
    "plt.tight_layout()\n",
    "figname = F\"figure{figure_num}.jpg\"\n",
    "atype='figure'\n",
    "tag =  'lake surveys: scatter plot, key values table'\n",
    "add_output(figname, tag, fignum=fignum, atype=atype)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_french:\n",
    "    sommarkdown = \"\"\"#### <span style=\"color:#008891\"> Les objets les plus communs: les lacs du projet</span>\\n\n",
    "    \"\"\"\n",
    "else:\n",
    "    sommarkdown = \"\"\"#### <span style=\"color:#008891\">Most common objects: project lakes</span>\\n\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(sommarkdown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allcodevals = pd.DataFrame(useThis.groupby('code').quantity.sum())\n",
    "\n",
    "# add description and material from the codes df\n",
    "allcodevals['description'] = allcodevals.index.map(lambda x: dfCodes.loc[x].description)\n",
    "allcodevals['material'] = allcodevals.index.map(lambda x: dfCodes.loc[x].material)\n",
    "allcodevals['group'] = allcodevals.index.map(lambda x: a_group_map[x])\n",
    "\n",
    "# get the total number of objects and the percent of total\n",
    "allcodevalst= allcodevals.quantity.sum()\n",
    "allcodevals['p_total'] = allcodevals.quantity/allcodevalst*100\n",
    "allcodevals['p_total'] = allcodevals['p_total'].round(2)\n",
    "\n",
    "# ptotal = allcodevals['p_total'].sum()\n",
    "\n",
    "# sort the values \n",
    "allcodevals = allcodevals.sort_values(by='quantity',ascending=False)\n",
    "\n",
    "# do some housekeeping\n",
    "allcodevals.rename(columns={'p_total':'% of total'}, inplace=True)\n",
    "allcodevals = allcodevals[['description', 'material', 'quantity', '% of total', 'group']]\n",
    "\n",
    "# format for charting\n",
    "allcodevals.reset_index(inplace=True)\n",
    "allcodevals['quantity'] = allcodevals.quantity.apply(lambda x: \"{:,}\".format(x))\n",
    "\n",
    "# define the most common objects:\n",
    "tabledata = allcodevals[allcodevals['% of total'] >= 2]\n",
    "\n",
    "# sum the % of total of the most common objects\n",
    "ptotal = tabledata['% of total'].sum()\n",
    "\n",
    "# check context\n",
    "if is_french:\n",
    "    tabledatacopy = tabledata.copy()\n",
    "    tabledatacopy['description'] = tabledatacopy.code.map(lambda x: count_k(fr_defs_codes[x], limit))\n",
    "    tabledatacopy['group'] = tabledatacopy.group.map(lambda x: count_k(french_names[x], limit))\n",
    "    tabledatacopy.rename(columns=french_columns, inplace=True)\n",
    "    tabledata = tabledatacopy\n",
    "\n",
    "# make adjustments to table kwargs:\n",
    "tablecenter_k = dict(loc=\"center\", bbox=(0,0,1,1), colWidths=[10,46, 10, 10, 10,15], cellLoc='center')\n",
    "\n",
    "# plot the table:\n",
    "fig, ax = plt.subplots(figsize=(14, len(tabledata)*.75))\n",
    "figure_num += 1\n",
    "ax = make_table_grids(ax)\n",
    "a_table = mpl.table.table(\n",
    "    cellText=tabledata.values,\n",
    "    colLabels=tabledata.columns,\n",
    "    colColours=['antiquewhite' for col in list(tabledata.columns)],    \n",
    "    ax=ax,\n",
    "    **tablecenter_k)\n",
    "\n",
    "table_fonts(a_table, size=12)\n",
    "\n",
    "ax.add_table(a_table)\n",
    "ax.tick_params(**tabtickp_k)\n",
    "\n",
    "# check context\n",
    "\n",
    "if is_french:\n",
    "    ax.set_title(F\"Figure {figure_num}: top {len(tabledata)} codes des lacs du projet, {np.round(ptotal, 2)}% de {'{:,}'.format(allcodevalst)} objets\", **title_k14)\n",
    "    \n",
    "else:\n",
    "    ax.set_title(F\"Figure {figure_num}: top {len(tabledata)} codes project lakes, {np.round(ptotal, 2)}% of {'{:,}'.format(allcodevalst)} objects\", **title_k14)\n",
    "\n",
    "figname = F\"figure{figure_num}.jpg\"\n",
    "fignum=figure_num\n",
    "tag = 'lake surveys: most common objects table'\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "add_output(figname,tag , fignum=fignum)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_french:\n",
    "    sommarkdown = \"\"\"### <span style=\"color:#1e90ff\"> Lacs du projet : objets regroupÃ©s par usage ou caractÃ©ristiques physiques</span>\\n\n",
    "    \"\"\"\n",
    "else:\n",
    "    sommarkdown = \"\"\"### <span style=\"color:#1e90ff\"> Project lakes: objects grouped by use or physical characteristics</span>\\n\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(sommarkdown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atotal = useThis.quantity.sum()\n",
    "groupoftotal = useThis.groupby('groupname', as_index=False).quantity.sum()\n",
    "groupoftotal['p_total'] = (groupoftotal.quantity/atotal)*100\n",
    "groupoftotal['p_total'] = groupoftotal['p_total'].round(2)\n",
    "groupoftotal.sort_values(by='p_total', ascending=True, inplace=True)\n",
    "anorder = groupoftotal.groupname.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = useThis.groupby(['loc_date', 'date','location','water_name', 'groupname'], as_index=False).pcs_m.sum()\n",
    "get_an_order = boxes.groupby('groupname').pcs_m.median()\n",
    "an_order_of_boxes = get_an_order.sort_values(ascending=True)\n",
    "a_box_order = an_order_of_boxes.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the significant value for each code group\n",
    "sig_vals = boxes.groupby('groupname').pcs_m.quantile(sig)\n",
    "\n",
    "# map the significant value to the results\n",
    "boxes['limit'] = boxes.groupname.map(lambda x: sig_vals[x])\n",
    "\n",
    "# create a boolean for significant\n",
    "boxes['significant'] = boxes.pcs_m >= boxes.limit\n",
    "\n",
    "# map to number of samples, and significant values\n",
    "survey_totals.reset_index(inplace=True)\n",
    "\n",
    "# number of samples per lake\n",
    "tries = survey_totals.groupby(['water_name']).loc_date.nunique()\n",
    "\n",
    "# number of locations per lake\n",
    "num_locations = useThis.groupby('water_name').location.nunique()\n",
    "\n",
    "# fails: number of locations where object group has been identified\n",
    "num_with = useThis[useThis.quantity > 0].groupby(['water_name', 'groupname']).location.nunique()\n",
    "\n",
    "# fails: number of samples with the object group\n",
    "samps_with = useThis[useThis.quantity > 0].groupby(['water_name', 'groupname']).loc_date.nunique()\n",
    "\n",
    "# median pcs_m\n",
    "median_pcs = boxes[boxes.pcs_m >0].groupby(['water_name', 'groupname']).pcs_m.median()\n",
    "\n",
    "# mean pcs_m\n",
    "mean_pcs = boxes[boxes.pcs_m >0].groupby(['water_name', 'groupname']).pcs_m.mean()\n",
    "\n",
    "# significant values\n",
    "# determine wether or not the event was greater than the 90th percentile\n",
    "\n",
    "# map limit to data\n",
    "boxes['limit'] = boxes.groupname.map(lambda x: sig_vals[x])\n",
    "\n",
    "# create boolean\n",
    "boxes['significant'] = boxes.pcs_m >= boxes.limit\n",
    "\n",
    "# make a df of tests and test failures\n",
    "fails = boxes.groupby(['water_name', 'groupname'], as_index=False).significant.sum()\n",
    "\n",
    "# get the number of samples for the lake\n",
    "fails['samples'] = fails.water_name.map(lambda x: tries[x])\n",
    "\n",
    "# display the ratio of significant values to samples\n",
    "fails['frequency_s'] = fails.significant.astype('str') + '/' + fails.samples.astype('str')\n",
    "\n",
    "# the number of locations\n",
    "fails['locations'] = fails.water_name.map(lambda x: num_locations[x])\n",
    "\n",
    "def locations_with(x,y,somdata):\n",
    "    try:\n",
    "        has = somdata[x][y]        \n",
    "    except:\n",
    "        has = 0\n",
    "    return has\n",
    "        \n",
    "# the number of locations where the object group has been identified\n",
    "fails['loc_with'] = fails.apply(lambda x:locations_with(x['water_name'], x['groupname'], num_with), axis=1)\n",
    "\n",
    "# the number of samples where the object group has been identified\n",
    "fails['samp_with'] = fails.apply(lambda x:locations_with(x['water_name'], x['groupname'], samps_with), axis=1)\n",
    "\n",
    "# samples frequency of failure\n",
    "fails['frequency'] = fails.samp_with.astype('str') + '/' + fails.samples.astype('str')\n",
    "\n",
    "# locations frequency of failure\n",
    "fails['frequency_l'] = fails.loc_with.astype('str') + '/' + fails.locations.astype('str')\n",
    "\n",
    "# median/mean pcs_m:\n",
    "fails['median pcs/m'] = fails.apply(lambda x:locations_with(x['water_name'], x['groupname'], median_pcs), axis=1)\n",
    "fails['mean pcs/m'] = fails.apply(lambda x:locations_with(x['water_name'], x['groupname'], mean_pcs), axis=1)\n",
    "\n",
    "# likelihood\n",
    "fails['likelihood'] = ((fails.loc_with/fails.locations)*(fails.samp_with/fails.samples))*100\n",
    "fails['likelihood'] = fails.likelihood.astype('int')\n",
    "\n",
    "table_data = fails[['water_name','frequency_l', 'frequency',  'frequency_s', 'likelihood','median pcs/m', 'groupname']].copy()\n",
    "table_data.rename(columns={'water_name':'name', 'frequency_l':\"# locations\", 'frequency':\"# samples\", 'frequency_s':'# significant'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "markers = ['s', 'P', 'D', 'X', 'o']\n",
    "def make_ecdf(somdata, numsamps):\n",
    "    vals = somdata.pcs_m.sort_values()\n",
    "    valsy = [i/numsamps for i in np.arange(numsamps)]\n",
    "    return vals, valsy\n",
    "a_form = mtick.FormatStrFormatter('%.0f%%')\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(11, 7))\n",
    "figure_num += 1\n",
    "if is_french:\n",
    "    groupoftotal['groupname'] = groupoftotal['groupname'].map(lambda x: french_names[x])\n",
    "    groupdconcat['groupname'] = groupdconcat['groupname'].map(lambda x: french_names[x])\n",
    "    anorder = [french_names[x] for x in a_box_order]\n",
    "\n",
    "    sns.barplot(data=groupoftotal, x='groupname', hue='groupname', palette=frpalette, y='p_total', dodge=False, ax=ax[0])\n",
    "    ax[0].set_ylabel(F\"{french_pct}\", labelpad=10)\n",
    "    ax[0].set_title(F\"Figure {figure_num}: {french_bg} % {of_prep} {'{:,}'.format(atotal)} {thing}\", **title_k)\n",
    "    ax[0].set_xlabel(\"\")\n",
    "    ax[0].set_xticklabels(\"\")\n",
    "    ax[0].legend(loc='upper left')    \n",
    "    \n",
    "    sns.boxplot(data=useThis[['groupname','pca_m']], x='groupname', y='pcs_m', hue='groupname', order=anorder, palette=frpalette, dodge=False, ax=ax[1],  showfliers=False)\n",
    "    ax[1].set_ylabel(F\"{french_pcm}\", labelpad=10)\n",
    "    ax[1].set_title(F\"distribution {french_bg}*\", **titler_k)\n",
    "    ax[1].set_xlabel(F\"{french_nooutliers}\")\n",
    "    ax[1].get_legend().remove()\n",
    "    ax[1].set_xticklabels(\"\")\n",
    "    \n",
    "\n",
    "else:\n",
    "    sns.barplot(data=groupoftotal, x='groupname', hue='groupname', palette=grouppalette, y='p_total', dodge=False, ax=ax[0])\n",
    "    ax[0].set_ylabel(\"Percent total of all objects\", labelpad=10)\n",
    "    ax[0].set_title(F\"Figure {figure_num}: code groups as a % of {'{:,}'.format(atotal)} objects\", **title_k)\n",
    "    ax[0].yaxis.set_major_formatter(a_form)\n",
    "    ax[0].set_xlabel(\"\")\n",
    "    ax[0].set_xticklabels(\"\")\n",
    "    ax[0].legend(loc='upper left')    \n",
    "    \n",
    "    sns.boxplot(data=boxes[['groupname','pcs_m']], x='groupname', y='pcs_m', hue='groupname', palette=grouppalette, order=a_box_order, dodge=False, ax=ax[1], showfliers=False)\n",
    "    ax[1].set_ylabel(\"Pieces per meter\", labelpad=10)\n",
    "    ax[1].set_title(F\"disribution of groups*\", **titler_k)\n",
    "    ax[1].set_xlabel(\"*outliers not shown\")\n",
    "    ax[1].get_legend().remove()\n",
    "    ax[1].set_xticklabels(\"\")\n",
    "    \n",
    "fignum=figure_num\n",
    "    \n",
    "plt.tight_layout()\n",
    "figname = F\"figure{fignum}.jpg\"\n",
    "atype='figure'\n",
    "tag = 'code groups: percentage of total, distribution'\n",
    "add_output(figname, tag, fignum=fignum, atype=atype)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context\n",
    "# the group names need to be in the appropriate language\n",
    "if is_french:\n",
    "    sigheat['groupname'] = sigheat.groupname.map(lambda x: french_names[x])\n",
    "    sigdf['groupname'] = sigdf.groupname.map(lambda x: french_names[x])\n",
    "\n",
    "    \n",
    "heat_map_palette = 'flare'\n",
    "linecolor = 'white'\n",
    "\n",
    "fig,axx = plt.subplots(1,2, figsize=(16,10))\n",
    "figure_num += 1\n",
    "\n",
    "sns.heatmap(\n",
    "    fails[['water_name', 'groupname', 'likelihood']].pivot(columns='water_name', index='groupname'),\n",
    "    cmap=heat_map_palette, \n",
    "    ax=axx[0],\n",
    "    square=True,\n",
    "    cbar_kws={\"shrink\": .9},\n",
    "    annot=True, fmt=\" \",\n",
    "    linewidths=.5,\n",
    "    linecolor=linecolor\n",
    ")\n",
    "\n",
    "labels = [a_text.get_text() for a_text in axx[0].get_xticklabels()]\n",
    "newlabels = []\n",
    "\n",
    "# make new labels\n",
    "for i, a_text in enumerate(labels):\n",
    "    oldlabel = a_text\n",
    "    newlabel = oldlabel[len('likelihood')+1:]\n",
    "    newlabels.append(newlabel)\n",
    "\n",
    "sns.heatmap(fails[['water_name', 'groupname', 'mean pcs/m']].pivot(columns='water_name', index='groupname'), cmap=heat_map_palette, ax=axx[1], square=True, cbar_kws={\"shrink\": .9}, annot=True, annot_kws={'fontsize':12},linewidths=.1, linecolor=linecolor)\n",
    "\n",
    "# set parameters\n",
    "for anax in axx:\n",
    "    anax.set_xticklabels(newlabels, fontsize=12)\n",
    "    anax.set_ylabel(\" \")\n",
    "    anax.set_xlabel(\" \")\n",
    "    anax.tick_params(axis='both', labelsize=12)\n",
    "\n",
    "if is_french:\n",
    "    axx[0].set_title(F\"groupe de codes probabilitÃ© de trouver au moins une\", **title_k14)\n",
    "    axx[1].set_title(F\"la valeur moyenne de dÃ©chets par mÃ¨tre\", **title_k14)\n",
    "    plt.suptitle(F\"Figure {figure_num}: tous les lacs, pourcentage des Ã©chantillons > 90%, la valeur mÃ©diane de dÃ©chets par mÃ¨tre\", ha='left', size=14, x=0.06, y=1)\n",
    "else:\n",
    "    axx[0].set_title(F\"code group: likelihood of finding at least one\", **title_k14)\n",
    "    axx[1].set_title(F\"code group: average pieces of trash per meter\", **title_k14)\n",
    "    plt.suptitle(F\"Figure {figure_num}: summary code groups as % of total, median pieces per meter\", ha='left', size=14, x=0.04, y=1)\n",
    "    \n",
    "plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)\n",
    "\n",
    "atype=\"figure\"\n",
    "figname = F\"figure{figure_num}.jpg\"\n",
    "tag = F\"likelihood of finding one object from a group and median pcs/m\"\n",
    "add_output(figname,tag, fignum=figure_num, atype=atype)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# map number of sample per locations\n",
    "tries_l = boxes.groupby('location').loc_date.nunique()\n",
    "\n",
    "# map number of times at least one item was found\n",
    "fails_l = boxes[boxes.pcs_m > 0].groupby(['location', 'groupname']).loc_date.nunique()\n",
    "lake_l = fails.set_index(['groupname','water_name'])\n",
    "lake_l = lake_l['likelihood']\n",
    "\n",
    "fails_beach = boxes.groupby(['location', 'water_name','groupname'], as_index=False).pcs_m.median()\n",
    "fails_beach['tries'] = fails_beach.location.map(lambda x: tries_l[x])\n",
    "fails_beach['fails'] = fails_beach.apply(lambda x:locations_with(x['location'], x['groupname'], fails_l), axis=1)\n",
    "fails_beach['loclikelihood'] = (fails_beach.fails/fails_beach.tries) * 100\n",
    "fails_beach['loclikelihood'] = fails_beach['loclikelihood'].astype('int')\n",
    "fails_beach['lakelikelihood'] = fails_beach.apply(lambda x:locations_with(x['groupname'], x['water_name'], lake_l), axis=1)\n",
    "fails_beach['likelihood'] = (fails_beach.loclikelihood*fails_beach.lakelikelihood)/100\n",
    "fails_beach['likelihood'] = fails_beach['likelihood'].astype('int')\n",
    "\n",
    "a = boxes.groupby('location').significant.sum()\n",
    "these_beaches['significant'] = these_beaches.index.map(lambda x: a.loc[x])\n",
    "these_beaches.to_csv(F\"{project_directory}/these_beaches.csv\")\n",
    "these_rivers = dfSurveys[(dfSurveys.date >= start_date)]['location'].unique()\n",
    "river_beaches = dfBeaches.loc[(dfBeaches.index.isin(these_rivers))&(dfBeaches.water == 'r')]\n",
    "river_beaches.to_csv(F\"{project_directory}/these_rivers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fig,axx = plt.subplots(figsize=(18,18))\n",
    "figure_num += 1\n",
    "\n",
    "this_data=fails_beach[fails_beach.water_name == lake].copy()\n",
    "\n",
    "sns.heatmap(\n",
    "    this_data[['location', 'groupname', 'likelihood']].pivot(columns='location', index='groupname'), \n",
    "    cmap=heat_map_palette,\n",
    "    linecolor=linecolor,\n",
    "    ax=axx, \n",
    "    square=True, \n",
    "    annot=True,\n",
    "    cbar_kws={\"shrink\": .38}, \n",
    "    annot_kws={'fontsize':12}, \n",
    "    linewidths=.5,\n",
    "    fmt=\" \",\n",
    ")\n",
    "labels = [a_text.get_text() for a_text in axx.get_xticklabels()]\n",
    "newlabels = []\n",
    "for i, a_text in enumerate(labels):\n",
    "    oldlabel = a_text\n",
    "    newlabel = oldlabel[len('likelihood')+1:]\n",
    "    newlabels.append(newlabel)\n",
    "\n",
    "axx.set_xticklabels(newlabels)\n",
    "\n",
    "axx.set_ylabel(\" \")\n",
    "axx.set_xlabel(\" \")\n",
    "axx.tick_params(axis='both', labelsize=12)\n",
    "\n",
    "if is_french:\n",
    "    axx.set_title(F\"code group: likelihood of finding at least one\", **title_k14)\n",
    "else:\n",
    "    axx.set_title(F\"code group: likelihood of finding at least one\", **title_k14)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "atype=\"figure\"\n",
    "figname = F\"figure{figure_num}.jpg\"\n",
    "tag = F\"{lake} code groups percent of total by location.\"\n",
    "add_output(figname,tag, fignum=figure_num, atype=atype)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fig,axx = plt.subplots(figsize=(18,18))\n",
    "figure_num += 1\n",
    "\n",
    "sns.heatmap(this_data[['location', 'groupname', 'pcs_m']].pivot(columns='location', index='groupname'),\n",
    "            cmap=heat_map_palette, ax=axx, square=True, annot=True,cbar_kws={\"shrink\": .38}, annot_kws={'fontsize':12}, linewidths=.5, linecolor=linecolor)\n",
    "labels = [a_text.get_text() for a_text in axx.get_xticklabels()]\n",
    "newlabels = []\n",
    "for i, a_text in enumerate(labels):\n",
    "    oldlabel = a_text\n",
    "    newlabel = oldlabel[6:]\n",
    "    newlabels.append(newlabel)\n",
    "axx.set_xticklabels(newlabels, fontsize=12)\n",
    "axx.set_ylabel(\" \")\n",
    "axx.set_xlabel(\" \")\n",
    "axx.tick_params(axis='both', labelsize=12)\n",
    "\n",
    "if is_french:\n",
    "    axx.set_title(F\"Figure {figure_num}: {lake} la valeur mÃ©diane de dÃ©chets par mÃ¨tre.\", **title_k14)\n",
    "else:\n",
    "    axx.set_title(F\"Figure {figure_num}: {lake} median pieces of trash per meter.\", **title_k14)\n",
    "    \n",
    "plt.tight_layout()\n",
    "atype=\"figure\"\n",
    "figname = F\"figure{figure_num}.jpg\"\n",
    "tag = F\"{lake} all locations median pcs/m\"\n",
    "add_output(figname,tag, fignum=figure_num, atype=atype)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "boxes.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "monthly = pd.DataFrame(boxes.groupby('groupname').resample('M').pcs_m.median())\n",
    "monthly['change'] = monthly.pcs_m.diff().round(4)\n",
    "monthly.fillna(0, inplace=True)\n",
    "monthly.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "french_columns = {'code':'code','description': 'description', 'material':'matÃ©riel', 'quantity':'quantitÃ©'}\n",
    "thing = 'objets'\n",
    "parent = \"de l'ensemble\"\n",
    "french_pcm = \"piÃ¨ces par mÃ¨tre\"\n",
    "french_srs = \"rÃ©sultats des recensements\"\n",
    "french_pcg = \"par groupe de codes\"\n",
    "french_med = \"mÃ©dian\"\n",
    "french_mm = \"mÃ©diane mensuelle\"\n",
    "french_change = 'changement'\n",
    "\n",
    "fig, axs = plt.subplots(3,1,figsize=(14,16))\n",
    "figure_num +=1\n",
    "\n",
    "# plots\n",
    "sns.scatterplot(data=boxes, x='date',  y='pcs_m', hue='groupname', palette=grouppalette, alpha=0.8,s=60, ax=axs[0])\n",
    "sns.lineplot(data=monthly, x='date', y='pcs_m', hue='groupname', palette=grouppalette, ax=axs[1])\n",
    "sns.lineplot(data=monthly, x='date',  y='change',  hue='groupname', palette=grouppalette, linewidth=2, ax=axs[2])\n",
    "\n",
    "if is_french:    \n",
    "    # titles\n",
    "    axs[0].set_title(F\"Figure {figure_num}:{french_srs} {french_pcg}, {startyearmonth} - {endyearmonth}, n={len(boxes)}\", **title_k)    \n",
    "    axs[1].set_title(F\"{french_mm} {french_srs}, {startyearmonth} - {endyearmonth}, n={len(boxes)}\", **title_k)    \n",
    "    axs[2].set_title(F\"changement {french_mm} pcs/m, n={len(boxes)}\", **title_k)\n",
    "    \n",
    "    # labels\n",
    "    axs[0].set_ylabel(french_pcm, **ylab_k)\n",
    "    axs[1].set_ylabel(french_pcm, **ylab_k)\n",
    "    axs[2].set_ylabel(F\"{french_change}\", **ylab_k)\n",
    "else:\n",
    "    # titles\n",
    "    axs[0].set_title(F\"Figure {figure_num}: survey results by code group, {startyearmonth} - {endyearmonth}, n={len(boxes)}\", **title_k)\n",
    "    axs[1].set_title(F\"median monthly results, {startyearmonth} - {endyearmonth}, n={len(boxes)}\", **title_k)\n",
    "    axs[2].set_title(F\"monthly change pcs/m, n={len(boxes)}\", **title_k)    \n",
    "    \n",
    "    # labels\n",
    "    axs[0].set_ylabel(\"pieces per meter\", **ylab_k)\n",
    "    axs[1].set_ylabel(\"pieces per meter\", **ylab_k)\n",
    "    axs[2].set_ylabel(\"Change pieces per meter\", **ylab_k)\n",
    "    \n",
    "    \n",
    "for anax in axs:\n",
    "    # set axs parameters\n",
    "    anax.xaxis.set_minor_locator(weeks)\n",
    "    anax.xaxis.set_major_formatter(mths_fmt)\n",
    "    anax.xaxis.set_major_locator(months)\n",
    "    anax.tick_params(which='major', pad=10)\n",
    "    anax.set_xlabel(\"\")\n",
    "    labels, handles = anax.get_legend_handles_labels()\n",
    "    anax.legend(labels, handles, bbox_to_anchor=(1, 1),loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "figname = F\"figure{figure_num}.jpg\"\n",
    "tag = F\"code group survey results, montlhy median and change\"\n",
    "atype='figure'\n",
    "add_output(figname, tag, fignum=figure_num, atype=atype)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if is_french:\n",
    "    sommarkdown = \"\"\"#### <span style=\"color:#008891\">Commentaire groupe d'objets</span>\n",
    "    Les restes reprÃ©sente la plus grande proportion des objets trouvÃ©s. Cela illustre l'importance du transport fluvial et les difficultÃ©s liÃ©es Ã  la dÃ©termination de la source gÃ©ographique exacte de la plupart des objets.\n",
    "\n",
    "    Lorsqu'ils sont combinÃ©s, les groupes de l'agriculture, de la construction et l'agriculture ou de construction et agriculture reprÃ©sentent ~26%, soit Ã  peu prÃ¨s le mÃªme que celui des kiosques.\n",
    "    \n",
    "    Le groupe des microplastiques reprÃ©sente ~ 8% du total. Il faut tenir compte du fait que ces objets, par dÃ©finition, sont difficiles Ã  voir et qu'ils sont donc certainement sous-reprÃ©sentÃ©s dans ces chiffres.    \n",
    "    \"\"\"\n",
    "else:\n",
    "    sommarkdown = \"\"\"#### <span style=\"color:#008891\">Comments object groups</span>\n",
    "\n",
    "    The rest represents the biggest proportion of the objects found. This illustrates the importance of fluvial transport and the difficulties associated with determining the exact geographic source of most objects.\n",
    "    \n",
    "    When combined, the groups of aggriculture, construction and agg or construction are ~26% or about the same as the kiosk group.\n",
    "    \n",
    "    The microplastic group is ~ 8% of the total. These objects, by definition, are difficult to see and therfore are certainly under represented in these counts.\n",
    "    \"\"\" \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#1e90ff\"> Group components</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "is_french = False\n",
    "# creating tables for each code group\n",
    "# each table is saved in jpeg\n",
    "\n",
    "\n",
    "# context:\n",
    "french_columns = {'code':'code','description': 'description', 'material':'matÃ©riel', 'quantity':'quantitÃ©'}\n",
    "thing = 'objets'\n",
    "parent = \"de l'ensemble\"\n",
    "\n",
    "# define the summary table for each code group\n",
    "groupTotals = {}\n",
    "for name in group_names:\n",
    "    \n",
    "    somdata = useThis[useThis.groupname == name ].copy()\n",
    "    somdata = somdata[somdata.quantity > 0]\n",
    "    newdata = somdata.groupby('code').agg({'quantity':'sum', 'pcs_m':'mean'})\n",
    "    somdatatot = somdata.quantity.sum()\n",
    "    newdata['% of group']=np.round((newdata.quantity/somdatatot)*100, 1)\n",
    "    # check context\n",
    "    if is_french:\n",
    "        newdata['description'] = newdata.index.map(lambda x: count_k(fr_defs_codes[x], limit))\n",
    "    else:\n",
    "        # do it in english\n",
    "        newdata['description'] = newdata.index.map(lambda x: count_k(dfCodes.loc[x].description, limit))\n",
    "        \n",
    "    newdata['material'] = newdata.index.map(lambda x: dfCodes.loc[x].material)\n",
    "    newdata.reset_index(inplace=True)\n",
    "    \n",
    "    newdata.drop('pcs_m', axis=1, inplace=True)\n",
    "    newdata = newdata[['code','description', 'material', 'quantity', '% of group']]\n",
    "    newdata.sort_values(by='% of group', ascending=False, inplace=True)\n",
    "    groupTotals.update({name:newdata})\n",
    "\n",
    "\n",
    "tablecenter_k = dict(loc=\"center\", bbox=(0,0,1,1), colWidths=[10,52, 13, 13, 13], cellLoc='center')\n",
    "a_total = newdfx.quantity.sum()\n",
    "\n",
    "for i,name in enumerate(group_names):\n",
    "    # make the data\n",
    "    somdata = groupTotals[name]\n",
    "    \n",
    "    # get the number of records\n",
    "    somnums = np.arange(len(somdata))\n",
    "    \n",
    "    # get the total for the group\n",
    "    group_total = somdata.quantity.sum()\n",
    "    \n",
    "    # check context before exporting:\n",
    "    if is_french:\n",
    "        # makes the column headers to desired language:\n",
    "        somdata.rename(columns=french_columns, inplace=True)\n",
    "    \n",
    "    # make the figure\n",
    "    fig, axs = plt.subplots(figsize=(12, len(somdata)*.75))\n",
    "    # keep track\n",
    "    figure_num += 1\n",
    "    \n",
    "    # define table\n",
    "    a_table = mpl.table.table(\n",
    "        cellText=somdata.values,\n",
    "        colLabels=list(somdata.columns),\n",
    "        colColours=['antiquewhite' for i in list(somdata.columns)],\n",
    "        \n",
    "        ax=axs,\n",
    "        **tablecenter_k)\n",
    "    \n",
    "    # add table to figure and set parameters\n",
    "    axs.add_table(a_table)\n",
    "    table_fonts(a_table, size=12)\n",
    "    make_table_grids(axs)\n",
    "    axs.tick_params(**tabtickp_k)    \n",
    "    \n",
    "    # check context, the name is used to iterate so:    \n",
    "    if is_french:\n",
    "        axs.set_title(F\"Figure {figure_num}: {french_names[name]} {'{:,}'.format(group_total)} {thing}, {np.round((group_total/a_total)*100, 2)}% {parent}.\", **titler_k)\n",
    "    else:\n",
    "        # do it in english\n",
    "        axs.set_title(F\"Figure {figure_num}: {name} {'{:,}'.format(group_total)} items, {np.round((group_total/a_total)*100, 2)}% of all objects.\", **titler_k)\n",
    "    # tag and save\n",
    "    figname = F\"figure{figure_num}.jpg\"\n",
    "    tag = F\"{name} component codes\"\n",
    "    \n",
    "    add_output(figname, tag, fignum=figure_num)\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "is_french = False\n",
    "if is_french:\n",
    "    sommarkdown = \"\"\"### <span style=\"color:#1e90ff\">RÃ©sultats par groupe de codes</span>\\n#### <span style=\"color:#008891\">rÃ©sultats mensuels mÃ©dians</span>\\n\n",
    "    \"\"\"\n",
    "\n",
    "else:\n",
    "    sommarkdown = \"\"\"### <span style=\"color:#1e90ff\">Survey results per code group</span>\\n#### <span style=\"color:#008891\">Median monthly survey results</span>\\n\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "display(Markdown(sommarkdown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if is_french:\n",
    "    sommarkdown = \"\"\"#### <span style=\"color:#008891\">Valeurs clÃ©s par groupe de code</span>\n",
    "    \"\"\"\n",
    "else:    \n",
    "    sommarkdown = \"\"\"#### <span style=\"color:#008891\">Key values per code group</span>\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "display(Markdown(sommarkdown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# aggregate the survey totals by group\n",
    "somdata = boxes.groupby('groupname').pcs_m.describe()\n",
    "somdata.reset_index(inplace=True)\n",
    "somcols = {'groupname':'group'}\n",
    "somdata.rename(columns=somcols, inplace=True)\n",
    "# somdata.columns = somdata.columns.get_level_values(1)\n",
    "thisdata = somdata[['group', 'max','75%', '50%', '25%', 'min', 'mean', 'std']].round(2).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# context:\n",
    "if is_french:\n",
    "    thisdata.rename(columns={'group':'groupe', 'mean':'moyenne', 'std':'et'}, inplace=True)   \n",
    "    thisdata['group'] = thisdata.group.map(lambda x: french_names[x])\n",
    "\n",
    "# display and print\n",
    "col_widths = [16,12,12,12,12,12,12,12 ]\n",
    "tablecenter_k = dict(loc=\"top left\", bbox=(0,0,1,1), colWidths=col_widths, cellLoc='center')\n",
    "\n",
    "# a table\n",
    "fig, axs = plt.subplots(figsize=(18,len(thisdata)))\n",
    "# keeping count\n",
    "figure_num += 1\n",
    "\n",
    "# define the table\n",
    "a_table = mpl.table.table(\n",
    "    cellText=thisdata.values,\n",
    "    colLabels=thisdata.columns,\n",
    "    colColours=['antiquewhite' for i in thisdata.columns],\n",
    "    ax=axs,\n",
    "    **tablecenter_k)\n",
    "\n",
    "# set axs parameters\n",
    "make_table_grids(axs)\n",
    "table_fonts(a_table, size=14)\n",
    "axs.add_table(a_table )\n",
    "axs.tick_params(**tabtickp_k)\n",
    "\n",
    "# context\n",
    "if is_french:\n",
    "    axs.set_title(F\"Figure {figure_num}: groupes de codes {french_key_values} {startyearmonth} - {endyearmonth}, n={len(survey_totals)} \", **title_k)\n",
    "else:\n",
    "    axs.set_title(F\"Figure {figure_num}: code groups key values {startyearmonth} - {endyearmonth}, n={len(survey_totals)}\", **title_k)\n",
    "\n",
    "# tag the image\n",
    "figname = F\"figure{figure_num}.jpg\"\n",
    "fignum = figure_num\n",
    "tag = F\"code groups key values\"\n",
    "\n",
    "# draw it\n",
    "plt.tight_layout()\n",
    "\n",
    "# save it\n",
    "add_output(figname, tag, fignum=fignum)\n",
    "\n",
    "plt.box(on=None)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#1e90ff\"> Project lakes: significant events by code group and lake</span>\n",
    "\n",
    "**Definition of significant event**: a significant event is defined as a survey result that exceeds the 90th percentile of all surveys for that code group. In this report the 90th percentile is considered for all surveys in the project lakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "boxes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # get the significant value for each code group\n",
    "# sig_vals = boxes.groupby('groupname').pcs_m.quantile(sig)\n",
    "\n",
    "# # map the significant value to the results\n",
    "# boxes['limit'] = boxes.groupname.map(lambda x: sig_vals[x])\n",
    "\n",
    "# # create a boolean for significant\n",
    "# boxes['significant'] = boxes.pcs_m >= boxes.limit\n",
    "\n",
    "# # map to number of samples, and significant values\n",
    "# survey_totals.reset_index(inplace=True)\n",
    "\n",
    "# # number of samples per lake\n",
    "# tries = survey_totals.groupby(['water_name']).loc_date.nunique()\n",
    "\n",
    "# # number of locations per lake\n",
    "# num_locations = useThis.groupby('water_name').location.nunique()\n",
    "\n",
    "# # fails: number of locations where object group has been identified\n",
    "# num_with = useThis[useThis.quantity > 0].groupby(['water_name', 'groupname']).location.nunique()\n",
    "\n",
    "# # fails: number of samples with the object group\n",
    "# samps_with = useThis[useThis.quantity > 0].groupby(['water_name', 'groupname']).loc_date.nunique()\n",
    "\n",
    "# # median pcs_m\n",
    "# median_pcs = boxes[boxes.pcs_m >0].groupby(['water_name', 'groupname']).pcs_m.median()\n",
    "\n",
    "# # mean pcs_m\n",
    "# mean_pcs = boxes[boxes.pcs_m >0].groupby(['water_name', 'groupname']).pcs_m.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # significant values\n",
    "# # determine wether or not the event was greater than the 90th percentile\n",
    "\n",
    "# # map limit to data\n",
    "# boxes['limit'] = boxes.groupname.map(lambda x: sig_vals[x])\n",
    "\n",
    "# # create boolean\n",
    "# boxes['significant'] = boxes.pcs_m >= boxes.limit\n",
    "\n",
    "# # find the test failures\n",
    "# fails = boxes.groupby(['water_name', 'groupname'], as_index=False).significant.sum()\n",
    "\n",
    "# # get the number of samples for the lake\n",
    "# fails['samples'] = fails.water_name.map(lambda x: tries[x])\n",
    "\n",
    "# # display the ratio of significant values to samples\n",
    "# fails['frequency_s'] = fails.significant.astype('str') + '/' + fails.samples.astype('str')\n",
    "\n",
    "# # the number of locations\n",
    "# fails['locations'] = fails.water_name.map(lambda x: num_locations[x])\n",
    "\n",
    "# def locations_with(x,y,somdata):\n",
    "#     try:\n",
    "#         has = somdata[x][y]        \n",
    "#     except:\n",
    "#         has = 0\n",
    "#     return has\n",
    "        \n",
    "# # the number of locations where the object group has been identified\n",
    "# fails['loc_with'] = fails.apply(lambda x:locations_with(x['water_name'], x['groupname'], num_with), axis=1)\n",
    "\n",
    "# # the number of samples where the object group has been identified\n",
    "# fails['samp_with'] = fails.apply(lambda x:locations_with(x['water_name'], x['groupname'], samps_with), axis=1)\n",
    "\n",
    "# # samples frequncy of failure\n",
    "# fails['frequency'] = fails.samp_with.astype('str') + '/' + fails.samples.astype('str')\n",
    "\n",
    "# # locations frequncy of failure\n",
    "# fails['frequency_l'] = fails.loc_with.astype('str') + '/' + fails.locations.astype('str')\n",
    "\n",
    "# # median/mean pcs_m:\n",
    "# fails['median pcs/m'] = fails.apply(lambda x:locations_with(x['water_name'], x['groupname'], median_pcs), axis=1)\n",
    "# fails['mean pcs/m'] = fails.apply(lambda x:locations_with(x['water_name'], x['groupname'], mean_pcs), axis=1)\n",
    "\n",
    "# # likelihood\n",
    "# fails['likelihood'] = ((fails.loc_with/fails.locations)*(fails.samp_with/fails.samples))*100\n",
    "# fails['likelihood'] = fails.likelihood.astype('int')\n",
    "\n",
    "# table_data = fails[['water_name','frequency_l', 'frequency',  'frequency_s', 'likelihood','median pcs/m', 'groupname']].copy()\n",
    "# table_data.rename(columns={'water_name':'name', 'frequency_l':\"# locations\", 'frequency':\"# samples\", 'frequency_s':'# significant'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "somcols = {'lake':'lac',\n",
    "           '# locations':'# sites',\n",
    "           '# with':'# avec',\n",
    "           '# samples':'# Ã©chantillon',\n",
    "           '# samps with':'# avec',\n",
    "           'median pcs/m':'mÃ©dian pcs/m',\n",
    "           'mean pcs/m':'moyenne pcs/m', \n",
    "           '% of daily total':'% de total'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# adjust table args\n",
    "tablecenter_k = dict(loc=\"top left\", bbox=(0,0,1,1), cellLoc='center', fontsize=12, colWidths = [0.4, 0.3, 0.3])\n",
    "tablecenter_kx = dict(loc=\"top left\", bbox=(0,0,1,1), cellLoc='center',colWidths = [0.16, 0.16, 0.16, 0.16, 0.16], fontsize=12)\n",
    "\n",
    "# make a figure for eac code group\n",
    "for i,name in enumerate(group_names):\n",
    "    \n",
    "    # events table:\n",
    "    event_data = fails[fails.groupname == name][['water_name', 'significant','frequency_s']].copy()\n",
    "    \n",
    "    # context    \n",
    "    if is_french:\n",
    "        event_data = event_data.rename(columns={'lake':'lac', '# significant':'# significatif', 'frequency':'frÃ©quence'})        \n",
    "        \n",
    "    # there is a mix of blank and active grids switch off the grid for the figure\n",
    "    with sns.axes_style('white', {'xtick.color':'white', 'ytick.color':'white'}):        \n",
    "        fig, axs = plt.subplots(figsize=(12,12), frameon=False)\n",
    "        figure_num += 1\n",
    "        sns.despine(fig=fig, top=True, left=True, right=True, bottom=True)\n",
    "\n",
    "    # declare the grid\n",
    "    gs = GridSpec(2, 2, figure=fig)\n",
    "    \n",
    "    # add ax to grid\n",
    "    ax1 = fig.add_subplot(gs[0,0])\n",
    "    \n",
    "    # apply formatting before putting in table\n",
    "    make_table_grids(ax1)\n",
    "\n",
    "    # define table\n",
    "    a_table = mpl.table.table(\n",
    "        cellText=event_data[event_data.significant > 0].values,\n",
    "        colLabels=event_data.columns,\n",
    "        colColours=['antiquewhite' for col in event_data.columns],\n",
    "        ax=ax1,\n",
    "        **tablecenter_k)\n",
    "    \n",
    "    # add table to ax\n",
    "    ax1.add_table(a_table)\n",
    "    \n",
    "    # set remaining parameters\n",
    "    table_fonts(a_table)\n",
    "    ax1.tick_params(**tabtickp_k)\n",
    "    the90th = sig_vals[name]\n",
    "    \n",
    "    # add the dist chart\n",
    "    ax2 = fig.add_subplot(gs[0,1])\n",
    "    with sns.axes_style('whitegrid',{'xtick.color':'black', 'ytick.color':'black'}):\n",
    "        ax2 = sns.scatterplot(data=boxes[boxes.groupname == name],\n",
    "                              x='water_name',\n",
    "                              y='pcs_m',\n",
    "                              hue='water_name',\n",
    "                              style='significant',\n",
    "                              s=120, \n",
    "                              palette='husl',\n",
    "                              markers={True:'X', False:'s'}, ax=ax2)\n",
    "        # set axis parameters\n",
    "        ax2.xaxis.set_tick_params(rotation=45)        \n",
    "        for tick in ax2.xaxis.get_majorticklabels():\n",
    "            tick.set_horizontalalignment(\"right\")        \n",
    "        ax2.set_xlabel(\"\")\n",
    "        \n",
    "        # context\n",
    "        if is_french:\n",
    "            ax1.set_title(F\"frÃ©quence\", **title_k)\n",
    "            ax2.set_ylabel(F\"{french_pcm}\", **ylab_k)\n",
    "            handles, labels = ax2.get_legend_handles_labels()\n",
    "            ax2.legend(handles, labels)\n",
    "            ax2.set_title(F\"distribution des rÃ©sultats\", **titler_k)\n",
    "        else:\n",
    "            ax1.set_title(F\"frequency\", **title_k)\n",
    "            ax2.set_ylabel(\"pieces per meter\", **ylab_k)\n",
    "            handles, labels = ax2.get_legend_handles_labels()\n",
    "            ax2.legend(handles, labels)\n",
    "            ax2.set_title(F\"distribution of results\", **titler_k)\n",
    "            \n",
    "        \n",
    "    # add key values table\n",
    "    ax3 = fig.add_subplot(gs[1, 0:])\n",
    "    \n",
    "    # format the table data\n",
    "    this_data = table_data[table_data.groupname == name]\n",
    "    this_data= this_data[['name', \"# locations\", \"# samples\", '# significant', 'likelihood']]\n",
    "    \n",
    "    # context\n",
    "    if is_french:\n",
    "        these_labels = [somcols[x] for x in list(this_data.columns)]\n",
    "    else:\n",
    "        these_labels = list(this_data.columns)\n",
    "    \n",
    "    # add table\n",
    "    a_table = mpl.table.table(cellText=this_data.values, colLabels= these_labels,colColours=['antiquewhite' for col in these_labels], ax=ax3, **tablecenter_kx)\n",
    "    ax3.add_table(a_table)\n",
    "    \n",
    "    # table parameters\n",
    "    make_table_grids(ax3)\n",
    "    table_fonts(a_table)\n",
    "    ax3.tick_params(**tabtickp_k)\n",
    "    \n",
    "    # context\n",
    "    if is_french:\n",
    "        ax3.set_title(F\"{french_sum_names[name]}: valeurs clÃ©s\", **title_k)\n",
    "        plt.suptitle(F\"Figure {figure_num}: Ã©vÃ©nements significatifs {french_sum_names[name]}, 90%= {np.round(the90th, 3)}\", ha='left', size=14, x=0.04, y=0.99)\n",
    "    else:\n",
    "        ax3.set_title(F\"{name}: key values\", **title_k)\n",
    "        plt.suptitle(F\"Figure {figure_num}: Significant events {name} , 90%= {np.round(the90th, 3)}\", ha='left', size=14, x=0.04, y=0.99)\n",
    "    \n",
    "    # tag the output\n",
    "    figname=F\"figure{figure_num}.jpg\"\n",
    "    tag = F\"{name} significant events\"\n",
    "    atype='figure'\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # save the figure\n",
    "    add_output(figname, tag, fignum=figure_num, atype=atype)\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# a grid that dispalys the significant results per code group and location\n",
    "\n",
    "# define the number of rows\n",
    "locs=len(group_names)\n",
    "rows = math.ceil(locs/3)\n",
    "cols=3\n",
    "\n",
    "# add space for the legend\n",
    "if rows > locs/3:\n",
    "    rows = rows\n",
    "else:\n",
    "    rows +=1\n",
    "\n",
    "# clear the figure grid\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "fig, axs = plt.subplots(rows,cols, figsize=(18, 22))\n",
    "figure_num += 1\n",
    "for i in np.arange(len(group_names)):\n",
    "    end = len(group_names) -1\n",
    "    thisi = i\n",
    "    thiscol = i%3\n",
    "    name = group_names[i]\n",
    "    anax = axs[math.floor(i/3),thiscol]\n",
    "    somdata = boxes[boxes.groupname == name]\n",
    "    \n",
    "    somdata = somdata[somdata.water_name == lake]\n",
    "    thisplot = sns.scatterplot(\n",
    "            data=somdata,\n",
    "            x='location',\n",
    "            y='pcs_m',\n",
    "            hue='location',\n",
    "            style='significant',\n",
    "            s=160, ax=anax,\n",
    "            palette='husl',\n",
    "            markers={True:'X', False:'s'}\n",
    "        )\n",
    "    handles, lables = anax.get_legend_handles_labels()\n",
    "    anax.get_legend().remove()\n",
    "    anax.set_xticks([])\n",
    "    anax.set_xlabel(\"\")\n",
    "    the90th = sig_vals[name]\n",
    "    if thiscol > 0:\n",
    "            anax.set_ylabel(\"\")\n",
    "    else:\n",
    "        anax.set_ylabel(\"pieces per meter\", **ylab_k)\n",
    "    if is_french:\n",
    "        anax.set_title(F\"{french_sum_names[name]} 90%= {np.round(the90th, 3)} \", **title_k14)        \n",
    "    else:\n",
    "        anax.set_title(F\"{name} 90%= {np.round(the90th, 3)}\", **title_k14)\n",
    "\n",
    "\n",
    "\n",
    "usedgrids = [[math.floor(i/3), i%3] for i in np.arange(len(group_names))]\n",
    "availablegrids = [[math.floor(i/3), i%3] for i in np.arange(rows*cols)]\n",
    "\n",
    "# get the unused grids\n",
    "unusedgrids = [x for x in availablegrids if x not in usedgrids]\n",
    "\n",
    "# turn off the unused grids\n",
    "for grid in unusedgrids:\n",
    "    axs[grid[0],grid[1]].tick_params(**tabtickp_k)\n",
    "    axs[grid[0],grid[1]].grid(False)\n",
    "    make_table_grids(axs[grid[0],grid[1]])\n",
    "\n",
    "# put the legend in the last grid and size it\n",
    "for handle in handles:\n",
    "    handle.set_sizes([200])\n",
    "fig.legend(handles, lables, bbox_to_anchor=(0.99, 0.01), loc='lower right', ncol=2, fontsize=12)\n",
    "\n",
    "\n",
    "# tag the figure\n",
    "figname = F\"figure{figure_num}.jpg\"\n",
    "atype=\"figure\"\n",
    "tag = F\"{lake} regional assessment\"\n",
    "\n",
    "plt.suptitle(F\"Figure {figure_num}: significant events per code group {lake}\", ha='left', x=0.047, size=16, y=.98)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.95)\n",
    "\n",
    "# add figure to output:\n",
    "add_output(figname,tag, fignum=figure_num, atype=atype)\n",
    "\n",
    "plt.box(on=None)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figures and data produced by this notebook:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "files_df = pd.DataFrame(files_generated[2:])\n",
    "files_df.rename(columns={'tag':'description'}, inplace=True)\n",
    "\n",
    "files_df = files_df[['type','number', 'description']]\n",
    "files_df = files_df.sort_values(by='type')\n",
    "files_df.sort_values(by='number', inplace=True)\n",
    "tablecenter_k = dict(loc=\"top left\", bbox=(0,0,1,1), cellLoc='center', colWidths=[20,10,70], fontsize=12)\n",
    "tablecenter_kx = dict(loc=\"top left\", bbox=(0,0,1,1), cellLoc='center', fontsize=12)\n",
    "        \n",
    "with sns.axes_style('white', {'xtick.color':'white', 'ytick.color':'white'}):\n",
    "    fig, axs = plt.subplots(figsize=(12,(len(files_df)*.75)), frameon=False)\n",
    "    sns.despine(fig=fig, top=True, left=True, right=True, bottom=True)\n",
    "\n",
    "    make_table_grids(ax1)\n",
    "\n",
    "    \n",
    "\n",
    "    a_table = axs.add_table(mpl.table.table(\n",
    "        cellText=files_df.values,\n",
    "        colLabels=files_df.columns,\n",
    "        colColours=['antiquewhite' for col in files_df.columns],\n",
    "        ax=axs,\n",
    "        **tablecenter_k))\n",
    "\n",
    "\n",
    "    table_fonts(a_table)\n",
    "\n",
    "    axs.tick_params(**tabtickp_k)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hopefully that just worked for you\n",
    "\n",
    "if not contact analyst@hammerdirt.ch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
