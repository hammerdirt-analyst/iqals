{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Code groups: assessing regional litter survey results. Support text for presentation </span>\n",
    "\n",
    "### <span style=\"color:#008891\">Methods</span>\n",
    "1. data collection\n",
    "2. scope\n",
    "\n",
    "### <span style=\"color:#008891\">Summary data</span>\n",
    "#### <span style=\"color:#008891\">All surveys</span>\n",
    "\n",
    "1. all data\n",
    "2. project lakes\n",
    "\n",
    "### <span style=\"color:#008891\">Code groups</span>\n",
    "\n",
    "1. summary data\n",
    "2. components\n",
    "3. survey results\n",
    "4. monthly median and change\n",
    "5. key values by lake\n",
    "\n",
    "#### <span style=\"color:#008891\">Code groups: Significant events</span>\n",
    "\n",
    "1. definition\n",
    "2. significant events per lake\n",
    "3. frequency of ocurrence per group and lake\n",
    "\n",
    "#### <span style=\"color:#008891\">Regional assessment tools</span>\n",
    "\n",
    "Find the locations on one lake that may be hotspots for litter accumulation. Identify the ones that may be interesting to monitor in the future. Use the provided graphic and map to make your decision.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys, file and nav packages:\n",
    "import os\n",
    "import datetime as dt\n",
    "import csv\n",
    "\n",
    "# math packages:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import datetime as dt \n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "from scipy.stats import kendalltau, pearsonr, spearmanr\n",
    "import math\n",
    "\n",
    "# charting:\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib import ticker\n",
    "import matplotlib.ticker as mtick\n",
    "import seaborn as sns\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from IPython.display import display, Markdown, Latex, HTML\n",
    "\n",
    "# mapping\n",
    "import geopandas as gpd\n",
    "\n",
    "# home brew utitilties\n",
    "import utilities.utility_functions as ut\n",
    "\n",
    "# documenting\n",
    "from IPython.display import Markdown as md\n",
    "\n",
    "\n",
    "# returns the p_value for each test\n",
    "def kendall_pval(x,y):\n",
    "    return kendalltau(x,y)[1]\n",
    "\n",
    "def pearsonr_pval(x,y):\n",
    "    return pearsonr(x,y)[1]\n",
    "\n",
    "def spearmanr_pval(x,y):\n",
    "    return spearmanr(x,y)[1]\n",
    "\n",
    "# convenience functions for tables\n",
    "def make_table_grids(anax):\n",
    "    anax.grid(False)\n",
    "    anax.spines[\"top\"].set_visible(False)\n",
    "    anax.spines[\"right\"].set_visible(False)\n",
    "    anax.spines[\"bottom\"].set_visible(False)\n",
    "    anax.spines[\"left\"].set_visible(False)\n",
    "    return(anax)\n",
    "\n",
    "def table_fonts(a_table, size=12):\n",
    "    a_table.auto_set_font_size(False)\n",
    "    a_table.set_fontsize(size)\n",
    "# variables/arrays that are frequently used:\n",
    "# project lakes\n",
    "\n",
    "the_lakes = [\n",
    "    \"Bielersee\",\n",
    "    \"Walensee\",\n",
    "    \"Lac Léman\",\n",
    "    \"Zurichsee\",\n",
    "    \"Neuenburgersee\",\n",
    "    \"Thunersee\",\n",
    "    \"Lago Maggiore\",\n",
    "    \"Brienzersee\",\n",
    "]\n",
    "\n",
    "# standard formats already in use for charts, these will gradually\n",
    "# define the chart style or output format for the app\n",
    "# you can just apply these as kwargs to different elements...\n",
    "# table kwargs\n",
    "table_k = dict(loc=\"top left\", bbox=(0,0,1,1), colWidths=[.5, .5], cellLoc='center')\n",
    "tablecenter_k = dict(loc=\"top left\", bbox=(0,0,1,1), cellLoc='center')\n",
    "tabtickp_k = dict(axis='both', which='both', bottom=False, top=False, left=False, right=False, labelleft=False, labelbottom=False)\n",
    "\n",
    "# chart kwargs\n",
    "title_k = {'loc':'left', 'pad':12, 'linespacing':1.5, 'fontsize':12}\n",
    "title_k14 = {'loc':'left', 'pad':12, 'linespacing':1.5, 'fontsize':14}\n",
    "title_k20 = {'loc':'left', 'pad':10, 'linespacing':1.5, 'fontsize':12, 'color':'dodgerblue'}\n",
    "title_k17 = {'loc':'left', 'pad':10, 'linespacing':1.5, 'fontsize':12, 'color':'salmon'}\n",
    "titler_k20 = {'loc':'right', 'pad':10, 'linespacing':1.5, 'fontsize':12, 'color':'dodgerblue'}\n",
    "titler_k17 = {'loc':'right', 'pad':10, 'linespacing':1.5, 'fontsize':12, 'color':'salmon'}\n",
    "xlab_k = {'labelpad':10, 'fontsize':12}\n",
    "ylab_k = {'labelpad':14, 'fontsize':14}\n",
    "titler_k = {'loc':'right', 'pad':10, 'linespacing':1.5, 'fontsize':12}\n",
    "label45r = {'rotation':45, 'ha':'right'}\n",
    "label45c = {'rotation':45, 'ha':'center'}\n",
    "\n",
    "# use these to format date axis in charts\n",
    "weeks = mdates.WeekdayLocator(byweekday=1, interval=4)\n",
    "onedayweek = mdates.DayLocator(bymonthday=1, interval=1)\n",
    "everytwoweeks = mdates.WeekdayLocator(byweekday=1, interval=4)\n",
    "\n",
    "months = mdates.MonthLocator(bymonth=[3,6,9,12])\n",
    "bimonthly = mdates.MonthLocator(bymonth=[1,3,5,7,9,11])\n",
    "allmonths = mdates.MonthLocator()\n",
    "wks_fmt = mdates.DateFormatter('%d')\n",
    "mths_fmt = mdates.DateFormatter('%b')\n",
    "\n",
    "# map marker size:\n",
    "markerSize = 100\n",
    "survey_data, location_data, code_defs, stat_ent, geo_data, output = ut.make_local_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "som_names = {\n",
    "    \"waste water\": \"wastewater.json\" ,\n",
    "    \"less than 5mm\":\"codeListMicros.json\",\n",
    "    \"construction\":\"construction.json\",\n",
    "    \"food\":\"foodstuff.json\",\n",
    "    \"agg-con-trans\":\"cat.json\",\n",
    "    \"agriculture\":\"ag.json\",\n",
    "    \"tobacco\":\"tobac.json\",\n",
    "    \"recreation\":\"recreation.json\",    \n",
    "    \"packaging\":\"packaging.json\",\n",
    "    \"personal items\":\"pi.json\",    \n",
    "}\n",
    "def make_group_map(a_dict_of_lists):\n",
    "    wiw = {}\n",
    "    for group in a_dict_of_lists:\n",
    "        keys = a_dict_of_lists[group]\n",
    "        a_dict = {x:group for x in keys}\n",
    "        wiw.update(**a_dict)\n",
    "    return wiw\n",
    "\n",
    "these_groups ={k:ut.json_file_get(F\"{output}/code_groups/{v}\") for k,v in som_names.items()}\n",
    "these_groups.update({\"fragmented plastics\":[\"G79\", \"G78\", \"G75\"]})\n",
    "group_names = list(these_groups.keys())\n",
    "\n",
    "# collect the codes\n",
    "accounted = [v for k,v in these_groups.items()]\n",
    "accounted = [item for a_list in accounted for item in a_list]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'water_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-1a9b600f0159>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;31m# restrict to lakes only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;31m# aggregated to the parent code, which is an MLW code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m \u001b[0mdfS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwater_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthe_lakes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0mdfS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loc_date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdfS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/refactor_process/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5138\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'water_name'"
     ]
    }
   ],
   "source": [
    "# the local file structure. The resources are located in the corresponding directory.\n",
    "\n",
    "\n",
    "# set some parameters:\n",
    "start_date = '2020-04-01'\n",
    "end_date = dt.datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "startyearmonth = '{}/{}'.format(start_date[5:7], start_date[:4])\n",
    "endyearmonth = '{}/{}'.format(end_date[5:7], end_date[:4]) \n",
    "\n",
    "# decide which data to use\n",
    "aggregated = False\n",
    "\n",
    "french_names = {\n",
    "    \"waste water\":\"traitement d'eau\",\n",
    "    \"less than 5mm\":\"moins que 5mm\",\n",
    "    \"construction\":\"construction\",\n",
    "    \"food\":\"alimentation\",\n",
    "    \"agg-con-trans\":\"const-trans-ag\",\n",
    "    \"agriculture\":\"agriculture\",\n",
    "    \"the rest\":\"le rest\",\n",
    "    \"tobacco\":\"tabac\",\n",
    "    \"recreation\": \"recreation\",\n",
    "    \"fragmented plastics\":\"plastiques fragmentés\",\n",
    "    \"packaging\":\"emballages\",\n",
    "    \"personal items\":\"affaires personnelles\",\n",
    "    \"survey total\":\"total du jour\"\n",
    "}\n",
    "\n",
    "\n",
    "# collect the names:\n",
    "group_names = list(these_groups.keys())\n",
    "\n",
    "# choose a lake:\n",
    "lake = 'Lac Léman'\n",
    "\n",
    "# define a significant event:\n",
    "sig = .9\n",
    "one_minus_sig = (1-sig)\n",
    "\n",
    "# define explanatory variables:\n",
    "expv = ['population','streets','buildings','rivs']\n",
    "\n",
    "# name the folder:\n",
    "name_of_project = 'codegroupsummaryMarch2020'\n",
    "\n",
    "# use this to store things:\n",
    "project_directory = ut.make_project_folder(output, name_of_project)\n",
    "\n",
    "# get the data\n",
    "# aggregated survey data\n",
    "dfAgg = pd.read_csv(F\"{survey_data}/results_with_zeroes_aggregated_parent.csv\")\n",
    "dfAgg['date'] = pd.to_datetime(dfAgg['date'])\n",
    "dfAgg = dfAgg[dfAgg.date >= start_date]\n",
    "dfAgg = dfAgg[dfAgg.location != 'pfafikon-bad']\n",
    "dfAgg['groupname'] = 'nogroup'\n",
    "\n",
    "# non aggregated survey data\n",
    "dfSurveys = pd.read_csv(F\"{survey_data}/results_with_zeroes.csv\")\n",
    "dfSurveys['date'] = pd.to_datetime(dfSurveys['date'])\n",
    "dfSurveys = dfSurveys[dfSurveys.date >= start_date]\n",
    "dfSurveys = dfSurveys[dfSurveys.location != 'pfafikon-bad']\n",
    "dfSurveys['groupname'] = 'nogroup'\n",
    "\n",
    "# beach data\n",
    "dfBeaches = pd.read_csv(F\"{location_data}/beaches_with_ranks.csv\")\n",
    "dfBeaches.set_index('slug', inplace=True)\n",
    "dfBeaches.rename(columns={\"NUMPOINTS\":\"intersects\"}, inplace=True)\n",
    "\n",
    "# code definitions\n",
    "dfCodes = pd.read_csv(F\"{code_defs}/mlw_codes.csv\", index_col='code')\n",
    "\n",
    "cols_to_keep = ['loc_date',\n",
    "                'location',\n",
    "                'water_name',\n",
    "                'date',\n",
    "                'population',\n",
    "               ]\n",
    "\n",
    "# geo data: explantory variables, index by slug and make a map:\n",
    "# dfStreets = pd.read_csv(F\"{geo_data}/exp_variables/strasse_1000.csv\", index_col='slug')['length']\n",
    "# dfBlds = pd.read_csv(F\"{geo_data}/exp_variables/builds_500.csv\", index_col='slug')['surface']\n",
    "# dfRivs = pd.read_csv(F\"{geo_data}/exp_variables/riparian_intersects.csv\", index_col='slug')['NUMPOINTS']\n",
    "\n",
    "# restrict to lakes only\n",
    "# aggregated to the parent code, which is an MLW code\n",
    "dfS = dfAgg.loc[(dfAgg.water_name.isin(the_lakes))].copy()\n",
    "dfS['loc_date'] = zip(dfS.location,dfS.date)\n",
    "\n",
    "# these values are not aggregated:\n",
    "dfNag = dfSurveys.copy()\n",
    "thesecols = ['loc_date',\n",
    "             'location',\n",
    "             'water_name',\n",
    "             'date']\n",
    "\n",
    "# there are somecodes that allways need to be aggregated:\n",
    "dfNagl = dfNag.copy()\n",
    "mapG82 = dfNagl[dfNagl.code.isin(['G82', 'G912'])].groupby(thesecols, as_index=False).agg({'pcs_m':'sum', 'quantity':'sum'})\n",
    "mapG82['code'] = 'G82'\n",
    "mapG81 = dfNagl[dfNagl.code.isin(['G81', 'G911'])].groupby(thesecols, as_index=False).agg({'pcs_m':'sum', 'quantity':'sum'})\n",
    "mapG81['code'] = 'G81'\n",
    "mapG74 = dfNagl[dfNagl.code.isin(['G74', 'G910', 'G909'])].groupby(thesecols, as_index=False).agg({'pcs_m':'sum', 'quantity':'sum'})\n",
    "mapG74['code'] = 'G74'\n",
    "dfnofoam = dfNag.loc[~dfNag.code.isin(['G82', 'G912','G81', 'G911','G74', 'G910', 'G909'])]\n",
    "newdf = pd.concat([dfnofoam,mapG74,mapG81,mapG82])\n",
    "newdfx = newdf.copy()\n",
    "\n",
    "newdf = newdf.loc[(newdf.water_name.isin(the_lakes))&(newdf.date >= start_date)]\n",
    "\n",
    "dfS['population']=dfS.location.map(lambda x: dfBeaches.loc[x]['population'])\n",
    "\n",
    "# these need to be moved to context:\n",
    "# map geo values to aggregated survey results:\n",
    "# dfS['streets'] = dfS.location.map(lambda x: dfStreets.loc[x])\n",
    "# dfS['buildings'] = dfS.location.map(lambda x: dfBlds.loc[x])\n",
    "# dfS['rivs'] = dfS.location.map(lambda x: dfRivs.loc[x])\n",
    "# dfS['pop_streets'] = dfS.population + dfS.streets\n",
    "# dfS['pop_builds'] = dfS.population + dfS.buildings\n",
    "# dfS['streets_builds'] = dfS.streets + dfS.rivs\n",
    "\n",
    "newdf['population']=newdf.location.map(lambda x: dfBeaches.loc[x]['population'])\n",
    "\n",
    "# these need to be moved to context\n",
    "# map geo values to non aggregated survey results:\n",
    "# newdf['streets'] = newdf.location.map(lambda x: dfStreets.loc[x])\n",
    "# newdf['buildings'] = newdf.location.map(lambda x: dfBlds.loc[x])\n",
    "# newdf['rivs'] = newdf.location.map(lambda x: dfRivs.loc[x])\n",
    "# newdf['pop_streets'] = newdf.population + newdf.streets\n",
    "# newdf['pop_builds'] = newdf.population + newdf.buildings\n",
    "# newdf['streets_builds'] = newdf.streets + newdf.buildings\n",
    "\n",
    "if aggregated:\n",
    "    print(\"Using aggregated data\")\n",
    "    useThis = dfS.copy()\n",
    "else:\n",
    "    print(\"Using non aggregated data\")\n",
    "    useThis = newdf.copy()\n",
    "    \n",
    "codes_in_use = useThis.code.unique()\n",
    "\n",
    "# make a code group of the unaccounted for codes:\n",
    "the_rest = [x for x in codes_in_use if x not in accounted]\n",
    "these_groups.update({'the rest':the_rest})\n",
    "group_names = list(these_groups.keys())\n",
    "\n",
    "# map code to group in the survey results\n",
    "a_group_map = make_group_map(these_groups)\n",
    "useThis['groupname'] = useThis.code.map(lambda x: a_group_map[x])\n",
    "\n",
    "# make sure to have acces to this column throughout\n",
    "cols_to_keep.append('groupname')\n",
    "\n",
    "# keep track of the files you are exporting:\n",
    "files_generated = []\n",
    "\n",
    "# method to save\n",
    "def add_output(a_name, a_tag, atype=\"table\", fignum=0, a_list=files_generated):\n",
    "    tableonefile = F\"{project_directory}/{a_name}\"\n",
    "    files_generated.append({'tag':a_tag, 'number':fignum, 'file':tableonefile,'type':atype})\n",
    "    plt.savefig(tableonefile, dpi=300)\n",
    "\n",
    "# save files\n",
    "survey_csv = F\"{project_directory}/survey_data.csv\"\n",
    "files_generated.append(survey_csv)\n",
    "useThis.to_csv(survey_csv, index=False)\n",
    "\n",
    "beaches_csv = F\"{project_directory}/beach_data.csv\"\n",
    "files_generated.append(beaches_csv)\n",
    "dfBeaches.to_csv(beaches_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geo output\n",
    "locs = newdf.location.unique()\n",
    "these_beaches = dfBeaches[dfBeaches.index.isin(locs)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_totals = useThis.groupby(['loc_date','location','water_name', 'date','population'], as_index=False).agg({\"pcs_m\":\"sum\", \"quantity\":\"sum\"})\n",
    "survey_totals.set_index('loc_date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# place to store the summaries\n",
    "regional_summaries = []\n",
    "\n",
    "# creating a summary for each df in groupdfs\n",
    "\n",
    "def account_for_no_vals(x, a_df):\n",
    "    if x in a_df.index:\n",
    "        data = a_df.loc[x].location\n",
    "    else:\n",
    "        data = 0\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_agg = {'location':'nunique', 'loc_date':'nunique', 'pcs_m':'mean', 'quantity':'sum'}\n",
    "agrouper = useThis.groupby(['water_name', 'groupname'])\n",
    "regional_summary = agrouper.agg(this_agg)\n",
    "\n",
    "regions = list(regional_summary.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_defs_codes = {\n",
    "    'G95': 'Coton-tige',\n",
    "    'G100': 'Médical conteneurs/tubes/ emballages',\n",
    "    'G98': 'Couches - lingettes',\n",
    "    'G96': 'Serviettes hygiéniques / protège-slips / tampons et ...',\n",
    "    'G91': 'Porte-biomasse',\n",
    "    'G133':'Préservatifs, y compris emballage',\n",
    "    'G144':'Tampons',\n",
    "    'G97': 'Rafraîchisseurs de toilettes',\n",
    "    \"G112\":\"Pellets industriels (GPI)\",\n",
    "    \"G117\":\"polystyrène < 5mm\",\n",
    "    \"G106\":\"Fragments de plastique angulaires <5mm\",\n",
    "    \"G103\":\"fragments de plastique arrondis <5mm\",\n",
    "    \"G115\":\"Mousse de plastique <5mm\",\n",
    "    \"G105\":\"fragments de plastique subangulaires <5mm\",\n",
    "    \"G114\":\"Films <5mm\",\n",
    "    \"G118\":\"Petites sphères industrielles <5mm\",\n",
    "    \"G123\":\"Granulés de polyuréthane < 5mm\",\n",
    "    \"G113\":\"Filaments <5mm\",\n",
    "    \"G119\":\"Plastique utilisateur en feuille (>1mm)\",\n",
    "    \"G122\":\"Fragments de plastique ( >1mm)\",\n",
    "    \"G107\":\"Boulettes cylindriques < 5mm\",\n",
    "    \"G108\":\"pastilles de disque <5mm\",\n",
    "    \"G109\":\"Pellets plats <5mm\",\n",
    "    \"G111\":\"Granulés sphéroïdes < 5mm\",\n",
    "    \"G104\":\"fragments de plastique sous-arrondis <5mm\",\n",
    "    \"G81\":\"Morceaux de polystyrène expansé 0,5cm - 2,5cm\",\n",
    "    \"G82\":\"Mousse de polystyrène ; perles/billes expansées 2,5 cm\",\n",
    "    \"G74\":\"Mousse de plastique pour l'isolation thermique ou ...\",\n",
    "    \"G89\":\"Déchets de construction en plastique\",\n",
    "    \"G73\":\"Articles et pièces en mousse (sans emballage ou... liés)\",\n",
    "    \"G22\":\"Couvercles pour produits chimiques, détergents (non alimentaires)\",\n",
    "    \"G66\":\"sangles/bandes ; fermeture de paquet en plastique dur\",\n",
    "    \"G921\":\"Carreaux et pièces de céramique\",\n",
    "    \"G908\": \"Ruban ; électrique, isolant\",\n",
    "    \"G186\":\"Débris industriels\",\n",
    "    \"G93\": \"Colson, zip-ties\",\n",
    "    \"G87\": \"Ruban adhésif, masquage/conduit/emballage\",\n",
    "    \"G194\":\"Câbles, fil(s) métallique(s) souvent à l'intérieur du caoutchouc ou...\",\n",
    "    \"G931\":\"Ruban adhésif pour barrière, police, construction\",\n",
    "    \"G68\":\"Fragments de fibre de verre\",\n",
    "    \"G83\":\"Pièces en polystyrène > 50cm\",\n",
    "    \"G17\":\"Cartouche pour pistolet d'injection\",\n",
    "    \"G174\":\"Bombes aérosols\",\n",
    "    \"G190\":\"Bidons de peinture\",\n",
    "    \"G188\":\"Autres bidons < 4 L\",\n",
    "    \"G27\": \"Mégots et filtres à cigarettes\", \n",
    "    \"G30\": \"Emballages alimentaires ; emballages de bonbons, de snacks\", \n",
    "    \"G21\": \"Couvercles de bouteilles\", \n",
    "    \"G25\": \"Tabac ; emballages en plastique, conteneurs\", \n",
    "    \"G24\" :\"Couvercle/anneaux de fermeture de bouteilles/récipients en plastique\", \n",
    "    \"G35\": \"Pailles et agitateurs\", \n",
    "    \"G31\": \"Bâtonnets de sucette\", \n",
    "    \"G32\": \"Jouets et faveurs de fête\", \n",
    "    \"G33\": \"Gobelets, couvercles, mousse à usage unique et plastique dur\", \n",
    "    \"G34\": \"Couverts, assiettes et plateaux palstique\",\n",
    "    \"G67\":\"Bâche plastique industrielle\",\n",
    "    \"G38\":\"Couvertures ; emballages en plastique gros calibre\",\n",
    "    \"G204\" :\"Matériaux de construction ; briques, tuyaux, ciment\",\n",
    "    \"G191\" :\"Fils et grillages\",\n",
    "    \"G170\" :\"Bois (transformé)\",\n",
    "    \"G161\" :\"Bois transformé\",\n",
    "    \"G919\" :\"Clous, vis, boulons, etc.\",\n",
    "    \"G171\" :\"Autre bois < 50cm\",\n",
    "    \"G13\":\"Bouteilles, conteneurs, fûts pour le transport, le stockage\",\n",
    "    \"G14\": \"Bouteilles d'huile moteur\",\n",
    "    \"G172\":\"Autres bois > 50cm\",\n",
    "    \"G41\":\"Gant industriel/professionnel\",\n",
    "    \"G936\":\"Film sur les serres\",\n",
    "    \"G937\":\"Appâts à phéromones pour les vignobles\",\n",
    "    \"G943\":\"Clôturer l'agriculture, plastique\",\n",
    "    \"G36\":\"Sacs/sacs en plastique résistant pour 25 kg ou plus\",\n",
    "    \"G81\":\"Morceaux de polystyrène expansé 0,5cm - 2,5cm\",\n",
    "    \"G30\":\"Emballages alimentaires ; emballages de bonbons, de snacks\",\n",
    "    \"G67\":\"Feuilles industrielles\",\n",
    "    \"G82\":\"Mousse de polystyrène; perles/billes expansées > 2,5 cm -\",\n",
    "    \"G74\":\"Mousse de plastique pour l'isolation thermique ou ...\",\n",
    "    \"G117\": \"Polystyrène expansée < 5mm\",\n",
    "    \"G89\":\"Déchets de construction en plastique\",\n",
    "    \"G21\":\"Couvercles de boissons\",\n",
    "    \"G24\":\"Couvercle/anneaux de fermeture de bouteilles/récipients en plastique\",\n",
    "    \"G23\":\"Couvercles non identifiés\",\n",
    "    \"G73\":\"Articles et pièces en mousse (sans emballage ou... liés)\",\n",
    "    \"G22\":\"Couvercles pour produits chimiques, détergents (non alimentaires)\",\n",
    "    \"G78\":\"Plastiques fragmentés .5mm < x < 25mm\",\n",
    "    \"G79\":\"Plastiques fragmentés x > 25mm\",\n",
    "    \"G200\":\"verre brisé \",\n",
    "    \"G10\":\"Emballage fast food\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a table for key statistics:\n",
    "somdata = survey_totals\n",
    "a_sum = pd.DataFrame(somdata.pcs_m.describe()[1:].round(2)).T\n",
    "a_sum_table = [[x] for x in a_sum.values[0]]\n",
    "rowLabels = [x for x in list(a_sum.columns)]\n",
    "\n",
    "\n",
    "def map_to_group_type(x):\n",
    "    if x in ['diffusion','less than 5mm']:\n",
    "        thistype = 'phys'\n",
    "    else:\n",
    "        thistype = 'econ'\n",
    "    return thistype\n",
    "limit=50\n",
    "def count_k(a_string, limit):\n",
    "    split = a_string.split(\" \")\n",
    "    total = 0\n",
    "    new_words = []\n",
    "    for i,word in enumerate(split):\n",
    "        if (total + len(word))+1 >= limit:\n",
    "            thisnewword = F\"{split[i-1]}...\"\n",
    "            if (len(thisnewword) + total) <= limit:\n",
    "                del new_words[-1]\n",
    "                new_words.append(thisnewword)\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            total += len(word)+1\n",
    "            new_words.append(word)\n",
    "\n",
    "    return \" \".join(new_words)\n",
    "\n",
    "colors = ['dodgerblue', 'salmon', 'teal', 'red','maroon','goldenrod', 'mediumspringgreen', 'slategray','olive','yellowgreen', 'purple', 'orange', 'cyan']\n",
    "grouppalette = {x:colors[i] for i,x in enumerate(group_names)}\n",
    "\n",
    "\n",
    "is_french = False\n",
    "is_german = False\n",
    "is_italian = False\n",
    "\n",
    "french_sum_names = {\"survey total\":\"total de l'enquête\", **french_names}\n",
    "thing = 'objets'\n",
    "parent = \"de l'ensemble\"\n",
    "french_pcm = \"pièces par mètre\"\n",
    "french_srs = \"résultats des recensements\"\n",
    "french_pcg = \"par groupe de codes\"\n",
    "french_pct = \"pourcentage du total\"\n",
    "french_med = \"médian\"\n",
    "french_mm = \"médiane mensuelle\"\n",
    "french_change = 'changement'\n",
    "french_bg = \"par groupe\"\n",
    "french_nooutliers = \"les valeurs extrêmes ne sont pas indiquées\"\n",
    "french_columns = {'code':'code','description': 'description', 'material':'matériel', 'quantity':'quantité', '% of total':'% du total', 'group':'groupe'}\n",
    "of_prep= 'de'\n",
    "frname = [v for k,v in french_names.items()]\n",
    "frpalette = {french_names[x]:grouppalette[x] for x in grouppalette}\n",
    "summary_row_fr = ['moy', 'et', 'min', '25%', '50%', '75%', 'max']\n",
    "french_key_values = \"valeurs clés\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_french:    \n",
    "    sommarkdown = \"\"\"### <span style='color:#1e90ff'>Méthodes</span>\\n#### <span style='color:#008891'>Source des données, calendrier, portée géographique et méthodes de collecte</span>\\n\n",
    "    Les données utilisées pour cette analyse sont les résultats d'enquêtes sur les déchets de plage menées en Suisse. Toutes les enquêtes qui ont été menées sur le lac de Bienne, le lac de Neuchâtel, le lac de Thoune, le lac Walensee, le lac de Zurich, le lac Léman, le lac Brienze et le lac Magiore ont été prises en compte.\\n\n",
    "    Les données ont été collectées selon le protocole décrit ici https://www.plagespropres.ch/. En bref, toutes les déchets visibles sont collectées le long d'une plage à une distance mesurée du bord de l'eau. La largeur de la zone d'étude dépend du terrain et du niveau de l'eau. La ligne de rive visible ou la structure physique la plus proche définit la largeur d'une enquête (figure 1).\\n\n",
    "    Des enquêtes ont été menées par:\\n\n",
    "    1. hammerdirt\n",
    "    2. Association pour le Sauvegarde du leman\n",
    "    3. Solid Waste Management Ecole Polytechnique Federal\n",
    "    4. Ecole International de Geneve\n",
    "    5. Precious plastic leman\n",
    "    6. Why isn't your association here?\\n\n",
    "    Cette analyse est un document open source. Le cahier de notes de travail est disponible dans le dépôt situé ici: https://github.com/hammerdirt-analyst/iqals.\\n\n",
    "    \n",
    "    \"\"\"\n",
    "else:\n",
    "    sommarkdown = \"\"\"### <span style=\"color:#1e90ff\">Methods</span>\\n#### <span style=\"color:#008891\">Data source, time frame, geographic scope and collection methods </span>\\n\n",
    "    The data for this analysis is the results from beach-litter surveys conducted in Switzerland.\\n\n",
    "    All surveys that were conducted on Bielersee, Neuenburgersee, Thunersee, Walensee, Zurichsee, Lac Léman, Brienzersee and Lago Magiore were considered.\\n \n",
    "    The data was collected according to the protocol described here https://www.plagespropres.ch/. In brief all visible data is collected along a beach within a measured distance from the waters edge. The width of the survey area depends on the terrain and the water level. The visible strand line or the nearest physical structure defines the width of a survey (figure 1).\\n\n",
    "    Surveys were conducted by the following organizations:\\n\n",
    "    1. hammerdirt\n",
    "    2. Association pour le Sauvegarde du leman\n",
    "    3. Solid Waste Management Ecole Polytechnique Federal\n",
    "    4. Ecole International de Geneve\n",
    "    5. Precious plastic leman\n",
    "    6. Why isn't your association here?\\n\n",
    "    This analysis is an open source document. The working note book is available in the repository located here https://github.com/hammerdirt-analyst/iqals.\\n\n",
    "\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(sommarkdown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "figure_num = 1\n",
    "map_num = 1\n",
    "\n",
    "plt.axvspan(xmin=0, xmax=1, fc='antiquewhite', label='littoral')\n",
    "plt.axvspan(xmin=0.6, xmax=1, fc='dodgerblue', label='lac/rivière')\n",
    "# plt.axvspan(xmin=0.2, xmax=0.5, fc='None', label='debris field')\n",
    "plt.axvspan(xmin=0.2, xmax=0.6, fc='None', ec='tan', hatch=\"x\", label=\"zone d'intérêt\")\n",
    "plt.axvspan(xmin=0.19, xmax=0.6, ymin=0.2, ymax=0.8, fc='salmon', alpha=0.4, ec='black', linewidth=8, label='zone de recensement')\n",
    "plt.axvline(x=0.2, linestyle=\":\",  c='tan', linewidth=8, label =\"plus haut ligne de rive\" )\n",
    "plt.axvline(x=0.19, linestyle=\":\",  c='tan', linewidth=8 )\n",
    "ax.annotate(\"zone de recensement\", xy=(0.4, 0.5), xycoords=\"data\",\n",
    "                  va=\"center\", ha=\"center\", size=20,\n",
    "                  bbox=dict(boxstyle=\"round\", fc=\"w\"))\n",
    "\n",
    "make_table_grids(ax)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.suptitle(F\"Figure {figure_num}: schéma d'un recensement\", x=0.16, fontsize=18, y=0.92,ha='left')\n",
    "plt.legend(fontsize=(14), framealpha=1, bbox_to_anchor=(0.6, .9), loc='upper left')\n",
    "\n",
    "figname = F\"figure{figure_num}.jpg\"\n",
    "atype = \"figure\"\n",
    "add_output(figname,  'schematic of a survey', fignum=figure_num, atype=atype)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_french:\n",
    "    sommarkdown = \"\"\"#### <span style=\"color:#008891\">Scope of surveys</span>\\n\n",
    "    Le champ d'application des enquêtes comprend toutes les berges accessibles sur les lacs mentionnés précédemment dans les conditions suivantes:\\n\n",
    "    \n",
    "    1. Les transports publics sont à moins d'une demi-heure de marche\n",
    "    2. Le lieu est un bien public\n",
    "    3. La zone d'enquête est sûre\n",
    "    4. Il n'y a pas de contre-indications à la réalisation d'un recensement\\n    \n",
    "    \"\"\"\n",
    "else:\n",
    "    sommarkdown = \"\"\"#### <span style=\"color:#008891\">Scope of surveys</span>\\n\n",
    "    The scope of the surveys includes all accessible shoreline on the previously mentioned lakes given the following conditions:\\n\n",
    "    \n",
    "    1. Public transport is 1/2 hour away on foot\n",
    "    2. The land is open to the public\n",
    "    3. The location is safe\n",
    "    4. There is no reason to not do the survey\\n    \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(sommarkdown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_french:\n",
    "    sommarkdown = \"\"\"### <span style=\"color:#1e90ff\"> Données de synthèse: toutes les enquêtes</span>\\n    \n",
    "    Depuis le 14 avril 2020, 301 échantillons ont été enregistrés, 266 provenant des lacs et 35 de rivières (graphique 1, tableau 1).\\n    \n",
    "    Le nombre d'échantillons dépasse à la fois nos attentes personnelles et les exigences du contrat. Cependant, il reste encore trois mois d'échantillonnage.\\n    \n",
    "    Nous remercions les personnes suivantes pour leur participation:\\n\n",
    "    1. Helen Kurukulasuriya\n",
    "    2. Martin Brenvasser\n",
    "    3. Adrien Bonny\n",
    "    4. Debora Camaro\n",
    "    5. Geatan Busser\n",
    "    6. Marie-France Labelle\n",
    "    7. Andreas Gauer\n",
    "    \n",
    "    \"\"\"\n",
    "else:\n",
    "    sommarkdown = \"\"\"### <span style=\"color:#1e90ff\"> Summary data: all surveys</span>\\n    \n",
    "    Since april 14, 2020 301 samples have been recorded, 266 from lakes and 35 from rivers (figure 1, table 1).\\n \n",
    "    The number of samples exceeds both our personal expectations and the contract requirements. However there are still three more months of sampling.\\n \n",
    "    Thanks to the following individuals for their participation:\\n \n",
    "    1. Helen Kurukulasuriya\n",
    "    2. Martin Brenvasser\n",
    "    3. Adrien Bonny\n",
    "    4. Debora Camaro\n",
    "    5. Geatan Busser\n",
    "    6. Marie-France Labelle\n",
    "    7. Andreas Gauer\n",
    "    8. Gaetan Buser\\n\n",
    "    \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(sommarkdown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep track of the figures you produce\n",
    "\n",
    "# use all the surveys un aggregated\n",
    "allsurveys =  newdfx[newdfx.date >= '2020-04-01'].groupby(['loc_date', 'location', 'date', 'water_name'], as_index=False).pcs_m.sum()\n",
    "\n",
    "# identify lakes v/s rivers\n",
    "allsurveys['type'] = allsurveys.location.map(lambda x: dfBeaches[dfBeaches.index == x]['water'].values[0])\n",
    "\n",
    "# count the number of rivers and lakes\n",
    "v_counts = allsurveys['type'].value_counts()\n",
    "rivercount = int(v_counts['r'])\n",
    "lakecount = int(v_counts['l'])\n",
    "\n",
    "# make a table for key statistics:\n",
    "a_sum = pd.DataFrame(allsurveys.pcs_m.describe()[1:].round(2)).T\n",
    "a_sum_table = [[x] for x in a_sum.values[0]]\n",
    "rowLabels = [x for x in list(a_sum.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust table kwargs\n",
    "tablecenter_k = dict(loc=\"center\", bbox=(0,0,1,1), cellLoc='center')\n",
    "\n",
    "fig = plt.figure(constrained_layout = False, figsize=(12,6))\n",
    "figure_num += 1\n",
    "\n",
    "# declare a grid\n",
    "gs = GridSpec(1, 5, figure=fig)\n",
    "\n",
    "# put an ax on it\n",
    "ax1 = fig.add_subplot(gs[4:])\n",
    "\n",
    "# the context matters for the row and column labels\n",
    "if is_french:\n",
    "    rowLabels = summary_row_fr\n",
    "    col_label = [french_pcm]\n",
    "else:\n",
    "    col_label = ['pieces per meter']\n",
    "\n",
    "# define the table\n",
    "a_table = mpl.table.table(\n",
    "    cellText=a_sum_table,\n",
    "    rowLabels=rowLabels,\n",
    "    rowColours=['antiquewhite' for i in rowLabels],\n",
    "    colLabels=['pieces per meter'],\n",
    "    colColours=['antiquewhite' for col in np.arange(1)],\n",
    "    \n",
    "    ax=ax1,\n",
    "    **tablecenter_k)\n",
    "\n",
    "def table_format(a_table, ax, size=12):\n",
    "    table_fonts(a_table, size=size)\n",
    "    make_table_grids(ax)\n",
    "    ax.tick_params(**tabtickp_k)\n",
    "\n",
    "table_format(a_table, ax1) \n",
    "\n",
    "# add table to ax\n",
    "ax1.add_table(a_table )\n",
    "\n",
    "# scatter plot\n",
    "ax2 = fig.add_subplot(gs[0:4])\n",
    "sns.scatterplot(data=allsurveys, x='date',  y='pcs_m', alpha=1, linewidth=1,s=80, ax=ax2)\n",
    "\n",
    "# format scatter\n",
    "ax2.xaxis.set_major_formatter(mths_fmt)\n",
    "ax2.xaxis.set_major_locator(allmonths)\n",
    "ax2.set_xlabel(\"\")\n",
    "\n",
    "# context\n",
    "if is_french:\n",
    "    ax1.set_title(F\"{french_key_values}\", loc='left', pad=10)\n",
    "    ax2.set_title(F\"Figure {figure_num}: {french_srs} {startyearmonth} - {endyearmonth}, échantillons={len(allsurveys)}, lacs={lakecount}, rivières={rivercount}.\", loc='left', pad=10)\n",
    "    ax2.set_ylabel(F\"{french_pcm}\", **ylab_k)\n",
    "else:\n",
    "    ax1.set_title(F\"key values\", loc='left', pad=10)\n",
    "    ax2.set_ylabel(\"Pieces per meter\", **ylab_k)\n",
    "    ax2.set_title(F\"Figure {figure_num}: survey totals {startyearmonth} - {endyearmonth}, all codes all locations. Samples={len(allsurveys)}, lakes={lakecount}, rivers={rivercount}\", loc='left', pad=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# tag the output:\n",
    "figname = F\"figure{figure_num}.jpg\"\n",
    "atype = \"figure\"\n",
    "tag =  'all surveys: scatter plot, key values table'\n",
    "add_output(figname, tag, fignum=figure_num, atype=atype)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_french:\n",
    "    sommarkdown = \"\"\"#### <span style=\"color:#008891\"> Les objets les plus communs: toutes les enquêtes </span>\\n    \n",
    "    \"\"\"\n",
    "else:\n",
    "    sommarkdown = \"\"\"#### <span style=\"color:#008891\">Most common objects: all surveys</span>\\n    \n",
    "     \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(sommarkdown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the total quantity for each code\n",
    "allcodevals = pd.DataFrame(newdfx[newdfx.date >= '2020-04-01'].groupby('code').quantity.sum())\n",
    "\n",
    "# add description and material from the codes df\n",
    "allcodevals['description'] = allcodevals.index.map(lambda x: dfCodes.loc[x].description)\n",
    "allcodevals['material'] = allcodevals.index.map(lambda x: dfCodes.loc[x].material)\n",
    "allcodevals['group'] = allcodevals.index.map(lambda x: a_group_map[x])\n",
    "\n",
    "# get the total number of objects and the percent of total\n",
    "allcodevalst= allcodevals.quantity.sum()\n",
    "allcodevals['p_total'] = allcodevals.quantity/allcodevalst*100\n",
    "allcodevals['p_total'] = allcodevals['p_total'].round(2)\n",
    "\n",
    "# sort the values \n",
    "allcodevals = allcodevals.sort_values(by='quantity',ascending=False)\n",
    "\n",
    "# do some housekeeping\n",
    "allcodevals.rename(columns={'p_total':'% of total'}, inplace=True)\n",
    "allcodevals = allcodevals[['description', 'material', 'quantity', '% of total', 'group']]\n",
    "\n",
    "# format for charting\n",
    "allcodevals.reset_index(inplace=True)\n",
    "allcodevals['quantity'] = allcodevals.quantity.apply(lambda x: \"{:,}\".format(x))\n",
    "\n",
    "# define the most common objects:\n",
    "tabledata = allcodevals[allcodevals['% of total'] >= 2]\n",
    "\n",
    "# sum the % of total of the most common objects\n",
    "ptotal = tabledata['% of total'].sum()\n",
    "# is_french = True\n",
    "if is_french:\n",
    "    tabledatacopy = tabledata.copy()\n",
    "    tabledatacopy['description'] = tabledatacopy.code.map(lambda x: count_k(fr_defs_codes[x], limit))\n",
    "    tabledatacopy['group'] = tabledatacopy.group.map(lambda x: count_k(french_names[x], limit))\n",
    "    tabledatacopy.rename(columns=french_columns, inplace=True)\n",
    "    tabledata = tabledatacopy\n",
    "\n",
    "# make adjustments to table kwargs:\n",
    "tablecenter_k = dict(loc=\"center\", bbox=(0,0,1,1), colWidths=[10,46, 10, 10, 10,14], cellLoc='center')\n",
    "\n",
    "# plot the table:\n",
    "fig, ax = plt.subplots(figsize=(15, len(tabledata)*.75))\n",
    "figure_num += 1\n",
    "ax = make_table_grids(ax)\n",
    "a_table = mpl.table.table(\n",
    "    cellText=tabledata.values,\n",
    "    colLabels=tabledata.columns,\n",
    "    colColours=['antiquewhite' for col in list(tabledata.columns)],    \n",
    "    ax=ax,\n",
    "    **tablecenter_k)\n",
    "\n",
    "# set parameters\n",
    "table_fonts(a_table, size=12)\n",
    "ax.tick_params(**tabtickp_k)\n",
    "\n",
    "# add the table\n",
    "ax.add_table(a_table)\n",
    "\n",
    "\n",
    "if is_french:\n",
    "    ax.set_title(F\"Figure {figure_num}: top {len(tabledata)} codes, {np.round(ptotal, 2)}% de {'{:,}'.format(allcodevalst)} objets\", **title_k14)\n",
    "else:\n",
    "    ax.set_title(F\"Figure {figure_num}: top {len(tabledata)} codes, {np.round(ptotal, 2)}% of {'{:,}'.format(allcodevalst)} objects\", **title_k14)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "figname = F\"figure{figure_num}.jpg\"\n",
    "tag = 'all surveys: most common objects table'\n",
    "add_output(figname, tag, fignum=figure_num)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_french:\n",
    "    sommarkdown = \"\"\"### <span style=\"color:#1e90ff\"> Données de synthèse sur les lacs du projet </span>\\n\n",
    "    \n",
    "    Il y a 8 lacs concernés par le projet:\\n\n",
    "\n",
    "    1. Zurichsee\n",
    "    2. Lago Maggiore\n",
    "    3. Thunersee\n",
    "    4. Lac Léman\n",
    "    5. Bielersee\n",
    "    6. Lac de Neuchâtel\n",
    "    7. Walensee\n",
    "    8. Brienzersee\\n\n",
    "\n",
    "    Le lac de Brienze a été ajouté à la liste des lacs étudiés, en raison de sa position dans le bassin versant de l'Aare (graphique 2, tableau 3).\n",
    "    \n",
    "    \"\"\"\n",
    "else:\n",
    "    sommarkdown = \"\"\"### <span style=\"color:#1e90ff\"> Project lakes summary data </span>\\n\n",
    "    \n",
    "    There are eight project lakes:\\n\n",
    "\n",
    "    1. Zurichsee\n",
    "    2. Lago Maggiore\n",
    "    3. Thunersee\n",
    "    4. Lac Léman\n",
    "    5. Bielersee\n",
    "    6. Neuenburgersee\n",
    "    7. Walensee\n",
    "    8. Brienzersee\\n\n",
    "\n",
    "    Brienzersee was added to the surveys beacuase of it's position in the catchment area of the Aare (figure 2, table 3).\n",
    "    \n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(sommarkdown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tablecenter_k = dict(loc=\"center\", bbox=(0,0,1,1), cellLoc='center')\n",
    "\n",
    "fig = plt.figure(constrained_layout = False, figsize=(12,6))\n",
    "figure_num += 1\n",
    "\n",
    "ax1 = fig.add_subplot(gs[4:])\n",
    "\n",
    "if is_french:\n",
    "    rowLabels = summary_row_fr\n",
    "    col_label = [french_pcm]\n",
    "else:\n",
    "    col_label = ['pieces per meter']\n",
    "\n",
    "a_table = mpl.table.table(\n",
    "    cellText=a_sum_table,\n",
    "    rowLabels=rowLabels,\n",
    "    rowColours=['antiquewhite' for i in rowLabels],\n",
    "    colLabels=col_label,\n",
    "    colColours=['antiquewhite' for col in np.arange(1)],\n",
    "    \n",
    "    ax=ax1,\n",
    "    **tablecenter_k)\n",
    "\n",
    "\n",
    "table_format(a_table, ax1) \n",
    "ax1.add_table(a_table )\n",
    "\n",
    "if is_french:\n",
    "    ax1.set_title(F\"{french_key_values}\", loc='left', pad=10)\n",
    "else:\n",
    "    ax1.set_title(F\"key values\", loc='left', pad=10)\n",
    "    \n",
    "\n",
    "ax2 = fig.add_subplot(gs[0:4])\n",
    "sns.scatterplot(data=somdata, x='date',  y='pcs_m', hue='water_name', palette='husl', alpha=1, linewidth=1,s=80, ax=ax2)\n",
    "ax2.xaxis.set_major_formatter(mths_fmt)\n",
    "ax2.xaxis.set_major_locator(allmonths)\n",
    "ax2.set_ylabel(\"Pieces per meter\", **ylab_k)\n",
    "\n",
    "if is_french:\n",
    "    ax2.set_title(F\"Figure {figure_num}: {french_srs} {startyearmonth} - {endyearmonth}, échantillons={len(somdata)}.\", loc='left', pad=10)\n",
    "    ax2.set_ylabel(F\"{french_pcm}\", **ylab_k)\n",
    "    \n",
    "else:\n",
    "    ax2.set_title(F\"Figure {figure_num}: lakes survey totals {startyearmonth} - {endyearmonth}, samples={len(somdata)}.\", loc='left', pad=10)\n",
    "ax2.set_xlabel(\"\")\n",
    "ax2.legend(title=\"Lakes\")\n",
    "\n",
    "\n",
    "\n",
    "fignum = figure_num\n",
    "plt.tight_layout()\n",
    "figname = F\"figure{figure_num}.jpg\"\n",
    "atype='figure'\n",
    "tag =  'lake surveys: scatter plot, key values table'\n",
    "add_output(figname, tag, fignum=fignum, atype=atype)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_french:\n",
    "    sommarkdown = \"\"\"#### <span style=\"color:#008891\"> Les objets les plus communs: les lacs du projet</span>\\n\n",
    "    \"\"\"\n",
    "else:\n",
    "    sommarkdown = \"\"\"#### <span style=\"color:#008891\">Most common objects: project lakes</span>\\n\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(sommarkdown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allcodevals = pd.DataFrame(useThis.groupby('code').quantity.sum())\n",
    "\n",
    "# add description and material from the codes df\n",
    "allcodevals['description'] = allcodevals.index.map(lambda x: dfCodes.loc[x].description)\n",
    "allcodevals['material'] = allcodevals.index.map(lambda x: dfCodes.loc[x].material)\n",
    "allcodevals['group'] = allcodevals.index.map(lambda x: a_group_map[x])\n",
    "\n",
    "# get the total number of objects and the percent of total\n",
    "allcodevalst= allcodevals.quantity.sum()\n",
    "allcodevals['p_total'] = allcodevals.quantity/allcodevalst*100\n",
    "allcodevals['p_total'] = allcodevals['p_total'].round(2)\n",
    "\n",
    "# ptotal = allcodevals['p_total'].sum()\n",
    "\n",
    "# sort the values \n",
    "allcodevals = allcodevals.sort_values(by='quantity',ascending=False)\n",
    "\n",
    "# do some housekeeping\n",
    "allcodevals.rename(columns={'p_total':'% of total'}, inplace=True)\n",
    "allcodevals = allcodevals[['description', 'material', 'quantity', '% of total', 'group']]\n",
    "\n",
    "# format for charting\n",
    "allcodevals.reset_index(inplace=True)\n",
    "allcodevals['quantity'] = allcodevals.quantity.apply(lambda x: \"{:,}\".format(x))\n",
    "\n",
    "# define the most common objects:\n",
    "tabledata = allcodevals[allcodevals['% of total'] >= 2]\n",
    "\n",
    "# sum the % of total of the most common objects\n",
    "ptotal = tabledata['% of total'].sum()\n",
    "\n",
    "# check context\n",
    "if is_french:\n",
    "    tabledatacopy = tabledata.copy()\n",
    "    tabledatacopy['description'] = tabledatacopy.code.map(lambda x: count_k(fr_defs_codes[x], limit))\n",
    "    tabledatacopy['group'] = tabledatacopy.group.map(lambda x: count_k(french_names[x], limit))\n",
    "    tabledatacopy.rename(columns=french_columns, inplace=True)\n",
    "    tabledata = tabledatacopy\n",
    "\n",
    "# make adjustments to table kwargs:\n",
    "tablecenter_k = dict(loc=\"center\", bbox=(0,0,1,1), colWidths=[10,46, 10, 10, 10,15], cellLoc='center')\n",
    "\n",
    "# plot the table:\n",
    "fig, ax = plt.subplots(figsize=(14, len(tabledata)*.75))\n",
    "figure_num += 1\n",
    "ax = make_table_grids(ax)\n",
    "a_table = mpl.table.table(\n",
    "    cellText=tabledata.values,\n",
    "    colLabels=tabledata.columns,\n",
    "    colColours=['antiquewhite' for col in list(tabledata.columns)],    \n",
    "    ax=ax,\n",
    "    **tablecenter_k)\n",
    "\n",
    "table_fonts(a_table, size=12)\n",
    "\n",
    "ax.add_table(a_table)\n",
    "ax.tick_params(**tabtickp_k)\n",
    "\n",
    "# check context\n",
    "\n",
    "if is_french:\n",
    "    ax.set_title(F\"Figure {figure_num}: top {len(tabledata)} codes des lacs du projet, {np.round(ptotal, 2)}% de {'{:,}'.format(allcodevalst)} objets\", **title_k14)\n",
    "    \n",
    "else:\n",
    "    ax.set_title(F\"Figure {figure_num}: top {len(tabledata)} codes project lakes, {np.round(ptotal, 2)}% of {'{:,}'.format(allcodevalst)} objects\", **title_k14)\n",
    "\n",
    "figname = F\"figure{figure_num}.jpg\"\n",
    "fignum=figure_num\n",
    "tag = 'lake surveys: most common objects table'\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "add_output(figname,tag , fignum=fignum)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_french:\n",
    "    sommarkdown = \"\"\"### <span style=\"color:#1e90ff\"> Lacs du projet : objets regroupés par usage ou caractéristiques physiques</span>\\n\n",
    "    \"\"\"\n",
    "else:\n",
    "    sommarkdown = \"\"\"### <span style=\"color:#1e90ff\"> Project lakes: objects grouped by use or physical characteristics</span>\\n\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(sommarkdown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atotal = useThis.quantity.sum()\n",
    "groupoftotal = useThis.groupby('groupname', as_index=False).quantity.sum()\n",
    "groupoftotal['p_total'] = (groupoftotal.quantity/atotal)*100\n",
    "groupoftotal['p_total'] = groupoftotal['p_total'].round(2)\n",
    "groupoftotal.sort_values(by='p_total', ascending=True, inplace=True)\n",
    "anorder = groupoftotal.groupname.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = useThis.groupby(['loc_date', 'date','location','water_name', 'groupname'], as_index=False).pcs_m.sum()\n",
    "get_an_order = boxes.groupby('groupname').pcs_m.median()\n",
    "an_order_of_boxes = get_an_order.sort_values(ascending=True)\n",
    "a_box_order = an_order_of_boxes.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the significant value for each code group\n",
    "sig_vals = boxes.groupby('groupname').pcs_m.quantile(sig)\n",
    "\n",
    "# map the significant value to the results\n",
    "boxes['limit'] = boxes.groupname.map(lambda x: sig_vals[x])\n",
    "\n",
    "# create a boolean for significant\n",
    "boxes['significant'] = boxes.pcs_m >= boxes.limit\n",
    "\n",
    "# map to number of samples, and significant values\n",
    "survey_totals.reset_index(inplace=True)\n",
    "\n",
    "# number of samples per lake\n",
    "tries = survey_totals.groupby(['water_name']).loc_date.nunique()\n",
    "\n",
    "# number of locations per lake\n",
    "num_locations = useThis.groupby('water_name').location.nunique()\n",
    "\n",
    "# fails: number of locations where object group has been identified\n",
    "num_with = useThis[useThis.quantity > 0].groupby(['water_name', 'groupname']).location.nunique()\n",
    "\n",
    "# fails: number of samples with the object group\n",
    "samps_with = useThis[useThis.quantity > 0].groupby(['water_name', 'groupname']).loc_date.nunique()\n",
    "\n",
    "# median pcs_m\n",
    "median_pcs = boxes[boxes.pcs_m >0].groupby(['water_name', 'groupname']).pcs_m.median()\n",
    "\n",
    "# mean pcs_m\n",
    "mean_pcs = boxes[boxes.pcs_m >0].groupby(['water_name', 'groupname']).pcs_m.mean()\n",
    "\n",
    "# significant values\n",
    "# determine wether or not the event was greater than the 90th percentile\n",
    "\n",
    "# map limit to data\n",
    "boxes['limit'] = boxes.groupname.map(lambda x: sig_vals[x])\n",
    "\n",
    "# create boolean\n",
    "boxes['significant'] = boxes.pcs_m >= boxes.limit\n",
    "\n",
    "# make a df of tests and test failures\n",
    "fails = boxes.groupby(['water_name', 'groupname'], as_index=False).significant.sum()\n",
    "\n",
    "# get the number of samples for the lake\n",
    "fails['samples'] = fails.water_name.map(lambda x: tries[x])\n",
    "\n",
    "# display the ratio of significant values to samples\n",
    "fails['frequency_s'] = fails.significant.astype('str') + '/' + fails.samples.astype('str')\n",
    "\n",
    "# the number of locations\n",
    "fails['locations'] = fails.water_name.map(lambda x: num_locations[x])\n",
    "\n",
    "def locations_with(x,y,somdata):\n",
    "    try:\n",
    "        has = somdata[x][y]        \n",
    "    except:\n",
    "        has = 0\n",
    "    return has\n",
    "        \n",
    "# the number of locations where the object group has been identified\n",
    "fails['loc_with'] = fails.apply(lambda x:locations_with(x['water_name'], x['groupname'], num_with), axis=1)\n",
    "\n",
    "# the number of samples where the object group has been identified\n",
    "fails['samp_with'] = fails.apply(lambda x:locations_with(x['water_name'], x['groupname'], samps_with), axis=1)\n",
    "\n",
    "# samples frequency of failure\n",
    "fails['frequency'] = fails.samp_with.astype('str') + '/' + fails.samples.astype('str')\n",
    "\n",
    "# locations frequency of failure\n",
    "fails['frequency_l'] = fails.loc_with.astype('str') + '/' + fails.locations.astype('str')\n",
    "\n",
    "# median/mean pcs_m:\n",
    "fails['median pcs/m'] = fails.apply(lambda x:locations_with(x['water_name'], x['groupname'], median_pcs), axis=1)\n",
    "fails['mean pcs/m'] = fails.apply(lambda x:locations_with(x['water_name'], x['groupname'], mean_pcs), axis=1)\n",
    "\n",
    "# likelihood\n",
    "fails['likelihood'] = ((fails.loc_with/fails.locations)*(fails.samp_with/fails.samples))*100\n",
    "fails['likelihood'] = fails.likelihood.astype('int')\n",
    "\n",
    "table_data = fails[['water_name','frequency_l', 'frequency',  'frequency_s', 'likelihood','median pcs/m', 'groupname']].copy()\n",
    "table_data.rename(columns={'water_name':'name', 'frequency_l':\"# locations\", 'frequency':\"# samples\", 'frequency_s':'# significant'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "markers = ['s', 'P', 'D', 'X', 'o']\n",
    "def make_ecdf(somdata, numsamps):\n",
    "    vals = somdata.pcs_m.sort_values()\n",
    "    valsy = [i/numsamps for i in np.arange(numsamps)]\n",
    "    return vals, valsy\n",
    "a_form = mtick.FormatStrFormatter('%.0f%%')\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(11, 7))\n",
    "figure_num += 1\n",
    "if is_french:\n",
    "    groupoftotal['groupname'] = groupoftotal['groupname'].map(lambda x: french_names[x])\n",
    "    groupdconcat['groupname'] = groupdconcat['groupname'].map(lambda x: french_names[x])\n",
    "    anorder = [french_names[x] for x in a_box_order]\n",
    "\n",
    "    sns.barplot(data=groupoftotal, x='groupname', hue='groupname', palette=frpalette, y='p_total', dodge=False, ax=ax[0])\n",
    "    ax[0].set_ylabel(F\"{french_pct}\", labelpad=10)\n",
    "    ax[0].set_title(F\"Figure {figure_num}: {french_bg} % {of_prep} {'{:,}'.format(atotal)} {thing}\", **title_k)\n",
    "    ax[0].set_xlabel(\"\")\n",
    "    ax[0].set_xticklabels(\"\")\n",
    "    ax[0].legend(loc='upper left')    \n",
    "    \n",
    "    sns.boxplot(data=useThis[['groupname','pca_m']], x='groupname', y='pcs_m', hue='groupname', order=anorder, palette=frpalette, dodge=False, ax=ax[1],  showfliers=False)\n",
    "    ax[1].set_ylabel(F\"{french_pcm}\", labelpad=10)\n",
    "    ax[1].set_title(F\"distribution {french_bg}*\", **titler_k)\n",
    "    ax[1].set_xlabel(F\"{french_nooutliers}\")\n",
    "    ax[1].get_legend().remove()\n",
    "    ax[1].set_xticklabels(\"\")\n",
    "    \n",
    "\n",
    "else:\n",
    "    sns.barplot(data=groupoftotal, x='groupname', hue='groupname', palette=grouppalette, y='p_total', dodge=False, ax=ax[0])\n",
    "    ax[0].set_ylabel(\"Percent total of all objects\", labelpad=10)\n",
    "    ax[0].set_title(F\"Figure {figure_num}: code groups as a % of {'{:,}'.format(atotal)} objects\", **title_k)\n",
    "    ax[0].yaxis.set_major_formatter(a_form)\n",
    "    ax[0].set_xlabel(\"\")\n",
    "    ax[0].set_xticklabels(\"\")\n",
    "    ax[0].legend(loc='upper left')    \n",
    "    \n",
    "    sns.boxplot(data=boxes[['groupname','pcs_m']], x='groupname', y='pcs_m', hue='groupname', palette=grouppalette, order=a_box_order, dodge=False, ax=ax[1], showfliers=False)\n",
    "    ax[1].set_ylabel(\"Pieces per meter\", labelpad=10)\n",
    "    ax[1].set_title(F\"disribution of groups*\", **titler_k)\n",
    "    ax[1].set_xlabel(\"*outliers not shown\")\n",
    "    ax[1].get_legend().remove()\n",
    "    ax[1].set_xticklabels(\"\")\n",
    "    \n",
    "fignum=figure_num\n",
    "    \n",
    "plt.tight_layout()\n",
    "figname = F\"figure{fignum}.jpg\"\n",
    "atype='figure'\n",
    "tag = 'code groups: percentage of total, distribution'\n",
    "add_output(figname, tag, fignum=fignum, atype=atype)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context\n",
    "# the group names need to be in the appropriate language\n",
    "if is_french:\n",
    "    sigheat['groupname'] = sigheat.groupname.map(lambda x: french_names[x])\n",
    "    sigdf['groupname'] = sigdf.groupname.map(lambda x: french_names[x])\n",
    "\n",
    "    \n",
    "heat_map_palette = 'flare'\n",
    "linecolor = 'white'\n",
    "\n",
    "fig,axx = plt.subplots(1,2, figsize=(16,10))\n",
    "figure_num += 1\n",
    "\n",
    "sns.heatmap(\n",
    "    fails[['water_name', 'groupname', 'likelihood']].pivot(columns='water_name', index='groupname'),\n",
    "    cmap=heat_map_palette, \n",
    "    ax=axx[0],\n",
    "    square=True,\n",
    "    cbar_kws={\"shrink\": .9},\n",
    "    annot=True, fmt=\" \",\n",
    "    linewidths=.5,\n",
    "    linecolor=linecolor\n",
    ")\n",
    "\n",
    "labels = [a_text.get_text() for a_text in axx[0].get_xticklabels()]\n",
    "newlabels = []\n",
    "\n",
    "# make new labels\n",
    "for i, a_text in enumerate(labels):\n",
    "    oldlabel = a_text\n",
    "    newlabel = oldlabel[len('likelihood')+1:]\n",
    "    newlabels.append(newlabel)\n",
    "\n",
    "sns.heatmap(fails[['water_name', 'groupname', 'mean pcs/m']].pivot(columns='water_name', index='groupname'), cmap=heat_map_palette, ax=axx[1], square=True, cbar_kws={\"shrink\": .9}, annot=True, annot_kws={'fontsize':12},linewidths=.1, linecolor=linecolor)\n",
    "\n",
    "# set parameters\n",
    "for anax in axx:\n",
    "    anax.set_xticklabels(newlabels, fontsize=12)\n",
    "    anax.set_ylabel(\" \")\n",
    "    anax.set_xlabel(\" \")\n",
    "    anax.tick_params(axis='both', labelsize=12)\n",
    "\n",
    "if is_french:\n",
    "    axx[0].set_title(F\"groupe de codes probabilité de trouver au moins une\", **title_k14)\n",
    "    axx[1].set_title(F\"la valeur moyenne de déchets par mètre\", **title_k14)\n",
    "    plt.suptitle(F\"Figure {figure_num}: tous les lacs, pourcentage des échantillons > 90%, la valeur médiane de déchets par mètre\", ha='left', size=14, x=0.06, y=1)\n",
    "else:\n",
    "    axx[0].set_title(F\"code group: likelihood of finding at least one\", **title_k14)\n",
    "    axx[1].set_title(F\"code group: average pieces of trash per meter\", **title_k14)\n",
    "    plt.suptitle(F\"Figure {figure_num}: summary code groups as % of total, median pieces per meter\", ha='left', size=14, x=0.04, y=1)\n",
    "    \n",
    "plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)\n",
    "\n",
    "atype=\"figure\"\n",
    "figname = F\"figure{figure_num}.jpg\"\n",
    "tag = F\"likelihood of finding one object from a group and median pcs/m\"\n",
    "add_output(figname,tag, fignum=figure_num, atype=atype)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# map number of sample per locations\n",
    "tries_l = boxes.groupby('location').loc_date.nunique()\n",
    "\n",
    "# map number of times at least one item was found\n",
    "fails_l = boxes[boxes.pcs_m > 0].groupby(['location', 'groupname']).loc_date.nunique()\n",
    "lake_l = fails.set_index(['groupname','water_name'])\n",
    "lake_l = lake_l['likelihood']\n",
    "\n",
    "fails_beach = boxes.groupby(['location', 'water_name','groupname'], as_index=False).pcs_m.median()\n",
    "fails_beach['tries'] = fails_beach.location.map(lambda x: tries_l[x])\n",
    "fails_beach['fails'] = fails_beach.apply(lambda x:locations_with(x['location'], x['groupname'], fails_l), axis=1)\n",
    "fails_beach['loclikelihood'] = (fails_beach.fails/fails_beach.tries) * 100\n",
    "fails_beach['loclikelihood'] = fails_beach['loclikelihood'].astype('int')\n",
    "fails_beach['lakelikelihood'] = fails_beach.apply(lambda x:locations_with(x['groupname'], x['water_name'], lake_l), axis=1)\n",
    "fails_beach['likelihood'] = (fails_beach.loclikelihood*fails_beach.lakelikelihood)/100\n",
    "fails_beach['likelihood'] = fails_beach['likelihood'].astype('int')\n",
    "\n",
    "a = boxes.groupby('location').significant.sum()\n",
    "these_beaches['significant'] = these_beaches.index.map(lambda x: a.loc[x])\n",
    "these_beaches.to_csv(F\"{project_directory}/these_beaches.csv\")\n",
    "these_rivers = dfSurveys[(dfSurveys.date >= start_date)]['location'].unique()\n",
    "river_beaches = dfBeaches.loc[(dfBeaches.index.isin(these_rivers))&(dfBeaches.water == 'r')]\n",
    "river_beaches.to_csv(F\"{project_directory}/these_rivers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fig,axx = plt.subplots(figsize=(18,18))\n",
    "figure_num += 1\n",
    "\n",
    "this_data=fails_beach[fails_beach.water_name == lake].copy()\n",
    "\n",
    "sns.heatmap(\n",
    "    this_data[['location', 'groupname', 'likelihood']].pivot(columns='location', index='groupname'), \n",
    "    cmap=heat_map_palette,\n",
    "    linecolor=linecolor,\n",
    "    ax=axx, \n",
    "    square=True, \n",
    "    annot=True,\n",
    "    cbar_kws={\"shrink\": .38}, \n",
    "    annot_kws={'fontsize':12}, \n",
    "    linewidths=.5,\n",
    "    fmt=\" \",\n",
    ")\n",
    "labels = [a_text.get_text() for a_text in axx.get_xticklabels()]\n",
    "newlabels = []\n",
    "for i, a_text in enumerate(labels):\n",
    "    oldlabel = a_text\n",
    "    newlabel = oldlabel[len('likelihood')+1:]\n",
    "    newlabels.append(newlabel)\n",
    "\n",
    "axx.set_xticklabels(newlabels)\n",
    "\n",
    "axx.set_ylabel(\" \")\n",
    "axx.set_xlabel(\" \")\n",
    "axx.tick_params(axis='both', labelsize=12)\n",
    "\n",
    "if is_french:\n",
    "    axx.set_title(F\"code group: likelihood of finding at least one\", **title_k14)\n",
    "else:\n",
    "    axx.set_title(F\"code group: likelihood of finding at least one\", **title_k14)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "atype=\"figure\"\n",
    "figname = F\"figure{figure_num}.jpg\"\n",
    "tag = F\"{lake} code groups percent of total by location.\"\n",
    "add_output(figname,tag, fignum=figure_num, atype=atype)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fig,axx = plt.subplots(figsize=(18,18))\n",
    "figure_num += 1\n",
    "\n",
    "sns.heatmap(this_data[['location', 'groupname', 'pcs_m']].pivot(columns='location', index='groupname'),\n",
    "            cmap=heat_map_palette, ax=axx, square=True, annot=True,cbar_kws={\"shrink\": .38}, annot_kws={'fontsize':12}, linewidths=.5, linecolor=linecolor)\n",
    "labels = [a_text.get_text() for a_text in axx.get_xticklabels()]\n",
    "newlabels = []\n",
    "for i, a_text in enumerate(labels):\n",
    "    oldlabel = a_text\n",
    "    newlabel = oldlabel[6:]\n",
    "    newlabels.append(newlabel)\n",
    "axx.set_xticklabels(newlabels, fontsize=12)\n",
    "axx.set_ylabel(\" \")\n",
    "axx.set_xlabel(\" \")\n",
    "axx.tick_params(axis='both', labelsize=12)\n",
    "\n",
    "if is_french:\n",
    "    axx.set_title(F\"Figure {figure_num}: {lake} la valeur médiane de déchets par mètre.\", **title_k14)\n",
    "else:\n",
    "    axx.set_title(F\"Figure {figure_num}: {lake} median pieces of trash per meter.\", **title_k14)\n",
    "    \n",
    "plt.tight_layout()\n",
    "atype=\"figure\"\n",
    "figname = F\"figure{figure_num}.jpg\"\n",
    "tag = F\"{lake} all locations median pcs/m\"\n",
    "add_output(figname,tag, fignum=figure_num, atype=atype)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "boxes.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "monthly = pd.DataFrame(boxes.groupby('groupname').resample('M').pcs_m.median())\n",
    "monthly['change'] = monthly.pcs_m.diff().round(4)\n",
    "monthly.fillna(0, inplace=True)\n",
    "monthly.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "french_columns = {'code':'code','description': 'description', 'material':'matériel', 'quantity':'quantité'}\n",
    "thing = 'objets'\n",
    "parent = \"de l'ensemble\"\n",
    "french_pcm = \"pièces par mètre\"\n",
    "french_srs = \"résultats des recensements\"\n",
    "french_pcg = \"par groupe de codes\"\n",
    "french_med = \"médian\"\n",
    "french_mm = \"médiane mensuelle\"\n",
    "french_change = 'changement'\n",
    "\n",
    "fig, axs = plt.subplots(3,1,figsize=(14,16))\n",
    "figure_num +=1\n",
    "\n",
    "# plots\n",
    "sns.scatterplot(data=boxes, x='date',  y='pcs_m', hue='groupname', palette=grouppalette, alpha=0.8,s=60, ax=axs[0])\n",
    "sns.lineplot(data=monthly, x='date', y='pcs_m', hue='groupname', palette=grouppalette, ax=axs[1])\n",
    "sns.lineplot(data=monthly, x='date',  y='change',  hue='groupname', palette=grouppalette, linewidth=2, ax=axs[2])\n",
    "\n",
    "if is_french:    \n",
    "    # titles\n",
    "    axs[0].set_title(F\"Figure {figure_num}:{french_srs} {french_pcg}, {startyearmonth} - {endyearmonth}, n={len(boxes)}\", **title_k)    \n",
    "    axs[1].set_title(F\"{french_mm} {french_srs}, {startyearmonth} - {endyearmonth}, n={len(boxes)}\", **title_k)    \n",
    "    axs[2].set_title(F\"changement {french_mm} pcs/m, n={len(boxes)}\", **title_k)\n",
    "    \n",
    "    # labels\n",
    "    axs[0].set_ylabel(french_pcm, **ylab_k)\n",
    "    axs[1].set_ylabel(french_pcm, **ylab_k)\n",
    "    axs[2].set_ylabel(F\"{french_change}\", **ylab_k)\n",
    "else:\n",
    "    # titles\n",
    "    axs[0].set_title(F\"Figure {figure_num}: survey results by code group, {startyearmonth} - {endyearmonth}, n={len(boxes)}\", **title_k)\n",
    "    axs[1].set_title(F\"median monthly results, {startyearmonth} - {endyearmonth}, n={len(boxes)}\", **title_k)\n",
    "    axs[2].set_title(F\"monthly change pcs/m, n={len(boxes)}\", **title_k)    \n",
    "    \n",
    "    # labels\n",
    "    axs[0].set_ylabel(\"pieces per meter\", **ylab_k)\n",
    "    axs[1].set_ylabel(\"pieces per meter\", **ylab_k)\n",
    "    axs[2].set_ylabel(\"Change pieces per meter\", **ylab_k)\n",
    "    \n",
    "    \n",
    "for anax in axs:\n",
    "    # set axs parameters\n",
    "    anax.xaxis.set_minor_locator(weeks)\n",
    "    anax.xaxis.set_major_formatter(mths_fmt)\n",
    "    anax.xaxis.set_major_locator(months)\n",
    "    anax.tick_params(which='major', pad=10)\n",
    "    anax.set_xlabel(\"\")\n",
    "    labels, handles = anax.get_legend_handles_labels()\n",
    "    anax.legend(labels, handles, bbox_to_anchor=(1, 1),loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "figname = F\"figure{figure_num}.jpg\"\n",
    "tag = F\"code group survey results, montlhy median and change\"\n",
    "atype='figure'\n",
    "add_output(figname, tag, fignum=figure_num, atype=atype)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if is_french:\n",
    "    sommarkdown = \"\"\"#### <span style=\"color:#008891\">Commentaire groupe d'objets</span>\n",
    "    Les restes représente la plus grande proportion des objets trouvés. Cela illustre l'importance du transport fluvial et les difficultés liées à la détermination de la source géographique exacte de la plupart des objets.\n",
    "\n",
    "    Lorsqu'ils sont combinés, les groupes de l'agriculture, de la construction et l'agriculture ou de construction et agriculture représentent ~26%, soit à peu près le même que celui des kiosques.\n",
    "    \n",
    "    Le groupe des microplastiques représente ~ 8% du total. Il faut tenir compte du fait que ces objets, par définition, sont difficiles à voir et qu'ils sont donc certainement sous-représentés dans ces chiffres.    \n",
    "    \"\"\"\n",
    "else:\n",
    "    sommarkdown = \"\"\"#### <span style=\"color:#008891\">Comments object groups</span>\n",
    "\n",
    "    The rest represents the biggest proportion of the objects found. This illustrates the importance of fluvial transport and the difficulties associated with determining the exact geographic source of most objects.\n",
    "    \n",
    "    When combined, the groups of aggriculture, construction and agg or construction are ~26% or about the same as the kiosk group.\n",
    "    \n",
    "    The microplastic group is ~ 8% of the total. These objects, by definition, are difficult to see and therfore are certainly under represented in these counts.\n",
    "    \"\"\" \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#1e90ff\"> Group components</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "is_french = False\n",
    "# creating tables for each code group\n",
    "# each table is saved in jpeg\n",
    "\n",
    "\n",
    "# context:\n",
    "french_columns = {'code':'code','description': 'description', 'material':'matériel', 'quantity':'quantité'}\n",
    "thing = 'objets'\n",
    "parent = \"de l'ensemble\"\n",
    "\n",
    "# define the summary table for each code group\n",
    "groupTotals = {}\n",
    "for name in group_names:\n",
    "    \n",
    "    somdata = useThis[useThis.groupname == name ].copy()\n",
    "    somdata = somdata[somdata.quantity > 0]\n",
    "    newdata = somdata.groupby('code').agg({'quantity':'sum', 'pcs_m':'mean'})\n",
    "    somdatatot = somdata.quantity.sum()\n",
    "    newdata['% of group']=np.round((newdata.quantity/somdatatot)*100, 1)\n",
    "    # check context\n",
    "    if is_french:\n",
    "        newdata['description'] = newdata.index.map(lambda x: count_k(fr_defs_codes[x], limit))\n",
    "    else:\n",
    "        # do it in english\n",
    "        newdata['description'] = newdata.index.map(lambda x: count_k(dfCodes.loc[x].description, limit))\n",
    "        \n",
    "    newdata['material'] = newdata.index.map(lambda x: dfCodes.loc[x].material)\n",
    "    newdata.reset_index(inplace=True)\n",
    "    \n",
    "    newdata.drop('pcs_m', axis=1, inplace=True)\n",
    "    newdata = newdata[['code','description', 'material', 'quantity', '% of group']]\n",
    "    newdata.sort_values(by='% of group', ascending=False, inplace=True)\n",
    "    groupTotals.update({name:newdata})\n",
    "\n",
    "\n",
    "tablecenter_k = dict(loc=\"center\", bbox=(0,0,1,1), colWidths=[10,52, 13, 13, 13], cellLoc='center')\n",
    "a_total = newdfx.quantity.sum()\n",
    "\n",
    "for i,name in enumerate(group_names):\n",
    "    # make the data\n",
    "    somdata = groupTotals[name]\n",
    "    \n",
    "    # get the number of records\n",
    "    somnums = np.arange(len(somdata))\n",
    "    \n",
    "    # get the total for the group\n",
    "    group_total = somdata.quantity.sum()\n",
    "    \n",
    "    # check context before exporting:\n",
    "    if is_french:\n",
    "        # makes the column headers to desired language:\n",
    "        somdata.rename(columns=french_columns, inplace=True)\n",
    "    \n",
    "    # make the figure\n",
    "    fig, axs = plt.subplots(figsize=(12, len(somdata)*.75))\n",
    "    # keep track\n",
    "    figure_num += 1\n",
    "    \n",
    "    # define table\n",
    "    a_table = mpl.table.table(\n",
    "        cellText=somdata.values,\n",
    "        colLabels=list(somdata.columns),\n",
    "        colColours=['antiquewhite' for i in list(somdata.columns)],\n",
    "        \n",
    "        ax=axs,\n",
    "        **tablecenter_k)\n",
    "    \n",
    "    # add table to figure and set parameters\n",
    "    axs.add_table(a_table)\n",
    "    table_fonts(a_table, size=12)\n",
    "    make_table_grids(axs)\n",
    "    axs.tick_params(**tabtickp_k)    \n",
    "    \n",
    "    # check context, the name is used to iterate so:    \n",
    "    if is_french:\n",
    "        axs.set_title(F\"Figure {figure_num}: {french_names[name]} {'{:,}'.format(group_total)} {thing}, {np.round((group_total/a_total)*100, 2)}% {parent}.\", **titler_k)\n",
    "    else:\n",
    "        # do it in english\n",
    "        axs.set_title(F\"Figure {figure_num}: {name} {'{:,}'.format(group_total)} items, {np.round((group_total/a_total)*100, 2)}% of all objects.\", **titler_k)\n",
    "    # tag and save\n",
    "    figname = F\"figure{figure_num}.jpg\"\n",
    "    tag = F\"{name} component codes\"\n",
    "    \n",
    "    add_output(figname, tag, fignum=figure_num)\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "is_french = False\n",
    "if is_french:\n",
    "    sommarkdown = \"\"\"### <span style=\"color:#1e90ff\">Résultats par groupe de codes</span>\\n#### <span style=\"color:#008891\">résultats mensuels médians</span>\\n\n",
    "    \"\"\"\n",
    "\n",
    "else:\n",
    "    sommarkdown = \"\"\"### <span style=\"color:#1e90ff\">Survey results per code group</span>\\n#### <span style=\"color:#008891\">Median monthly survey results</span>\\n\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "display(Markdown(sommarkdown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if is_french:\n",
    "    sommarkdown = \"\"\"#### <span style=\"color:#008891\">Valeurs clés par groupe de code</span>\n",
    "    \"\"\"\n",
    "else:    \n",
    "    sommarkdown = \"\"\"#### <span style=\"color:#008891\">Key values per code group</span>\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "display(Markdown(sommarkdown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# aggregate the survey totals by group\n",
    "somdata = boxes.groupby('groupname').pcs_m.describe()\n",
    "somdata.reset_index(inplace=True)\n",
    "somcols = {'groupname':'group'}\n",
    "somdata.rename(columns=somcols, inplace=True)\n",
    "# somdata.columns = somdata.columns.get_level_values(1)\n",
    "thisdata = somdata[['group', 'max','75%', '50%', '25%', 'min', 'mean', 'std']].round(2).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# context:\n",
    "if is_french:\n",
    "    thisdata.rename(columns={'group':'groupe', 'mean':'moyenne', 'std':'et'}, inplace=True)   \n",
    "    thisdata['group'] = thisdata.group.map(lambda x: french_names[x])\n",
    "\n",
    "# display and print\n",
    "col_widths = [16,12,12,12,12,12,12,12 ]\n",
    "tablecenter_k = dict(loc=\"top left\", bbox=(0,0,1,1), colWidths=col_widths, cellLoc='center')\n",
    "\n",
    "# a table\n",
    "fig, axs = plt.subplots(figsize=(18,len(thisdata)))\n",
    "# keeping count\n",
    "figure_num += 1\n",
    "\n",
    "# define the table\n",
    "a_table = mpl.table.table(\n",
    "    cellText=thisdata.values,\n",
    "    colLabels=thisdata.columns,\n",
    "    colColours=['antiquewhite' for i in thisdata.columns],\n",
    "    ax=axs,\n",
    "    **tablecenter_k)\n",
    "\n",
    "# set axs parameters\n",
    "make_table_grids(axs)\n",
    "table_fonts(a_table, size=14)\n",
    "axs.add_table(a_table )\n",
    "axs.tick_params(**tabtickp_k)\n",
    "\n",
    "# context\n",
    "if is_french:\n",
    "    axs.set_title(F\"Figure {figure_num}: groupes de codes {french_key_values} {startyearmonth} - {endyearmonth}, n={len(survey_totals)} \", **title_k)\n",
    "else:\n",
    "    axs.set_title(F\"Figure {figure_num}: code groups key values {startyearmonth} - {endyearmonth}, n={len(survey_totals)}\", **title_k)\n",
    "\n",
    "# tag the image\n",
    "figname = F\"figure{figure_num}.jpg\"\n",
    "fignum = figure_num\n",
    "tag = F\"code groups key values\"\n",
    "\n",
    "# draw it\n",
    "plt.tight_layout()\n",
    "\n",
    "# save it\n",
    "add_output(figname, tag, fignum=fignum)\n",
    "\n",
    "plt.box(on=None)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#1e90ff\"> Project lakes: significant events by code group and lake</span>\n",
    "\n",
    "**Definition of significant event**: a significant event is defined as a survey result that exceeds the 90th percentile of all surveys for that code group. In this report the 90th percentile is considered for all surveys in the project lakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "boxes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # get the significant value for each code group\n",
    "# sig_vals = boxes.groupby('groupname').pcs_m.quantile(sig)\n",
    "\n",
    "# # map the significant value to the results\n",
    "# boxes['limit'] = boxes.groupname.map(lambda x: sig_vals[x])\n",
    "\n",
    "# # create a boolean for significant\n",
    "# boxes['significant'] = boxes.pcs_m >= boxes.limit\n",
    "\n",
    "# # map to number of samples, and significant values\n",
    "# survey_totals.reset_index(inplace=True)\n",
    "\n",
    "# # number of samples per lake\n",
    "# tries = survey_totals.groupby(['water_name']).loc_date.nunique()\n",
    "\n",
    "# # number of locations per lake\n",
    "# num_locations = useThis.groupby('water_name').location.nunique()\n",
    "\n",
    "# # fails: number of locations where object group has been identified\n",
    "# num_with = useThis[useThis.quantity > 0].groupby(['water_name', 'groupname']).location.nunique()\n",
    "\n",
    "# # fails: number of samples with the object group\n",
    "# samps_with = useThis[useThis.quantity > 0].groupby(['water_name', 'groupname']).loc_date.nunique()\n",
    "\n",
    "# # median pcs_m\n",
    "# median_pcs = boxes[boxes.pcs_m >0].groupby(['water_name', 'groupname']).pcs_m.median()\n",
    "\n",
    "# # mean pcs_m\n",
    "# mean_pcs = boxes[boxes.pcs_m >0].groupby(['water_name', 'groupname']).pcs_m.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # significant values\n",
    "# # determine wether or not the event was greater than the 90th percentile\n",
    "\n",
    "# # map limit to data\n",
    "# boxes['limit'] = boxes.groupname.map(lambda x: sig_vals[x])\n",
    "\n",
    "# # create boolean\n",
    "# boxes['significant'] = boxes.pcs_m >= boxes.limit\n",
    "\n",
    "# # find the test failures\n",
    "# fails = boxes.groupby(['water_name', 'groupname'], as_index=False).significant.sum()\n",
    "\n",
    "# # get the number of samples for the lake\n",
    "# fails['samples'] = fails.water_name.map(lambda x: tries[x])\n",
    "\n",
    "# # display the ratio of significant values to samples\n",
    "# fails['frequency_s'] = fails.significant.astype('str') + '/' + fails.samples.astype('str')\n",
    "\n",
    "# # the number of locations\n",
    "# fails['locations'] = fails.water_name.map(lambda x: num_locations[x])\n",
    "\n",
    "# def locations_with(x,y,somdata):\n",
    "#     try:\n",
    "#         has = somdata[x][y]        \n",
    "#     except:\n",
    "#         has = 0\n",
    "#     return has\n",
    "        \n",
    "# # the number of locations where the object group has been identified\n",
    "# fails['loc_with'] = fails.apply(lambda x:locations_with(x['water_name'], x['groupname'], num_with), axis=1)\n",
    "\n",
    "# # the number of samples where the object group has been identified\n",
    "# fails['samp_with'] = fails.apply(lambda x:locations_with(x['water_name'], x['groupname'], samps_with), axis=1)\n",
    "\n",
    "# # samples frequncy of failure\n",
    "# fails['frequency'] = fails.samp_with.astype('str') + '/' + fails.samples.astype('str')\n",
    "\n",
    "# # locations frequncy of failure\n",
    "# fails['frequency_l'] = fails.loc_with.astype('str') + '/' + fails.locations.astype('str')\n",
    "\n",
    "# # median/mean pcs_m:\n",
    "# fails['median pcs/m'] = fails.apply(lambda x:locations_with(x['water_name'], x['groupname'], median_pcs), axis=1)\n",
    "# fails['mean pcs/m'] = fails.apply(lambda x:locations_with(x['water_name'], x['groupname'], mean_pcs), axis=1)\n",
    "\n",
    "# # likelihood\n",
    "# fails['likelihood'] = ((fails.loc_with/fails.locations)*(fails.samp_with/fails.samples))*100\n",
    "# fails['likelihood'] = fails.likelihood.astype('int')\n",
    "\n",
    "# table_data = fails[['water_name','frequency_l', 'frequency',  'frequency_s', 'likelihood','median pcs/m', 'groupname']].copy()\n",
    "# table_data.rename(columns={'water_name':'name', 'frequency_l':\"# locations\", 'frequency':\"# samples\", 'frequency_s':'# significant'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "somcols = {'lake':'lac',\n",
    "           '# locations':'# sites',\n",
    "           '# with':'# avec',\n",
    "           '# samples':'# échantillon',\n",
    "           '# samps with':'# avec',\n",
    "           'median pcs/m':'médian pcs/m',\n",
    "           'mean pcs/m':'moyenne pcs/m', \n",
    "           '% of daily total':'% de total'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# adjust table args\n",
    "tablecenter_k = dict(loc=\"top left\", bbox=(0,0,1,1), cellLoc='center', fontsize=12, colWidths = [0.4, 0.3, 0.3])\n",
    "tablecenter_kx = dict(loc=\"top left\", bbox=(0,0,1,1), cellLoc='center',colWidths = [0.16, 0.16, 0.16, 0.16, 0.16], fontsize=12)\n",
    "\n",
    "# make a figure for eac code group\n",
    "for i,name in enumerate(group_names):\n",
    "    \n",
    "    # events table:\n",
    "    event_data = fails[fails.groupname == name][['water_name', 'significant','frequency_s']].copy()\n",
    "    \n",
    "    # context    \n",
    "    if is_french:\n",
    "        event_data = event_data.rename(columns={'lake':'lac', '# significant':'# significatif', 'frequency':'fréquence'})        \n",
    "        \n",
    "    # there is a mix of blank and active grids switch off the grid for the figure\n",
    "    with sns.axes_style('white', {'xtick.color':'white', 'ytick.color':'white'}):        \n",
    "        fig, axs = plt.subplots(figsize=(12,12), frameon=False)\n",
    "        figure_num += 1\n",
    "        sns.despine(fig=fig, top=True, left=True, right=True, bottom=True)\n",
    "\n",
    "    # declare the grid\n",
    "    gs = GridSpec(2, 2, figure=fig)\n",
    "    \n",
    "    # add ax to grid\n",
    "    ax1 = fig.add_subplot(gs[0,0])\n",
    "    \n",
    "    # apply formatting before putting in table\n",
    "    make_table_grids(ax1)\n",
    "\n",
    "    # define table\n",
    "    a_table = mpl.table.table(\n",
    "        cellText=event_data[event_data.significant > 0].values,\n",
    "        colLabels=event_data.columns,\n",
    "        colColours=['antiquewhite' for col in event_data.columns],\n",
    "        ax=ax1,\n",
    "        **tablecenter_k)\n",
    "    \n",
    "    # add table to ax\n",
    "    ax1.add_table(a_table)\n",
    "    \n",
    "    # set remaining parameters\n",
    "    table_fonts(a_table)\n",
    "    ax1.tick_params(**tabtickp_k)\n",
    "    the90th = sig_vals[name]\n",
    "    \n",
    "    # add the dist chart\n",
    "    ax2 = fig.add_subplot(gs[0,1])\n",
    "    with sns.axes_style('whitegrid',{'xtick.color':'black', 'ytick.color':'black'}):\n",
    "        ax2 = sns.scatterplot(data=boxes[boxes.groupname == name],\n",
    "                              x='water_name',\n",
    "                              y='pcs_m',\n",
    "                              hue='water_name',\n",
    "                              style='significant',\n",
    "                              s=120, \n",
    "                              palette='husl',\n",
    "                              markers={True:'X', False:'s'}, ax=ax2)\n",
    "        # set axis parameters\n",
    "        ax2.xaxis.set_tick_params(rotation=45)        \n",
    "        for tick in ax2.xaxis.get_majorticklabels():\n",
    "            tick.set_horizontalalignment(\"right\")        \n",
    "        ax2.set_xlabel(\"\")\n",
    "        \n",
    "        # context\n",
    "        if is_french:\n",
    "            ax1.set_title(F\"fréquence\", **title_k)\n",
    "            ax2.set_ylabel(F\"{french_pcm}\", **ylab_k)\n",
    "            handles, labels = ax2.get_legend_handles_labels()\n",
    "            ax2.legend(handles, labels)\n",
    "            ax2.set_title(F\"distribution des résultats\", **titler_k)\n",
    "        else:\n",
    "            ax1.set_title(F\"frequency\", **title_k)\n",
    "            ax2.set_ylabel(\"pieces per meter\", **ylab_k)\n",
    "            handles, labels = ax2.get_legend_handles_labels()\n",
    "            ax2.legend(handles, labels)\n",
    "            ax2.set_title(F\"distribution of results\", **titler_k)\n",
    "            \n",
    "        \n",
    "    # add key values table\n",
    "    ax3 = fig.add_subplot(gs[1, 0:])\n",
    "    \n",
    "    # format the table data\n",
    "    this_data = table_data[table_data.groupname == name]\n",
    "    this_data= this_data[['name', \"# locations\", \"# samples\", '# significant', 'likelihood']]\n",
    "    \n",
    "    # context\n",
    "    if is_french:\n",
    "        these_labels = [somcols[x] for x in list(this_data.columns)]\n",
    "    else:\n",
    "        these_labels = list(this_data.columns)\n",
    "    \n",
    "    # add table\n",
    "    a_table = mpl.table.table(cellText=this_data.values, colLabels= these_labels,colColours=['antiquewhite' for col in these_labels], ax=ax3, **tablecenter_kx)\n",
    "    ax3.add_table(a_table)\n",
    "    \n",
    "    # table parameters\n",
    "    make_table_grids(ax3)\n",
    "    table_fonts(a_table)\n",
    "    ax3.tick_params(**tabtickp_k)\n",
    "    \n",
    "    # context\n",
    "    if is_french:\n",
    "        ax3.set_title(F\"{french_sum_names[name]}: valeurs clés\", **title_k)\n",
    "        plt.suptitle(F\"Figure {figure_num}: événements significatifs {french_sum_names[name]}, 90%= {np.round(the90th, 3)}\", ha='left', size=14, x=0.04, y=0.99)\n",
    "    else:\n",
    "        ax3.set_title(F\"{name}: key values\", **title_k)\n",
    "        plt.suptitle(F\"Figure {figure_num}: Significant events {name} , 90%= {np.round(the90th, 3)}\", ha='left', size=14, x=0.04, y=0.99)\n",
    "    \n",
    "    # tag the output\n",
    "    figname=F\"figure{figure_num}.jpg\"\n",
    "    tag = F\"{name} significant events\"\n",
    "    atype='figure'\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # save the figure\n",
    "    add_output(figname, tag, fignum=figure_num, atype=atype)\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# a grid that dispalys the significant results per code group and location\n",
    "\n",
    "# define the number of rows\n",
    "locs=len(group_names)\n",
    "rows = math.ceil(locs/3)\n",
    "cols=3\n",
    "\n",
    "# add space for the legend\n",
    "if rows > locs/3:\n",
    "    rows = rows\n",
    "else:\n",
    "    rows +=1\n",
    "\n",
    "# clear the figure grid\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "fig, axs = plt.subplots(rows,cols, figsize=(18, 22))\n",
    "figure_num += 1\n",
    "for i in np.arange(len(group_names)):\n",
    "    end = len(group_names) -1\n",
    "    thisi = i\n",
    "    thiscol = i%3\n",
    "    name = group_names[i]\n",
    "    anax = axs[math.floor(i/3),thiscol]\n",
    "    somdata = boxes[boxes.groupname == name]\n",
    "    \n",
    "    somdata = somdata[somdata.water_name == lake]\n",
    "    thisplot = sns.scatterplot(\n",
    "            data=somdata,\n",
    "            x='location',\n",
    "            y='pcs_m',\n",
    "            hue='location',\n",
    "            style='significant',\n",
    "            s=160, ax=anax,\n",
    "            palette='husl',\n",
    "            markers={True:'X', False:'s'}\n",
    "        )\n",
    "    handles, lables = anax.get_legend_handles_labels()\n",
    "    anax.get_legend().remove()\n",
    "    anax.set_xticks([])\n",
    "    anax.set_xlabel(\"\")\n",
    "    the90th = sig_vals[name]\n",
    "    if thiscol > 0:\n",
    "            anax.set_ylabel(\"\")\n",
    "    else:\n",
    "        anax.set_ylabel(\"pieces per meter\", **ylab_k)\n",
    "    if is_french:\n",
    "        anax.set_title(F\"{french_sum_names[name]} 90%= {np.round(the90th, 3)} \", **title_k14)        \n",
    "    else:\n",
    "        anax.set_title(F\"{name} 90%= {np.round(the90th, 3)}\", **title_k14)\n",
    "\n",
    "\n",
    "\n",
    "usedgrids = [[math.floor(i/3), i%3] for i in np.arange(len(group_names))]\n",
    "availablegrids = [[math.floor(i/3), i%3] for i in np.arange(rows*cols)]\n",
    "\n",
    "# get the unused grids\n",
    "unusedgrids = [x for x in availablegrids if x not in usedgrids]\n",
    "\n",
    "# turn off the unused grids\n",
    "for grid in unusedgrids:\n",
    "    axs[grid[0],grid[1]].tick_params(**tabtickp_k)\n",
    "    axs[grid[0],grid[1]].grid(False)\n",
    "    make_table_grids(axs[grid[0],grid[1]])\n",
    "\n",
    "# put the legend in the last grid and size it\n",
    "for handle in handles:\n",
    "    handle.set_sizes([200])\n",
    "fig.legend(handles, lables, bbox_to_anchor=(0.99, 0.01), loc='lower right', ncol=2, fontsize=12)\n",
    "\n",
    "\n",
    "# tag the figure\n",
    "figname = F\"figure{figure_num}.jpg\"\n",
    "atype=\"figure\"\n",
    "tag = F\"{lake} regional assessment\"\n",
    "\n",
    "plt.suptitle(F\"Figure {figure_num}: significant events per code group {lake}\", ha='left', x=0.047, size=16, y=.98)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.95)\n",
    "\n",
    "# add figure to output:\n",
    "add_output(figname,tag, fignum=figure_num, atype=atype)\n",
    "\n",
    "plt.box(on=None)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figures and data produced by this notebook:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "files_df = pd.DataFrame(files_generated[2:])\n",
    "files_df.rename(columns={'tag':'description'}, inplace=True)\n",
    "\n",
    "files_df = files_df[['type','number', 'description']]\n",
    "files_df = files_df.sort_values(by='type')\n",
    "files_df.sort_values(by='number', inplace=True)\n",
    "tablecenter_k = dict(loc=\"top left\", bbox=(0,0,1,1), cellLoc='center', colWidths=[20,10,70], fontsize=12)\n",
    "tablecenter_kx = dict(loc=\"top left\", bbox=(0,0,1,1), cellLoc='center', fontsize=12)\n",
    "        \n",
    "with sns.axes_style('white', {'xtick.color':'white', 'ytick.color':'white'}):\n",
    "    fig, axs = plt.subplots(figsize=(12,(len(files_df)*.75)), frameon=False)\n",
    "    sns.despine(fig=fig, top=True, left=True, right=True, bottom=True)\n",
    "\n",
    "    make_table_grids(ax1)\n",
    "\n",
    "    \n",
    "\n",
    "    a_table = axs.add_table(mpl.table.table(\n",
    "        cellText=files_df.values,\n",
    "        colLabels=files_df.columns,\n",
    "        colColours=['antiquewhite' for col in files_df.columns],\n",
    "        ax=axs,\n",
    "        **tablecenter_k))\n",
    "\n",
    "\n",
    "    table_fonts(a_table)\n",
    "\n",
    "    axs.tick_params(**tabtickp_k)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hopefully that just worked for you\n",
    "\n",
    "if not contact analyst@hammerdirt.ch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
