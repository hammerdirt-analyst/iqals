{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys, file and nav packages:\n",
    "import os\n",
    "import datetime as dt\n",
    "import csv\n",
    "import json\n",
    "\n",
    "# math packages:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# charting:\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# home brew utitilties\n",
    "import utilities.utility_functions as ut\n",
    "import utilities.abundance_classes as ac\n",
    "\n",
    "# chart kwargs\n",
    "title_k = {'loc':'left', 'pad':14, 'linespacing':1.5, 'fontsize':12}\n",
    "title_k14 = {'loc':'left', 'pad':16, 'linespacing':1.5, 'fontsize':14}\n",
    "xlab_k = {'labelpad':10, 'fontsize':12}\n",
    "xlab_k14 = {'labelpad':14, 'fontsize':14}\n",
    "\n",
    "survey_data, location_data, code_defs, stat_ent, geo_data, output = ut.make_local_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set some parameters:\n",
    "start_date = '2020-04-01'\n",
    "end_date ='2021-04-01'\n",
    "\n",
    "# name the folder:\n",
    "name_of_project = 'keyindicators'\n",
    "\n",
    "# use this to store things:\n",
    "project_directory = ut.make_project_folder(output, name_of_project)\n",
    "\n",
    "# keep track of output\n",
    "files_generated = []\n",
    "figure_num = 0\n",
    "data_num = 0\n",
    "\n",
    "# keyword arguments for the abundance class:\n",
    "group_names_locations = {\n",
    "    \"waste water\": \"wastewater.json\" ,\n",
    "    \"less than 5mm\":\"codeListMicros.json\",\n",
    "    \"construction\":\"construction.json\",\n",
    "    \"food\":\"foodstuff.json\",\n",
    "    \"agg-con-trans\":\"cat.json\",\n",
    "    \"agriculture\":\"ag.json\",\n",
    "    \"tobacco\":\"tobac.json\",\n",
    "    \"recreation\":\"recreation.json\",    \n",
    "    \"packaging non food\":\"packaging.json\",\n",
    "    \"personal items\":\"pi.json\",    \n",
    "}\n",
    "\n",
    "\n",
    "frag_plas = {\"fragmented plastics\":[\"G79\", \"G78\", \"G75\"]}\n",
    "\n",
    "\n",
    "def add_output(**kwargs):\n",
    "    files_generated.append({'tag':kwargs['tag'], 'number':kwargs['figure_num'], 'file':kwargs['file'],'type':kwargs['a_type']})\n",
    "    if kwargs['a_type'] == 'data':\n",
    "        kwargs['data'].to_csv(F\"{kwargs['file']}.csv\", index=False)\n",
    "    else:\n",
    "        plt.savefig(F\"{kwargs['file']}.jpeg\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non aggregated survey data\n",
    "# Zero values are assigned for all codes not identified at a survey, for each survey\n",
    "# see the notebook 'getdataforrepo' to see how this is done\n",
    "dfSurveys = pd.read_csv(F\"{survey_data}/results_with_zeroes.csv\")\n",
    "\n",
    "# house keeping\n",
    "# slice the data by the start and end date, convert date to datetime\n",
    "dfSurveys = dfSurveys[(dfSurveys.date >= start_date)&(dfSurveys.date <= end_date)]\n",
    "dfSurveys['date'] = pd.to_datetime(dfSurveys['date'], format=\"%Y-%m-%d\")\n",
    "\n",
    "# import river bassin labels\n",
    "river_bassins = ut.json_file_get(F\"{location_data}/river_basins.json\")\n",
    "\n",
    "# import beach data\n",
    "dfBeaches = pd.read_csv(F\"{location_data}/beaches_with_ranks.csv\")\n",
    "dfBeaches.set_index('slug', inplace=True)\n",
    "\n",
    "# assign river bassin labels to dfBeaches:\n",
    "for k,v in river_bassins.items():\n",
    "    dfBeaches.loc[dfBeaches.water_name.isin(v), 'river_bassin'] = k\n",
    "\n",
    "# code definitions\n",
    "dfCodes = pd.read_csv(F\"{code_defs}/mlw_codes.csv\", index_col='code')\n",
    "\n",
    "# map codes to descriptions and material type:\n",
    "material_map = dfCodes.material\n",
    "desc_map = dfCodes.description\n",
    "\n",
    "# project lakes and beaches:\n",
    "project_lakes = ut.json_file_get(F\"{location_data}/project_lakes.json\")\n",
    "project_beaches = ut.json_file_get(F\"{location_data}/project_beaches.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of the survey data and tag the records as either lake or river:\n",
    "data = dfSurveys.copy()\n",
    "\n",
    "# map lake or river from dfBeaches\n",
    "lakes = dfBeaches[dfBeaches.water == 'l'].water_name.unique()\n",
    "rivers = dfBeaches[dfBeaches.water == 'r'].water_name.unique()\n",
    "\n",
    "# map values to new column t:\n",
    "data['type'] = 't'\n",
    "for a_place in data.water_name.unique():\n",
    "    data.loc[data.water_name.isin(lakes), 'type'] = 'l'\n",
    "    data.loc[data.water_name.isin(rivers), 'type'] = 'r'\n",
    "\n",
    "# check if there any un categorized records:\n",
    "if len(data[data['type']=='t']) > 0:\n",
    "    print(F\"\\nThere are {len(data[data['type']=='t'])} records that were not classified as either lake or river:\\n\\n{data[data['type']=='t']}\\n\")\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#008891\">Description of survey results</span>\n",
    "\n",
    "### <span style=\"color:#008891\"> Total number of surveys and observations, total number of objects found, number of cities and total population concerned</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the data into a class\n",
    "a_class_kwargs = dict(\n",
    "    code_group_data=group_names_locations,\n",
    "    new_code_group=frag_plas,\n",
    "    levels=['river_bassin', 'water_name', 'city'],\n",
    "    river_bassins=river_bassins,\n",
    "    exp_variables=['population','buildings', 'streets', 'intersects', 'pop_group_proj', 'pop_group_rip', 'streets_rank', 'buildings_rank'],\n",
    "    code_group_loc=output,    \n",
    ")\n",
    "a = ac.PreprocessData(data, dfBeaches,**a_class_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the final data set here:\n",
    "a_data = a.survey_data[a.survey_data.river_bassin != 'reuss'].copy()\n",
    "\n",
    "# describe the data set:\n",
    "num_obs = len(a_data)\n",
    "num_samps = len(a_data.loc_date.unique())\n",
    "num_obj = a_data.quantity.sum()\n",
    "num_locs = len(a_data.location.unique())\n",
    "\n",
    "\n",
    "\n",
    "# number of municipalities\n",
    "a_map = dfBeaches['city']\n",
    "munis = [a_map[x] for x in a_data.location.unique()]\n",
    "munis = list(set(munis))\n",
    "num_munis = len(munis)\n",
    "\n",
    "# population\n",
    "total_pop_d = dfBeaches.loc[a_data.location.unique()][['city', 'population']]\n",
    "total_pop_c = total_pop_d.drop_duplicates('city')\n",
    "total_pop = total_pop_c.population.sum()\n",
    "\n",
    "num_rivs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an intermediary group\n",
    "foams_bg = ut.json_file_get(F\"{code_defs}/all_foams.json\")\n",
    "sheeting_bg = ut.json_file_get(F\"{code_defs}/sheeting.json\")\n",
    "fragplas_bg = ut.json_file_get(F\"{code_defs}/fragmented_plastics.json\")\n",
    "\n",
    "# put all the group members into one list\n",
    "the_big_group = ['G27','G30', *foams_bg, *sheeting_bg, *fragplas_bg]\n",
    "\n",
    "\n",
    "# map intermediary group to survey data\n",
    "a_data['big_group'] = 'no group'\n",
    "a_data.loc[a_data.code.isin(foams_bg), 'big_group'] = 'foams'\n",
    "a_data.loc[a_data.code.isin(sheeting_bg), 'big_group'] = 'sheeting'\n",
    "a_data.loc[a_data.code.isin(fragplas_bg), 'big_group'] = 'frag plastic'\n",
    "a_data.loc[a_data.code.isin(['G27']), 'big_group'] = 'cigarette ends'\n",
    "a_data.loc[a_data.code.isin(['G30']), 'big_group'] = 'snack wrapper'\n",
    "\n",
    "# if an object is not in \"the_big_group\" it retains its code name\n",
    "for code in [x for x in a_data.code.unique() if x not in the_big_group]:\n",
    "    a_data.loc[a_data.code==code, 'big_group'] = code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#008891\">The top ten objects identified</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# note all records where quantity is > 0\n",
    "a_data['fail'] = a_data.quantity > 0\n",
    "w_bassin_total = a_data.groupby('river_bassin').quantity.sum()\n",
    "\n",
    "# get the list of codes by quantity\n",
    "national_topten= a.code_totals.sort_values(ascending=False)\n",
    "\n",
    "# take first ten records after sorting\n",
    "national_topten_codes = national_topten.index[:10]\n",
    "\n",
    "# grab the data from the survey results:\n",
    "top_ten_national = a_data[a_data.code.isin(national_topten_codes)][['code', 'quantity', 'fail', 'pcs_m', 'loc_date']].copy()\n",
    "\n",
    "# add descriptive and categorical variables:\n",
    "top_ten_national['material'] = top_ten_national.code.map(lambda x: material_map.loc[x])\n",
    "top_ten_national['description'] = top_ten_national.code.map(lambda x: desc_map.loc[x])\n",
    "\n",
    "\n",
    "# agg the values from the survey data\n",
    "# there is a convenience method for this\n",
    "# the groups and the level where quantity is calculated:\n",
    "groups = {'quantity_level':'code', 'columns':['code', 'description']}\n",
    "\n",
    "# the columns to aggregate\n",
    "aggs = {'pcs_m':'mean', 'quantity':'sum', 'fail':'sum', 'loc_date':'nunique'}\n",
    "\n",
    "# columns divided by other columns\n",
    "rates = [\n",
    "    {'rate_name':'fail rate','columns':{'this':'fail', 'over_that':'loc_date'}},\n",
    "    {'rate_name':'% of total', 'columns':{'this':'quantity', 'over_that':'feature_total'}},\n",
    "]\n",
    "\n",
    "# product of two columns\n",
    "products = [\n",
    "     {'rate_name':'rating', 'columns':{'this':'pcs_m', 'times_that':'fail rate'}}    \n",
    "]\n",
    "\n",
    "# method that returns the project total total:\n",
    "def get_the_project_total(x , adf):\n",
    "    return  adf.quantity.sum()\n",
    "\n",
    "# calculate the fail rate and % of total for each code:\n",
    "top_ten_agg = ac.calculate_rates(top_ten_national, feature_total_map=get_the_project_total, feature_map=a_data,groups=groups, aggs=aggs, rates=rates, products=products)\n",
    "\n",
    "# for display purposes make the description the index\n",
    "top_ten_agg.set_index('description', inplace=True)\n",
    "print(F\"\\nThe top ten objects are {round((top_ten_agg.quantity.sum()/num_obj)*100, 2)}% of all objects identified\\n\")\n",
    "\n",
    "tt_agg = top_ten_agg[['quantity']].sort_values(by='quantity', ascending=False).round(2)\n",
    "tt_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#008891\">Survey results: consolidating object categories</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top ten list gives a very high level summary of the survey results. Based entirely on the total amount of an object found. It is a good indicator of overall abundance of an object in the ecosystem. Using this method we can account for ~60% of objects identified and very quickly identify the most abundant objects.\n",
    "\n",
    "The top ten list can be improved to account for a greater percentage of the objects found. Currently, polystyrene is present in three forms in the top ten list, extruded polystyrene and two size variants of expanded polystyrene. Fragmented plastics are also present twice in the top ten list. The survey method was designed to get a maximum amount of detail for each survey. Grouping like objects by size is a common way to differentiate observations.\n",
    "\n",
    "Some of the objects in the top ten list that can be consolidated:\n",
    "\n",
    "1. There are three objects that are made from expanded or extruded polystyrene\n",
    "2. Fragmented plastics are present in two different size ranges.\n",
    "\n",
    "By combining like objects or objects that have the same or similar origin the impact of that group can be better appreciated. When the foam and the fragmented plastics are combined, that liberates three new places in the top ten list. Foams replace cigarette ends as the most abundant (pcs/m and quantity) but cigarette ends still retain the title as most frequently found (fail rate). The top ten list now accounts for ~70% of the objects identified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#008891\"> There is more room at the top: a consolidated top ten list</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fts = a_data.groupby(['river_bassin','big_group','loc_date'], as_index=False).agg({'pcs_m':'sum', 'quantity':'sum'})\n",
    "fts['fail'] = fts.quantity > 0\n",
    "\n",
    "# assign a description to results:\n",
    "def assign_descriptions(x, **kwargs):\n",
    "    if x in kwargs['exclude']:\n",
    "        data = x\n",
    "    else:\n",
    "        data = kwargs['som_keys'][x]\n",
    "    return data\n",
    "\n",
    "\n",
    "groups = {'quantity_level':'big_group', 'columns':['big_group']}\n",
    "\n",
    "ftsx = ac.calculate_rates(fts, feature_total_map=get_the_project_total, feature_map=a_data,groups=groups, aggs=aggs, rates=rates, products=products)\n",
    "\n",
    "bg_desc = ['foams', 'cigarette ends', 'frag plastic', 'snack wrapper', 'sheeting']\n",
    "som_kwargs = dict(exclude=bg_desc, som_keys=desc_map)\n",
    "\n",
    "ftsx['description'] = ftsx.big_group.map(lambda x: assign_descriptions(x, **som_kwargs))\n",
    "\n",
    "\n",
    "ftsx = ftsx[['description','quantity', '% of total', 'pcs_m','fail rate']].set_index('description').sort_values(by='quantity', ascending=False)[:10].round(2)\n",
    "print(F\"\\nThe consolidated top ten objects are {round((ftsx.quantity.sum()/num_obj)*100, 2)}% of all objects identified\\n\")\n",
    "ftsx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *fail rate* is a **key indicator** as well as *% of total* and *pieces per meter*. Each indicator can be used to understand different aspects of the survey results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#008891\">Using the survey results: key indicators of the top ten objects</span>\n",
    "\n",
    "### <span style=\"color:#008891\">Key indicators for the most frequent questions:</span>\n",
    "\n",
    "1. What do you find?\n",
    "2. How often do you find it?\n",
    "3. Do you find alot of it?\n",
    "4. What else do you find?\n",
    "5. Where do you find the most? \n",
    "\n",
    "The key indicators provide reasonable answwers to those questions using parameters that are taken directly from the survey data. The key indicators are used throughout the report. In this section we explain the key indicators and use them to answer some common questions about the national results.  There is a detailed example of each calculation in annex A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#008891\">Key indicators definition and use</span>\n",
    "\n",
    "\n",
    "#### **Fail rate:** How often at least one of a particular item was found at a survey\n",
    "\n",
    "There are 76,466 observations from 346 surveys or 221 observations per survey. Observations that have a quantity greater than 0 for a survey are scored with a 1, if the quantity is 0 it is scored with a zero. The sum of the score is the number of times that an object was identified. \n",
    "\n",
    "_The fail rate is the number of times that an object was found divided by the number of samples taken._\n",
    "\n",
    "__what does it mean:__ The fail rate describes how likely you are to find at least one of an object in the course of the survey\n",
    "\n",
    "__how to use it:__ The objects with a high fail rate are those that are most likely to be found at a particular aggregation level\n",
    "\n",
    "__Why is this important?__ The fail rate alerts us to the presence of items that are identified regularly even though they may not be found in large quantities or the inverse.\n",
    "<br/><br />\n",
    "\n",
    "#### **Pieces per meter:** How many objects were found within a defined distance\n",
    "\n",
    "The pieces per meter ratio is the total number of objects found divided by the length in meters of the survey. This ratio is calculated for each record in the survey. Objects that were not identified durring a survey have a pcs/m ratio of 0.\n",
    "\n",
    "_Pieces per meter is the number of objects found divided by the number of samples taken._\n",
    "\n",
    "__what does it mean:__ The pcs-m ratio describes the average amount of an object you are likely to find if you mulitply pcs/m by the survey length\n",
    "\n",
    "__how to use it:__ Objects with a high pcs/m ratio have a higher minimum value per survey (if they are found: see fail rate)\n",
    "\n",
    "__Why is this is important?__ A high pcs/m ration indicates either proximity to a source or a zone of accumulation\n",
    "<br/><br />\n",
    "\n",
    "#### **% of total** The amount of an object relative to the other objects indeitififed\n",
    "\n",
    "The percent of total describes the value of an object when all the other objects are considered.\n",
    "\n",
    "__what does it mean:__ The % of total describes how much of the problem can be attributed to an object or group of objects\n",
    "\n",
    "__how to use it:__ The % of total is the often the first indicator used to prioritize mitigation campaigns\n",
    "\n",
    "__Why is this important:__ This helps define the problem at different levels\n",
    "<br/><br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#008891\">Key indicators of the top ten objects</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,3, figsize=(5.4,8))\n",
    "\n",
    "sns.heatmap(pd.DataFrame(ftsx['% of total']), ax = axs[0], cmap='YlOrRd', linewidth=.01, linecolor='white', annot=True, square=True, fmt=\".0%\", cbar=False)\n",
    "sns.heatmap(pd.DataFrame(ftsx['pcs_m']), ax = axs[1], cmap='YlOrRd', linewidth=.01, linecolor='white', annot=True, square=True, fmt=\".2\", yticklabels=False, cbar=False)\n",
    "sns.heatmap(pd.DataFrame(ftsx['fail rate']), ax = axs[2], cmap='YlOrRd', linewidth=.01, linecolor='white', annot=True, square=True, fmt=\".0%\", yticklabels=False, cbar=False)\n",
    "\n",
    "for i in [0,1,2]:\n",
    "    axs[i].set_ylabel(\"\")\n",
    "    axs[i].set_xlabel(\"\")\n",
    "    axs[i].xaxis.tick_top()\n",
    "    axs[i].xaxis.set_label_position('top') \n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hopefully that just worked for you\n",
    "\n",
    "if not contact analyst@hammerdirt.ch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
